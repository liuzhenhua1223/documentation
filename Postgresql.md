[TOC]



# 第一章 数据库系统概述

- 数据库技术
  - 数据库管理技术是组织或企业管理各类信息资源，几乎所有的领域都在采用数据库进行信息资源的存储和处理，因此数据库建设规模，是国家重要的`标识`

## 数据库的基本概念

### 数据（Data）

- 数据有多种表现形式，可以包括数字、字母、文字、特殊字符组成的文本数据，也可以是 图像、动画、影响、声音等各种形式的数据经过数字化处理后存入计算机。
  - 例如（张三，男，26，北京，19128220296）表示客户张三的信息

## 数据库（Database，DB）

- 通常被称为存储数据库的仓库，这个仓库存储在计算机存储设备上，并且所存储的数据是按一定的格式进行存储的。严格意义上讲，数据库指长期存储在计算机中 有组织的、可共享的数据集合，具有较小的冗余度、较高的数据独立性、系统易于扩展，并且可以被多个用户共享。
- `数据库中存储的数据具有永久存储、有组织和可共享三个基本特点`

## 数据库管理系统（DatabaseManagement System,DBMS)

- 是专门用于建立和管理数据库的一套软件，介于应用程序和操作系统之间。
- 科学有效的组织和存储数据，帮助数据库使用者从大量数据中快速地获取所需要的数据，以及提供必要的安全性和完整性，实现对数据有效的管理和维护。

1. 数据定义功能
   - 用户可以通过数据库管理系统提供数据定义语言（DDL）定义数据库中的数据对象，`包括表、视图、存储过程、触发器等`
2. 数据操纵功能
   - 用户可以通过数据库管理系统提供的数据操纵语言（DML）操作数据库中的数据，实现数据的`查询、插入、删除和修改等`
3. 数据库的运行管理功能
   - 数据库中可以提供多个用户同时使用共享数据，保证安全性、可靠性，并且开提供了控制和管理机制，从而数据不会被互相干扰的情况下并发使用，并且在故障是能够正确恢复
4. 数据库的建立和维护功能
   - 包括创建数据库及对数据库空间的维护、备份与恢复，重组织和性能监控、分析等。
5. 数据组织、存储和管理功能
   - 为提高数据存储效率，数据库管理系统需要对数据进行分类存储和管理。一般数据库管理系统会根据组织和存储方式提供多种存取方法、例如 索引查找，顺序查找等。

## 数据库系统（Database System，DBS）

- 是指在计算机中引入数据库技术之后的系统。通常一个完整的数据库系统包括数据库、数据库管理系统以及相关实用工具、应用程序、数据库管理员和用户
  - 其中DBA用来维护数据库正常运行，用户则是数据库系统的服务对象，其通常包括程序员和数据库终端用户，程序员通过高级设计语言(PHP JAVA)和数据库语言SQL，编写数据库应用程序。应用程序会根据需要想数据库管理系统发出合适的请求，再有数据库管理系统对数据库进行执行相应的操作，而终端用户则是从客户机或联机终端上交互方式向数据库系统提出请求，并由数据库管理系统响应执行，而后访问数据库中的数据
- 此外，一般在不引起混淆的情况下，常常将数据库管理系统简称为数据库。

# 第二章 数据管理技术的发展

## 数据库管理阶段分为

- 人工管理阶段

  - 20世纪50年代，主要通过手动的方式进行数据处理，一切靠人
    1. 数据不保存
       - 一组数据对应一个成勋，数据空间随着空间一切被释放
    
    2. 应用成勋管理数据
       - 当时没有数据库管理软件，数据库的设计工作，有应用程序的编写人员来完成。
    
    3. 数据面向应用
       - 一个数据只能对应一个程序，当多个应用程序 涉及某些数据时，必须各自定义，不能共享，因此程序与程序之间存在大量的冗余数据，数据的独立性差。

![image-20240530092527349](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240530092527349.png?raw=true)

## 文件系统管理阶段

- 文件系统是将 数据的`逻辑结构`和`物理结构`分离，由`存放方法`实现逻辑结构与物理结构之间的映射。`应用程序`只涉及数据`逻辑结构` `系统确定`数据的`物理结构`

- 这样当物理结构发生变化时，不会导致逻辑结构的修改，这成为数据的为例独立性

  ---

  可以理解为：逻辑结构就是数据(data)，物理结构(操作系统),当操作系统或者底层出现变化时，只要能提供操作系统或底层设备，就能正常运行逻辑结构数据

## 数据库系统管理阶段

### 数据集成

- 通过对数据的逻辑结构和物理结构的分离，当对应用进行增加等操作时，只对数据的逻辑结构发生关系。

- 这样可使数据得到最大程度的共享，且冗余最小

### 数据共享性高

- 数据共享指，在数据库中，一个数据库可以为多个不用的用户共同使用，各个用户可以为了不同的目的来存取 数据，并且他们是从不同的角度来看待数据库，即一个数据库有多个不同用户视图

### 数据冗余小

- 例如：学生学籍、学校图书馆应用、学校校园卡管理应用中，每一个应用都拥有一个包含学生信息的文件。而且对于数据库方法，这些独立而且有冗余的数据文件被集成为单一的逻辑结构，并且每一个数据项的值可以理想地只存储一次，从而节约存储空间，避免数据的重复存储。
- 但 并不是所有的冗余都应该被消除 ，有时，由于应用业务或技术上的原因，如果数据合法性校验、数据存取效率等方面，可以能就需要保持多个副本。因此，在数据库系统中，冗余是受控制的，保留必要的冗余也是系统预定的。

### 数据一致性

- 例如：一个学生的学号信息存储在数据库的两个记录中，当该学生应为调专业而需要更新他的学号时，若无控制，且只更新一个记录时，则会引起同一数据的两个副本的不一致性，此时数据库是不一致的。
- 显然引起不一致的根源是数据冗余。要是数据库只存储一次，则不会发生不一致行。但冗余又是避免不了的，所以，当发生更新时，数据库本身可以通过更新所有的其他副本来自动保持数据的一直性

### 数据独立性高

- **逻辑独立性**：
  - 想象你有一张表格，这张表格的数据可以通过不同的方式显示给不同的用户（或者应用程序）。
  - 比如，你有一张学生成绩表，老师看的是所有成绩，学生看到的只是自己的成绩，校长看到的是年级的平均成绩。
  - 如果某个应用程序（比如老师的应用程序）需要一些修改，比如增加一些功能，这时候只需要修改这个应用程序的视图，而不用去动表格本身。
  - 反过来，如果需要在表格里加一列数据，比如学生的手机号，只要不影响视图，应用程序也不需要修改。
  - 这种不互相干扰的特性，就是逻辑独立性。

### **物理独立性**：

- 想象你的数据存储在某个地方，可能是一台服务器，也可能是一个硬盘。
- 现在，如果你想换一种存储方式，比如从硬盘换到固态硬盘，或者换一个更快的数据库系统，只要这些改变不影响数据本身的定义（比如数据结构、数据内容），那么你就不用修改任何使用这些数据的应用程序。
- 应用程序继续照常运行，而不需要知道底层数据存储发生了什么变化。
- 这种随便换存储方式却不影响应用程序的特性，就是物理独立性。

---

现代的数据库系统中，通过数据独立性，你可以轻松应对这些变化而不需要频繁修改应用程序

---

### 实施统一管理与控制

- 主要包括数据的安全性、完整性、并发控制与故障恢复等，即数据库保护
- 数据安全性
  - 确保数据不被非法访问或破坏
  - 只有有权限的用户才能查看或修改特定数据
  - 比如，只有管理员才能看到用户的密码。
- 数据完整性
  - 确保数据正确、有效、符合规则
  - 数据必须在合理范围内，满足一定条件
  - 比如，性别字段只能是`男`或`女`
- 并发控制
  - 方式多个用户同时修改数据产生冲突
  - 确保同时操作数据不会导致错误
  - 比如，多个用户同时购买一张火车票，系统能正确处理。
- 故障恢复
  - 处理硬件故障，操作失误或人为损坏导致的数据损失
  - 能将数据库恢复到出错前的正确状态
  - 比如，断电后恢复到最近保存的数据状态

---

这样，数据库系统能统一管理和保护数据，确保数据安全、正确并在多用户环境中正常运行。

---

### 减少应用程序开发与维护的工作量

- 在数据库上开发与维护新的应用所花费的代价和时间大大减少。
- 数据库中，具有共享性和独立性，所以编程人员不需要承担基本数据文件设计。
- 应对数据变动，数据库中的类型、关系、存储方式变了，不需要大幅修改应用程序。传动文件系统中，数据变量就得重写程序，但数据库环境下，只需要小改动。

## 数据库系统结构

- 数据库管理员（DBA）的视角
  - 内部系统结构： 通常采用三级模式结构。
  - 外部体系结构： 表现为集中式结构，分布式结构和并行结构。
- 数据库应用用户的视角：
  - 运行与应用结构：通常具有客户/服务器（C/S）
  - 结构和浏览器/服务器（B/S)
- 三级模式结构
  - 内模式：也成为物理模式，描述数据的物理存储方法和数据结构。负责存储空间分配，数据压缩加密等。
  - 概念模式：描述整个数据库的逻辑结构和特性，是对所有用户可见的数据模式
  - 外模式：也成为用户视图，描述用户能看见和访问的数据。

![image-20240530125142922](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240530125142922.png?raw=true)

### 1. 模式（Schema）

- **模式是逻辑视图**：它不包括具体的技术细节，比如用什么数据库管理系统（DBMS），文件怎么组织，数据怎么存取，或者使用什么设备
- **数据库管理员（DBA）的任务**：DBA需要定义数据的逻辑结构、数据之间的关系，以及数据的安全性和完整性要求，而不是关心数据是如何存储的。
- **模式的中间层作用**：它在外模式（用户视图）和内模式（物理存储）之间起桥梁作用。模式不涉及数据的实际存储细节和硬件环境，也不依赖于具体的编程语言或开发工具。
- **唯一且稳定**：一个数据库只有一个模式，并且这个模式相对来说是稳定的。
- **模式描述语言（Schema DDL）**：数据库管理系统（DBMS）使用这种语言来定义模式，明确数据的逻辑结构、数据之间的关系，以及安全性和完整性等要求。

---

概念模式，就是

---



### 2.外模式

- **用户视图**：外模式是为了满足不同用户需求而提供的不同数据视图。它是整个数据库的一部分，供用户使用。
- **模式的子集**：外模式通常是整个数据库模式的一个子集，是对部分数据的重新组织。
- **因需而异**：不同用户可能有不同的需求、查看数据的方式、保密要求等，因此，每个用户的外模式可以不一样。
- **灵活多样**：同样的数据，在不同的外模式中，可以有不同的结构、类型、长度、保密级别等。这意味着数据库可以灵活地适应不同用户的需求。
  - 例如：在学校的管理信息系统中，教务处子系统用户只能看到教师的授课信息，学生的选课及成绩信息，人事处理系统用户只能看到教师的基本资料信息。

### 3.内模式（Internal Schema）

在三级模式结构中，内模式也称为存储模式（Storage Scheam），他是对数据库中数据物理结构和存储方式的描述，是数据库内部的表示形式。

- **存储描述**：内模式详细描述了数据在数据库内部的存储结构和方式。
- **底层视图**：这是数据库管理员看到的数据库内部结构。
- **独立于物理设备**：内模式与具体的物理存储设备无关，不涉及扇面、磁道等物理细节。
- **数据管理**：内模式定义了内部记录类型、索引、文件组织方式等数据管理细节，包括数据是按顺序还是按B树存储，是否压缩、加密等。
- **DBMS定义**：数据库管理系统使用内模式描述语言（DDL）来严格定义内模式。

## 三级模式结构的两层映像与数据独立性

### 外模式/模式映像

- 定义：
  - 外模式/模式映像是一种对应规则，用于定义外模式与概念模式之间的影响关系。他描述了如何将外模式转换为概念模式。由于一个概念模式可以有多个外模式，因此每个外模式都有其对应的外模式/模式映像。
- 功能与作用
  - 映像关系的定义：外模式/模式映像在各自的外模式中定义。这些映像关系确保外模式和概念模式之间的转换。
  - 应对模式变化：当概念模式发生变化（如增加新的关系、新的属性或改变属性的数据类型等）时，数据库管理员（DBA）会相应地调整各个外模式/映像模式。这使得用户的外模式不变。
  - 保持外模式稳定：通过调整映像关系，外模式不受概念模式i安华的影响，保证了应用程序的稳定性，编程人员无需修改基于外模式编写的应用程序。
  - 实现逻辑独立性：外模式的稳定性和独立性，确保了数据与程序的逻辑独立性，即使底层概念模式发生变化，也不会影响到外模式及其上层的应用。

---

外模式/模式映像在数据库系统中起到了桥梁作用，连接了外模式和概念模式。通过这一机制，数据库系统能够有效管理模式变化带来的影响，保证外模式的稳定，从而实现数据与程序的逻辑独立性，降低了应用程序维护的复杂度。

### 模式/内模式映像

- 定义了数据库全局逻辑结构与物理存储之间的对应关系，通常在模式中加以描述的。由于数据库只有一个模式，且只有一个内模式，所以`模式`/内模式映像是唯一的。
- 当数据库物理存储发生变化，DBA也会对`模式`/`内模式映像`做出相应的调整，以使数据库的模式保持不变，从而不去修改应用程序，如此实现了概念模型不受内模型变化的影响，并保证了数据与程序的物理独立性。
- 由此可见，这两层映像保证了数据库系统中的数据能具有较高的逻辑独立性和物理独立性，是的数据的定义和描述可以从应用程序分离，简化数据库应用开发，和维护的工作量

## 数据库系统体系结构

### C/S

![image-20240530163747496](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240530163747496.png?raw=true)

### B/S

![image-20240530164210879](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240530164210879.png?raw=true)

## 数据模型

- 是现实世界特征的模拟和抽象的表达，其有助于人们更好的认识客观世界中的事物、对象、过程等感兴趣的内容，例如：汽车模型、飞机模型、建筑图纸等等。对现实世界数据特征的抽象，描述的是数据的共性内容。

### 数据结构

- 描述静态特性，及数据类型、内容、属性及数据对象之间的联系。
- 常安数据结构的类型来命名：层次结构、网状结构、
- 关系结构的数据模型分别为命名：层次模型、网状模型、关系模型，以及近年来得到广泛应用的面向对象模型。

### 数据操作

- 数据操作主要分为更新和检索两大类，其中更新包括 插入、删除和修改。数据模型必须定义这些操作的确切含义，操作符号、操作规则(如优先级)以及实现操作的语言。

### 数据约束

- 数据约束描述数据结构中数据间语法和语义关联
- 数据约束包括：数据完整性约束、数据安全性约束、并发控制约束，通过约束刻画了数据静态特征，也表示了数据动态行为规则。
- 例如在关系模型中，任何关系必须满`足实体完整性`和`参照完整性`这两类约束。此外，数据模型还需要提供定义的完整性约束条件的机制，从而遵守特定的语义约束条件。
  - 例如：在某个网购数据库中，规定购买某些在线商品的客户的年龄不得低于18岁

### 数据模型分类

- 真实地模拟虚拟现实世界
- 容易被人们所理解
- 便于在计算机上实现

- 第一类是概念层数据模型，第二类是逻辑层数据模型和物理层数据模型。

![image-20240530174942827](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240530174942827.png?raw=true)

#### 概念层数据模型

- 概念层是数据抽象级别的最高层，其目的是按用户的观点来对世界建模。
- `概念层数据库模型`，也称数据的`概念模型`或`信息模型`用来描述世界的事物，与计算机系统无关，且独立与任何DBMS，但容易想DBMS所支持逻辑数据模型转换。

##### 信息世界中的基本概念

- 概念模型一方面具有较强的语义表达能力，能够方便、直接地表达应用的各种语义知识，另一方面他简单、清晰、易于用户理解。

1. 实体（Entity）
   - 实体可以是实际的事物，也可以是抽象的概念或联系。
     - 例如：商品、学生、部门、课程、比赛等都可以作为实体
2. 属性（Attribute）
   - 一个实体可以由多个属性来描述，
   - 例：学生、具有学号、姓名、性别、出生日期。
3. 码或键(Key)
   - 可以唯一标识实体的属性集为码或键
     - 例如，学号是学生实体的码或键
4. 域(Domain)
   - 属性的取值范围，称为该属性的域。
     - 例如：学生实体中姓名的域为字符串集合，性别的域为(男,女)
5. 实体型(Entity Type)
   - 具有相同属性的实体必然是有共同的特征和性质。
     - 例如：学生(学号、姓名、性别、出生日期)就是一个实体型
6. 实体集(Entity Set)
   - 同型实体的集合称为实体结合
     - 例如：每个学生是一个实体，所有学生构成一个实体集合
7. 联系（Relationship)
   - 在现实世界中，事物内部以及事物之间是有联系的，这些联系在信息世界中反映为实体(型)内部的联系和实体(型)之间的联系。实体内部的联系通常是指实体各属性之间的联系，例如，确定了学号，就一定能知道与之对应的姓名，即学号与姓名这两个属性之间有联系。实体之间的联系是指不同实体之间的联系，例如，一个班有许多的学生，一个学生只属于一个班级，学生与班级这两个实体之间有联系。型”(type)和“值”(value)两个不同的概念。
   - 需要注意的是，在数据模型中有“型”指的是对某一类数据的结构和属生的说明，而“值”是型的一个具体赋值。例如，在客户档案中，客户信息定义为(姓名，性别，年龄，籍贯，所在城市，联系电话)这样的记录型，而(张三，男，26,北，上海，13912345678)则是该记录型的一个记录值。

##### 概念模型的表示方法

- PPS.Chen 提出的实体-联系方法(Entity-Relationship approach)。该方法用E-R图来描述现实世界的概念模型，E-R方法也称为E-R模型

  - 实体型：其用矩形表示，矩形框内写明实体的名称。

  - 属性：其用椭圆形表示，并用无向边将其与相应的实体连接起来。

  - 联系：其用菱形表示，菱形框内写明联系的名称，并用无向边分别与有关实体连接起来。

    同时在无向边旁标上联系的类型，如果一个联系具有属性，则这些属性也要用无向边与该联系连接起来。

![image-20240530224858112](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240530224858112.png?raw=true)

**说明：**由于学生、课程等实体的属性较多，部分属性没有标出。另外，关于使用E-R图进行数据库概念结构 设计的细节。

**值得注意的是**：实体-联系方法是抽象和描述现实世界的有力工具。概念模型独立于具体的DBMS所支持的逻辑模型，他是各种逻辑模型的共同基础，因而比逻辑模型更一般，更抽象，更接近现实世界

### 逻辑层数据模型

- 这一层的数据抽象称为逻辑层 数据模型，也称为数据的逻辑模型(Logical Mode) 
- 他是用户通过数据库管理系统看到的现实世界，是基于计算机系统的观点对数据进行建模和表示，因此，既需要考虑用户理解，有要考虑便于DBMS实现。

#### 层次模型

1. **结构**：
   - 层次模型使用树形结构来表示数据，数据以父子关系层次化排列。
   - 每个节点表示一个数据项，每个节点可以有多个子节点，但每个子节点只能有一个父节点。
2. **优点**：
   - 数据结构简单，容易理解和实现。
   - 数据检索速度快，适合处理结构明确且关系单一的数据。
3. **缺点**：
   - 缺乏灵活性，不易适应复杂的多对多关系。
   - 由于父子关系的严格性，插入、删除和更新操作可能涉及大量的重新链接。
4. **使用场景**：
   - 适用于组织结构、目录结构等层次分明的应用场景。

#### 网状模型 

1. **结构**：
   - 网状模型使用图结构来表示数据，数据节点之间可以有多种关系。
   - 节点之间的连接通过边来表示，每个节点可以有多个父节点和多个子节点。
2. **优点**：
   - 更灵活，能够表示更复杂的多对多关系。
   - 通过索引机制，数据检索和操作可以更高效。
3. **缺点**：
   - 数据结构复杂，理解和实现较为困难。
   - 维护和管理较为复杂，可能需要更多的系统资源。
4. **使用场景**：
   - 适用于航班预定系统、电信网络等需要复杂数据关系的应用场景。

#### 关系模型

> 关系模型是用二维表结构来表示实体及实体间联系的模型，并以二维表格的形式组织数据库

- 关系模型是建立在严格的数学概念的基础上的。
- 关系模型的概念单一，统一用关系来表示实体以及实体之间的联系，对数据的检索和更新结构同样也是用关系(即表)来表示。因而，关系模型的数据结构简单、清晰，用户易懂，易用。
- 关系模型的存取路径对用户透明，从而具有更高的数据独立性、更好的安全保密性，也简化了工具和数据库建立的工作

# 第三章 关系数据库概述

### 数据库基本术语

- 关系数据结构
- 关系操作结合
- 关系完整约束

且关系数据库是以二维表格的形式组织数据如下图

![image-20240531145312594](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240531145312594.png?raw=true)

#### 表（Table）

表，也称为关系，是一个二维的数据结构，他由表名，构成的各个列(如 学号、姓名等)及若干行数据(各个学生的具体信息)组成。每个表有一个唯一的表名，表中每一行数据描述一条具体的记录值。

#### 关系(Relation)

一个关系逻辑上对应一张二维表，可以为每个关系取一个名称进行标识。例如，上面的图片，学生基本信息登记表，也即学生基本信息登记表。

- 基本关系
- 查询表
- 视图表

---

其中 基本关系通常又称为基本表或基表，真是存在的表，是实际存储数据的逻辑表示

查询表是查询结果对应的表

视图表是由基本表或其他视图表导出的表，是虚表，不应实际存储的数据

#### 列（Coloumn）

表中的列，也称为字段(Field)或属性(Attribute)。表中每一列有一个名称、字段名或属性名。每一列表示实体的一个属性，具有相同的数据类型。

![image-20240531164105916](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240531164105916.png?raw=true)

 需要说明的是：在一个数据库中，表名必须唯一，在表中，字段名必须唯一，不同表中可以出现相同的段名，表和字段的命名应尽量有意义，并尽量简单。

#### 属性（Attribute)

表中的一列即为一个属性，列的值称为属性值，属性值的取值范围称为值。录入上图表中：学号、姓名、性别等等即元数是8，即学生基本信息登记表关系是一个8元关系或8度关系。

#### 行（ROW）

也称作元组或记录。表中的数据是按行存储的。表中一行数据即为一个元组或十条记录。

#### 元组（Tuple）

表中的一行即为一个元组

![image-20240531165356058](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240531165356058.png?raw=true)

#### 分量(Component)

![image-20240531165824274](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240531165824274.png?raw=true)

**分量**是表格中的每一列，比如学号、姓名、班级等。

**码或键**是由一个或多个分量组成的，用来唯一标识表格中的每一行。

当码或键由多个分量组成时，这些分量的组合必须是唯一的

#### 码或键(Key)

码或键是一种方法，用来保证表格中的每一行都是独一无二的。

它可以是一个字段（比如学号），也可以是多个字段的组合（比如班级+座位号）。

#### 超码或超键(Super Key)

是一个或多个列（属性）的组合，这些列的组合能够唯一标识表格中的每一行。

超码可以包含多余的列，只要这组列能够保证唯一性。

- 学号 + 姓名
- 班级 + 座位号
  - 都是是唯一的

#### 候选码或候选键(Candidate Key)

> 是可以唯一标识表格中每一行的一组列，其中任意一个候选码都可以成为主键。
>
> 候选码是主键的候选项，而主键是最终选择的唯一标识符。

假设有一个学生信息表格，包含以下列：

- 学号（Student ID）
- 姓名（Name）
- 身份证号（ID Card Number）

在这个表格中，每个学生都有唯一的学号，所以学号可以作为候选码。同时，身份证号也可以作为候选码，因为每个学生的身份证号也是唯一的。

#### 主码或主键

> 一个关系的若干个候选码或候选键中指定一个用来唯一标识关系的元组，这个被指定的码或候选键为主键或主码

假设你有一个学生信息表，每行记录了一个学生的详细信息。在这个表里，学生的学号就是主键。因为每个学生的学号都是唯一的，所以你可以用学号来快速找到这个学生的所有信息。

#### 全码或全键(All-Key)

> 一个关系模式的所有属性集合是这个关系的主码或主键，则称这样的主码或主键为全码或全键

假设你有两个表：一个是“员工表”，里面有员工的ID（主键）和姓名；另一个是“部门表”，里面有部门的ID（主键）和部门名称。如果还有一个“员工部门表”，用来记录哪些员工属于哪个部门，那么这个表就会有两个外键：员工ID和部门ID，这两个外键分别与“员工表”和“部门表”的主键相匹配。

#### 主属性(PTimary Attribute)和非主属性

> 关系中包含任何一个候选码中的属性称为主属性或码属性，不包含任何一个候选码中的属性称为非主属性或非码属性。

**主属性**： 想象一下你有一个钱包，钱包里有很多卡，比如身份证、银行卡、会员卡等等。在这些卡中，身份证是最重要的，因为它能证明你的身份，没有它，很多事情都办不了。在数据库里，主属性就像身份证，是识别一条记录最核心的信息，比如一个人的姓名和身份证号，或者一个学生的学号。

**非主属性**： 还是拿钱包里的卡来比喻，除了身份证之外，其他的卡，比如银行卡、会员卡等，虽然也很重要，但它们不是证明你身份的核心。在数据库里，非主属性就像是这些其他的卡，它们提供了额外的信息，比如一个人的年龄、性别、住址等，但这些信息不是唯一识别一个人的最关键信息。

简单来说：

- **主属性**：是最重要的，用来唯一确定一条记录。
- **非主属性**：虽然也重要，但不是唯一确定记录的关键信息

#### 外码或外键(Foreign Key)

> 当关系中的某个属性不是这个关系的主码或候选码，而是另一个关系的主码时，称该属性为这个关系的外码或外键。

**外键**： 在数据库里，"外键"就像是购物中心里的门牌号。它是一个表里面的一个字段，用来指向另一个表的主键。就像门牌号帮助顾客找到商店一样，外键帮助数据库管理系统找到与之相关联的记录。

举个例子，假设你有一个"订单"表，每条记录代表一个顾客的订单。订单表里有一个字段叫做"顾客ID"，这个"顾客ID"就是外键，它指向"顾客"表里的"顾客ID"主键，这样你就知道每个订单是哪个顾客下的。

#### 15 参照关系和被参照表

Referencing Relation——Referenced Relation

1. **被参照表**：一个“学生”表，里面有一个“学号”字段作为主键，每个学生的学号都是唯一的。
2. **参照关系**：一个“课程”表，里面有一个“学生学号”字段作为外键，它参照“学生”表中的“学号”字段。

在这个例子中，每当你在“课程”表中添加一个新课程记录时，你必须确保“学生学号”字段中的学号在“学生”表中是存在的。这样，我们就知道这个课程记录是属于哪个学生的。

总结一下：

- **被参照表**：是包含主键的表，其他表通过外键与之建立关联。
- **参照关系**：是数据库表之间通过外键和主键建立的一种关系，确保数据的引用完整性和一致性。

#### 16域(Domain)

> 域标识属性的取值范围

#### 17数据类型(Data Type)

> 表中每个列都有相应的数据类型，它用于限制该列中存储的数据，每个字段表示同一类信息，具有相同的数据类型

#### 18关系模式(Relation Schema)

- 同数据模型一样，数据库也有"型"(type)和值(value)之分，在关系数据库中，关系模式是型，关系是值，即关系模式是对关系的描述

用大白话来说，“关系模式”就像是一张表格的设计图。在数据库的世界里，我们用表格来存储数据，而“关系模式”就是定义这张表格应该如何构建，包括表格里应该有哪些列（字段），每一列应该存储什么类型的数据，以及这些列之间有什么关系。

**关系模式**由以下几个部分组成：

1. **表名**：这是表格的名称，用来标识表格是关于什么的。比如，一个存储学生信息的表可能叫做“Students”。
2. **列（字段）**：表格中的每列代表一个特定的数据属性。比如，在“Students”表中，可能有一列叫做“Name”，用来存储学生的姓名；还有一列叫做“Age”，用来存储学生的年龄。
3. **数据类型**：每一列都有一个数据类型，这决定了该列可以存储什么类型的数据。比如，“Name”列可能是字符串类型，用来存储文本；“Age”列可能是整数类型，用来存储数字。
4. **键（Key）**：在关系模式中，键是用来唯一标识表中每条记录的。最常见的键是主键（Primary Key），它确保了每条记录的唯一性。
5. **约束（Constraints）**：这是一些规则，用来限制可以存储在表中的数据。比如，你可能有一个约束规定“Age”列只能存储0到120之间的整数。
6. **关系**：关系模式还定义了表与表之间的关系，比如通过外键（Foreign Key）来建立的参照关系。

举个例子，如果我们设计一个图书馆的数据库，我们可能会有一个“Books”表，这个表的关系模式可能包括：

- 表名：Books
- 列：BookID（主键，唯一标识每本书），Title（书名），Author（作者），PublishYear（出版年份）
- 数据类型：BookID（整数），Title（字符串），Author（字符串），PublishYear（整数）
- 约束：BookID必须是唯一的，PublishYear必须是有效的年份

通过定义关系模式，我们确保了数据库的结构清晰、组织有序，并且数据的存储和检索都是高效和准确的。

#### 19关系数据库(Relation Database)

> 关系数据库是以关系模型作为数据的逻辑模型，并采用关系作为数据组织方式的一类数据库，其数据库操作建立在关系代数的基础上。在给定的领域中，所有关系的集合构成一个关系数据库。

![image-20240603142622555](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603142622555.png?raw=true)

![image-20240603142825439](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603142825439.png?raw=true)

![image-20240603142855207](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603142855207.png?raw=true)

#### 二维表要求

- 每个属性都是不可分解的。
- 每个类系仅仅有一种关系模式，即每个关系模式中的属性的数据类型以及属性的个数和相对固定的
- 每个关系模式中的属性必须命名，在同一个关系模式中，属性名必须是不同的
- 同一个关系中不允许出现候选码或候选键值完全相同的元组。
- 在关系中元组的顺序(即行序)是无关紧要的，可以任意交换
- 在关系中属性的顺序(即列序)是无关紧要的，可以任意交换

### 关系操作集合

#### 1、基本的关系操作

**增删改查**：查询(Query)	操作和插入(Insct)	删除(Delete)	修改（Updata)操作等部分

![image-20240603145249193](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603145249193.png?raw=true)



#### 2、关系数据库语言分类

1. **关系代数**： 就像用数学公式来问数据库问题。比如，你可以说：“给我所有年龄大于20的学生的名字和分数。”关系代数就是用这种类似代数公式的方式来表达你的请求。
2. **元组关系演算**： 这种方式是用逻辑语言来描述你想要找到的数据。比如，你可以说：“找出所有在北京的学生。”这种方式关注的是数据记录（元组）本身。
3. **域关系演算**： 这也是一种逻辑方式，但它关注的是数据的属性（域），而不是记录。比如，你可以说：“找出所有分数超过90的记录。”

这三种方式虽然看起来不同，但其实它们都能做到相同的事情，就像用筷子、叉子或手抓食物，最终都能吃到东西。

这些操作语言是抽象的，意味着它们是理想化的，用来设计和评估实际的数据库查询语言。就像建筑师的设计图和实际建造的房子之间的关系。

实际的查询语言，比如SQL（结构化查询语言），是基于这些抽象概念建立的，但它还包括了很多额外的功能，比如计算平均分、更新数据等，让操作数据库变得更加方便和强大。

### 结构化语言

- 不仅具有丰富的查询功能，而且具有数据定义和数据控制功能，是集查询、`数据定义语言(DDL)`、`数据操纵语言(DML)`和`数据控制语言(DCL)`
- 因此关系数据库语言可以分为三类：关系代数语言、关系演算语言以及兼具两者双重特点的语言(SQL)

![image-20240603152748211](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603152748211.png?raw=true)

#### 传统的集合运算

- 具体有 `并、差、交、笛卡尔积`四种运算。

![image-20240603153610348](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603153610348.png?raw=true)

##### 1并（UNION）

![image-20240603153825149](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603153825149.png?raw=true)

##### 差(DIFFERENCE)

![image-20240603153925438](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603153925438.png?raw=true)

![image-20240603153944243](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603153944243.png?raw=true)

##### 交(INTERSECTION)

![image-20240603154220099](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603154220099.png?raw=true)

![image-20240603154245205](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603154245205.png?raw=true)

##### 笛卡尔积

![image-20240603154324574](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603154324574.png?raw=true)

![image-20240603154340536](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603154340536.png?raw=true)

![image-20240603154519363](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603154519363.png?raw=true)

#### 专间的关系运算

**一元专门关系操作**：

- **投影运算（Projection）**：就像是你把箱子里的一个或几个抽屉抽出来，只看这些抽屉里的东西，忽略其他的抽屉。在数据库里，这就像是说：“我只想看名字和年龄这两列的数据。”
- **选择运算（Selection）**：这就像是你决定只保留箱子里某些特定的东西，比如所有红色的或者所有大的东西。在数据库里，这就像是说：“我只想要那些年龄超过18岁的人的记录。”

**二元专门关系操作**：

- **连接运算（Join）**：假设你有另一个类似的箱子，里面也有抽屉和层，但是装的是不同的信息。连接运算就像是把两个箱子里相对应的东西拿出来放在一起看。比如，一个箱子里有学生的成绩，另一个箱子里有学生的个人信息，连接运算就是把每个学生的成绩和他们的个人信息放在一起。
- **除运算（Division）**：这个稍微复杂一点，就像是你有一堆东西，你想知道哪些东西是共有的。在数据库里，这就像是说：“给我找出那些至少选了两门课的所有学生的名字。”

##### 1、选择SELECT

![image-20240603155352039](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603155352039.png?raw=true)

![image-20240603155419311](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603155419311.png?raw=true)

##### 2、投影(PROJECTION)

![image-20240603160213509](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603160213509.png?raw=true)

![image-20240603160237058](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603160237058.png?raw=true)

![image-20240603160244791](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603160244791.png?raw=true)

##### 3、连接(JOIN)

![image-20240603161205569](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603161205569.png?raw=true)

##### 4、除（DIVISION）

![image-20240603162700837](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240603162700837.png?raw=true)

### 关系完整性约束

数据库的数据完整性就像是保证数据库里的信息是准确、合理且没有矛盾的。这就像是你有一个关于学生的记录本，里面记录了学生的学号、性别和他们上的课。

- **正确性**：意味着每条信息都是对的，比如学生的学号没有重复，性别只能是男或女。
- **相容性**：意味着信息之间是协调的，比如一个学生选的课必须是学校真的开的课。
- **一致性**：意味着不管什么时候看，信息都是一样的，没有矛盾。

数据库里的完整性规则就像是一些规则和检查，确保当你往记录本里添加、删除或修改信息时，本子上的信息还是准确和合理的。这样，当你查看记录本时，得到的信息都是有意义的，能够真实反映每个学生的情况。所以，保持数据的完整性对于数据库来说非常重要。

> **实体完整性和参照完整性是关系模型必须满足的完整性约束条件，被称作是关系的两个不变性。**

#### 实体完整性约束

就是数据库里的一条规矩，它确保每条记录都是独一无二的，并且记录里的重要信息不能是空的。

比如，你有一个学生信息表，每个学生都有一个独一无二的学号。实体完整性约束就会确保：

1. 学号这一列不能有空值，因为学号是识别每个学生的依据。
2. 学号必须是唯一的，不能有两个学生有相同的学号。

这个约束就像是在说：“嘿，注意了，每个学生都得有一个自己的学号，而且这个学号不能跟其他人重复，这样我们才能清楚地知道谁是谁。”通过这样的规则，数据库就能保持数据的准确性和一致性。

#### 参照完整性约束

Referential Integrity Constraint

参照完整性约束，就是数据库里的一种规则，它保证了一个表中的某个字段（通常是外键）必须在另一个表的某个字段（主键）中也有相同的值。简单来说，就是：

1. **不能有孤儿**：如果一个表里的记录指向了另一个表中的某个记录，那么这个被指向的记录不能被删除，否则第一个表里的记录就会成为“孤儿”。
2. **更新要同步**：如果一个表中的主键值被更新了，那么所有指向这个主键的外键值也必须更新，以保持一致性。

就像你不能在家庭相册中删除一张家庭成员的照片，而不更新所有相关联的宠物照片一样。

#### 用户自定义完整性约束

用户自定义完整性约束，就像是给数据库定的额外家规。除了数据库自带的一些基本规则，比如学号唯一、性别只能是男或女之外，有时候我们还需要一些特别的规则来确保数据的准确性。

比如，你可能想要一个规则来确保：

- 学生的入学年份不能晚于当前年份。
- 订单的总价不能是负数。
- 员工的工号必须符合某种特定的格式，比如以特定的字母开头。

这些规则不是数据库天生就有的，而是根据你的具体需求来设定的。用户自定义完整性约束就是让你能够添加这些特别的规则，来保证数据库里的数据不仅满足基本要求，还满足你的业务逻辑和需求。

### 关系数据库规范

#### 数据冗余

- 数据冗余通常指同一个数据被多长进行了存储，例如，卖出了1000种相同的货物，并且被反复存储了1000次

#### 更新异常

- 数据冗余将导致空间的浪费和潜在的数据不一致及修改麻烦等问题。更改了999个数据有一个没有更新，那么数据就可能出现不一致。

#### 插入异常

就是当你想往数据库里添加新数据时，因为某些数据不符合规则，导致你不能添加。比如，你想添加一个学生的信息，但是忘了写学号，或者学号已经被别人用了，数据库就会说：“不行，你得按规矩来。” 

#### 删除异常

就是当你想从数据库里删除某些数据时，因为这些数据和其他重要数据有关联，删除它们会导致问题。比如，你想删除一个课程，但是有学生已经选了这门课，数据库就会说：“不行，这门课还有学生在上，你不能删。”

### 函数依赖

#### 完全函数依赖

就像你有一个密码锁，需要一个完整的密码才能打开。在数据库里，完全函数依赖意味着一个字段（或字段组合）完全依赖于另一个字段组合（通常是主键），没有任何一部分可以单独存在。如果去掉主键的一部分，你就无法确定这个字段的值了。

#### 部分函数依赖

这就像是你有一个密码锁，但是只需要密码的一部分就能打开。在数据库里，部分函数依赖是指一个字段依赖于主键的一部分，而不是整个主键。这意味着即使只有主键的一部分，也能确定这个字段的值，这通常不是我们想要的，因为它违反了规范化的原则，可能会导致数据冗余和更新异常。

#### 传递函数依赖

想象一下，你有一个传声筒，你在这头说话，声音通过中间的管道传到另一头。在数据库里，传递函数依赖就像是A字段决定了B字段，然后B字段又决定了C字段。虽然C字段实际上并不直接依赖于A字段，但是因为B的存在，C间接地依赖了A。

简单来说，就是如果通过一个字段（A）可以确定另一个字段（B），然后B又可以确定第三个字段（C），那么C就间接地依赖于A，这就是传递函数依赖。这种情况可能会让数据库设计变得复杂，因为它意味着字段之间有间接的联系，这在设计数据库时需要特别注意。

### 关系规范化过程

在关系数据库中，不同程度的要求称为不同的范式(NF)。满足最低要求的范式为第一范式(INF最基本范式),在第一范式的基础上进一步满足称为第二范式(2NF),以此类推，再进一步的范式是第三范式(3NF)以及其改进模型(BCNF)

![image-20240604144713351](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240604144713351.png?raw=true)

#### 第一范式1NF

**属性不可再分的原子值**

- 第一范式是一个不含重复组的关系，其中不存在嵌套结构。不满足第一范式的关系为非规范关系。例如：2.16图片中SC关系是一个非规范关系，因为学号为80154的学生数据库中出现了重复组。
- 非规范关系转化为1NF较为容易，可以通过重写关系中属性值相同部分数据来实现。如2.17所示的1NF

>**特点**：数据表中的每个字段都不能再分解成更小的单位。想象一下，你的学生信息表中有一列是“联系方式”，里面记录了学生的电话号码和电子邮件地址。这不符合1NF，因为“联系方式”这个字段还可以继续分解为“电话号码”和“电子邮件”两个字段。

![image-20240604151201267](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240604151201267.png?raw=true)



#### 第二范式 2NF

- 由2.17分解成的表2.18和2.19所示的关系都是1NF的，不存在非主属性对候选关键字的部分函数依赖，因此也满足2NF的定义。
- 然而2NF不能解决所有问题。在关系CI中，仍然存在插入、删除操作异常及修改麻烦等问题。例如有一位新老师报到，插入到CI中，但是该教师暂时还未承担任何教学工作，因此CNO值不能进行插入操作。

>满足1NF的基础上，要求表中没有字段是部分依赖于候选键的。候选键是可以用来唯一标识一条记录的字段或字段组合。如果一个表中，学生的“课程成绩”只依赖于“课程编号”而不是整个候选键“学生编号+课程编号”，那么这就违反了2NF。为了满足2NF，你需要把“课程编号”和“学生编号”分开，各自独立存储。
>
>如果一个表有组合主键，那么表中的其他字段必须依赖于这个组合主键的全部，而不是只依赖于其中的一部分。这样可以避免数据冗余和更新异常。

![image-20240604152444318](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240604152444318.png?raw=true)

#### 第三范式 3NF

- 根据第三范式，由分解形成的表2.20和2.21分别所示的关系COURSE和关系INSTRUCTOR都是第三范式。

- 通常，第三范式的关系大多数都能解决插入和删除操作异常的问题，数据冗余也能得到有效控制。但是，也存在一些列外。如表2.22所示的SCT中，若每个学生选多门课程，每一门课程可有多个指导老师，但每个老师只能指导一门。

>**特点**：满足2NF的基础上，要求表中没有字段是传递依赖于候选键的。传递依赖意味着一个字段依赖于另一个非主键字段。比如，如果“学生姓名”依赖于“学生编号”，而“学生编号”又是主键，那么“学生姓名”就是传递依赖于主键的，这违反了3NF。为了满足3NF，你需要将“学生姓名”和“学生编号”分开存储，消除这种传递依赖。
>
>3NF要求你确保数据表中的非主键字段之间没有相互依赖的关系，它们要么独立，要么直接依赖于主键。这有助于进一步规范数据表的结构，减少数据冗余，提高数据的一致性和完整性。

![image-20240604153835802](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240604153835802.png?raw=true)

#### 第三半范式 BCNF

- BCNF就像是3NF的加强版。它要求在数据表里，如果一个字段（X）依赖于另一个字段（Y），那么Y必须是构成主键的一部分。简单来说，就是不允许有任何字段依赖于主键之外的任何字段组合。

>- BCNF要求你确保数据表中的所有字段依赖都是直接与主键相关联的，不允许有任何间接的依赖关系。这有助于进一步规范数据表的结构，确保数据的规范化，减少数据冗余，提高数据的一致性和完整性。

![image-20240604164341074](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240604164341074.png?raw=true)

经分析，引起上述问题的原因在于：主属性之间存在函数依赖TNAME—>TITLE故需要进一步规范化，其结果为表2.23和2.24分别所示的ST和关系TC

![image-20240604164442934](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240604164442934.png?raw=true)

# 第四章 数据库设计概述

- 数据库设计具有两个十分重要的目标，既要满足功能需求和性能需求，主要是指对数据库高效率取和空间的节省，并具有良好的数据共享、完整性一致性和保密性。这样可以确保开发工作进展顺利，并能够高效工作效率，保证数据模型的准确和完整

## 生命周期

### 分析与设计阶段

### 实现与操作阶段

### 数据库设计的内容

#### 数据库结构设计

是针对给定的应用环境进行数据库的模式或子模式的设计，包括数据库的概念结构设计、逻辑结构设计和物理结构设计。模式定义并给出各应用程序共享的结构，是静态的，一经形形成通常不会变

#### 数据库行为设计

确定用户的行为和动作，而用户的行为和动作，而用户的行为和动作是对数据库的操作，他们通常是通过应用程序来实现的。

### 数据库设计的方法

直观设计法是一类最原始的数据设计方法，由于缺乏科学理论的指导，质量很难保证

#### 计算机辅助设法法

是指在数据库设计过程中，模拟某一规范设计的方法，通过人机交互的方式来设计某些过程，通过计算机软件工程工具（CASE）设计一些工作，加快数据库设计的进度

#### 规范设计法

规范设计法是一类较为普遍、常用的数据库设计方法。其中常见的有下面几个

##### 新奥尔良（New Orleans）

需求分析、概念结构设计、逻辑结构设计和物理结构设计，它注重数据库的结构设计，而不太考虑数据库行为设计

##### 基于E-R模型的数据库设计方法

用E-R图构造一个反应现实世界实体之间联系的模式，然后将模式转换成一个特定的DBMS下的概念模式。

##### 基于第三范式的设计方法

其思想是需求分析的基础上首先确定数据库的模式、属性及属性间的依赖关系，然后将他们组织在一个单一的关系模式中，在分析模式中不符合第三范式的约束条件，进行模式分解，规范若干个第三范式关系模式的集合。

![image-20240605001519581](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605001519581.png?raw=true)

## 数据库设计的基本步骤

### 需求分析

#### 1.确定数据库范围

- 应该支持那些功能
- 充分瞒住用户的应用功能要求
- 从而有效地利用计算机设备及数据库系统的潜在能力。

![image-20240605150312194](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605150312194.png?raw=true)

#### 2.应用过程分析

例如聚会：

- **了解和分析**：看看我们要准备什么食物和饮料（数据），以及谁来做、怎么做。
- **数据和处理关系**：就像决定谁来切菜、谁来煮饭，最后怎么上菜。
- **数据库结构设计**：确定哪些食材需要提前买好放在厨房，哪些只需要知道哪里买就行。
- **使用权限和共享范围**：就像告诉每个人，谁可以拿冰箱的东西，谁可以开火做饭。
- **应用程序编写依据**：就是聚会的流程指南，告诉大家每一步该怎么做。
- **数据流程图**：就是聚会的计划表，什么时间做什么事。
- **局部化和分块设计**：先搞定食物准备，再搞定音乐和装饰，一步步来。

应用过程分析的目的就是确保聚会（数据库操作）顺利进行，每个人都知道自己要做什么，每样东西都知道怎么用。

#### 3.收集与分析数据

- 了解并分析数据组成格式及操作特征。
- 可从数据的静态结构、动态结构及数据约束三个方面展开。

#### 静态结构

- 数据分类中的每一类数据所有数据元素名称、类型、长度、以及算法等都应该在数据元素表中。

![image-20240605152132258](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605152132258.png?raw=true)

#### 动态结构

是指是应用操作施加于数据之上后数据的状况，可以通过升任分类表和数据操作特征表进行说明。

#### 数据约束

> 数据约束是指使用数据库的特殊要求

- 数据的安全保密性，其主要是指针对各种不同类型数据，谁拥有操作(存 取、删、改)的不同授权
- 数据的完整性，其主要是指数据正确性的约束范围和验证准则，以及一致性保护的要求。
- 响应时间，其主要的指某些特定应用要求的数据存取时间限制。
- 数据恢复，其中要是指转存储及恢复的时机与范围等要求。

#### 编写需求分析报告

1. 数据库的应用功能目标

   要求明确表名数据库的应用范围及应达到的应用处理功能。

2. 标明不同用户视图范围

   根据机构与只能关系图和数据流程图，并参考任务分类表等，确定不同部门功能的局部视图范围。

3. 应用处理过程需求说明

   - 数据流程图
   - 任务分类表
   - 数据操作特征表
   - 操作过程说明书

4. 数据字典

   - 数据字典DDL是数据库系统中存储三级结构的数据库，是各类数据描述的结合。
   - 数据字典通常包括数据分类表、数据元素表和各类原始资料。

5. 数据量

   数据分类表中是静态数据和操作特征中的动态数据量，进行统计计算，求出数据总量。

6. 数据约束

### 概念结构设计

- 概念结构设计的常用方法又实体分析法和属性综合法，他们也分别称为自定向下法和自顶向上法

### 逻辑结构设计

1. 逻辑结构设计的输入和输出信息
   - 独立于特定DBMS的概念模型
   - 有关响应时间、安全保密性、数据完整性及恢复方面的要求说明，包括保持数据一致性的规则说明。
   - 数据量及使用频率
   - 特定DBMS特性，包括DBMS支撑的数据库模型及数据定义语言的说明。

![image-20240605165323964](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605165323964.png?raw=true)

![image-20240605165337097](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605165337097.png?raw=true)

## 概念结构设计方法

它通常使用E-R图来作为描述现实世界的建模工具。E-R图提供了表示信息中实体属性和联系的具体方法

- 实体型：其用矩形表示，矩形框内写明实体的名称
- 属性：其用椭圆形表示，并用无相边将其与相应的实体连接起来。
- 联系：其用菱形表示，菱形框内写明联系的名称，

1. 两个实体型之间的联系

   A、B两个实体型之间的联系可分为一对一、一对多、多对多

![image-20240605171526688](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605171526688.png?raw=true)

![image-20240605171502551](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605171502551.png?raw=true)

![image-20240605171657303](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605171657303.png?raw=true)

![image-20240605171730879](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605171730879.png?raw=true)

![image-20240605171823611](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605171823611.png?raw=true)

![image-20240605172032569](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605172032569.png?raw=true)

![image-20240605172049977](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605172049977.png?raw=true)

![image-20240605172203841](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605172203841.png?raw=true)

![image-20240605172255432](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605172255432.png?raw=true)

![image-20240605172629553](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605172629553.png?raw=true)

## 逻辑结构设计方法

![image-20240605172849060](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605172849060.png?raw=true)

![image-20240605172906725](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605172906725.png?raw=true)

![image-20240605173011205](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605173011205.png?raw=true)

![image-20240605173112293](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605173112293.png?raw=true)

![image-20240605173218142](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605173218142.png?raw=true)

![image-20240605173237093](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240605173237093.png?raw=true)

# Postgresql

# 第一章 安装与配置基础

## 1.1 初识Postgresql

- Postgresql源于UCBerkeley大学1977年的Ingress计划，由Michael Stonebraker领导的，随着2010年PostgreSQL 9.0的发行，正式进入了黄金发展阶段
- PostgreSQL是目前可免费获取最高级的开源数据库，目前主流的云服务提供商如亚马逊、阿里云、腾讯云、都提供了PostgreSQL的RDS服务。

### 1.1.1Postgresql特点

- 支持各种操作系统：Linux、Windows、UNIX等。拥有丰富的接口，C、C++、GO、JAVA、Perl、Python和开放数据库连接（ODBC）的编程接口

- 支持广泛的数据类型，数组，json，jsonb，还可以使用SQL命令CREATE TYPE创建自定义类型。
- 复杂的SQL查询，子查询，函数和统计语法、支持主键、外键、触发器、视图、物化视图。
- 支持并行计算和基于MVCC的多版本并发控制，支持同步、半同步、异步的主流复制，支持逻辑复制和订阅。
- 可以将其他数据源当作自己的数据表使用，如Oracle、Mysql等等。

### 1.1.2 许可

- PostgreSQL使用PostgreSQL的 License声明，类似于BSD或MIT的软件授权许可，由于这个经OSI认证的版本不受限制PostgreSQL在上衣环境和版权的应用程序中使用，公认是灵活和商业用用友好。

## 1.2 安装PostgreSQL

### 1.2.1 通过YUM源安装(互联网)

- 通过YUN源安装是最便捷的方式，前提需要连接互联网

1. **安装PostgreSQL的repository RPM**

   访问PostgreSQL官方主页:[PostgreSQL：Linux 下载（Red Hat 系列）](https://www.postgresql.org/download/linux/redhat/)

![image-20240606144353257](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240606144353257.png?raw=true)

```apl
sudo yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm
sudo yum install -y epel-release
sudo yum install -y libzstd
sudo yum install -y postgresql15-server
sudo /usr/pgsql-15/bin/postgresql-15-setup initdb
sudo systemctl enable postgresql-15
sudo systemctl start postgresql-15
```

![image-20240606150754056](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240606150754056.png?raw=true)

2. 安装PostgreSQL

   安装完成，通过yum search postgresql15看到包

   - postgresql15.x86_64：这个包只包含PostgreSQL的Client端程序和库文件，不会安装数据库服务器
   - postgresql15-docs.x86_64：文档
   - postgresql15-devel.x86_64：PostgreSQL的C和C++头文件，如果开发者libpq程序他是必须的
   - postgresql15-contrib.x86_64：PostgreSQL的附加模块，包含常用的扩展
   - postgresql15-server.x86_64：PostgreSQl server端程序，作为数据库服务器，他是最核心的包。

- 如果网络状况好，大约几秒钟就可以完成安装，使用yum源安装的位置在/usr/pgsql-15目录，可执行文件位于/usr/pgsql-15/bin目录，并且会自动创建一个postgresql账户，他的home目录在/var/lib/pgsql。

3. 卸载通过yum 源安装的PostgreSQL

   执行如下命令查看已经安装的PostgreSQL软件包

   ```apl
   [root@02 ~]# rpm -qa | grep postgresql
   postgresql15-15.7-1PGDG.rhel7.x86_64
   postgresql15-libs-15.7-1PGDG.rhel7.x86_64
   postgresql15-server-15.7-1PGDG.rhel7.x86_64=
   ```

   可以使用yum remove命令进行一个一个卸载，也可以直接卸载libs会将其他包一并卸载。

   ```apl
   [root@02 ~]# yum remove postgresql15-libs-15.7-1PGDG.rhel7.x86_64
   ```

   由于安装的时候已经间PostgreSQL作为服务安装，所以还需要删除服务管理脚本

   ```apl
   [root@02 ~]# rm -rf /etc/init.d/postgresql-15
   ```

### 1.2.2通过源码编译安装

通过源码便于安装和便于其他的开源工具一样简单方便。

1. 下载源码包

   官方主页：[PostgreSQL: File Browser](https://www.postgresql.org/ftp/source/v15.5/)

![image-20240606154315744](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240606154315744.png?raw=true)

​		下载后解压

```apl
[root@vm-1715569180 ~]# ls
anaconda-ks.cfg  postgresql-15.5.tar.gz
[root@vm-1715569180 ~]# tar -zxf postgresql-15.5.tar.gz
[root@vm-1715569180 ~]# ls
anaconda-ks.cfg  postgresql-15.5  postgresql-15.5.tar.gz
```

2. 运行Configure程序配置编译选项

   运行configure程序之前，需要先准备好编译环境和安装必要的包

   ```apl
   yum groupinstall "Development tools"
   yum install y bison flex readline-devel zlib-devel
   ./configure --prefix=/data/pg-15 --with-pgport=1921
   ```

![image-20240606162518354](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240606162518354.png?raw=true)

![image-20240606233711109](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240606233711109.png?raw=true)

3. 编译安装

   执行gmake或gmake world程序进行编译

   ```apl
   gmake
   ```

   执行gmake install或gmake install-world进行安装

   ```apl
   gmake install
   ```

   ![image-20240606233917360](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240606233917360.png?raw=true)

查看安装的PostgreSQL版本的命令如下所示

```apl
[root@pgsql postgresql-15.5]# /data/pg-15/bin/postgres --version
postgres (PostgreSQL) 15.5
```

### 1.2.3设置一个软连接

- 有时候为了方便工作，会自己写一些shell或Python脚本，经常会通过类似/data/pg15.x这样的全路径调用一些工具，如何尽可能避免麻烦，就需要通过软连接

```apl
[root@pgsql postgresql-15.5]# ln -s /data/pg-15/ /data/pgsql
```

- 当版本变更之后，不需要调整大量的脚本，只需要修改这个软连接即可。下文也会使用它。

## 1.3 客户端程序和服务器程序

- 目前已经成功安装了PostgreSQL数据库

  ```apl
  [root@pgsql postgresql-15.5]# tree -L 1 /data/pg-15/
  /data/pg-15/
  ├── bin //是PG应用程序
  ├── include //是PG的C、C++的头文件
  ├── lib 
  └── share //存放文档、man、实列、以及扩展
  4 directories, 0 files
  ```

---

PG本身就是一个C/S架构的程序，这些程序分为两类，客户端程序和服务器程序。

### 1.3.1 客户端程序

- 客户端程序也可以分为

1. 封装SQL命令的客户端程序

   **clusterdb**

   clusterdb 是 SQL CLUSTER命令的一个封装。PostgreSQL是 堆表存储的，clusterdb通过索引对数据库中基于堆表的物理文件进行重新排序，一定场景下可以`节省磁盘空间`、`加快查询速度`

   - 举例：

     ```apl
     /data/pgsql/bin/clusterdb -h pghost1 -p1921 -d mydb
     ```

   **reindexdb**

   reindexdb是 SQL REINDEX命令的一个封装。在索引物理文件发生损坏或索引膨胀情况方式时，可以使用reindex命令对指定的表或数据库进行重建索引并且删除旧的索引。

   - 举例：

     ```apl
     /data/pgsql/bin/reindexdb -h pghost1 -p1921 -d mydb
     ```

   **vacuumdb**

   vacuumdb 是 PostgreSQL数据库独有的VACUUM、VACUUM FREEZE和VACUUM FULL、VACUUM ANALYZE这几个SQL命令封装。主要是对数据的物理文件等垃圾回收。是PostgreSQL中非常重要的一些列命令

   - 举例：

     ```apl
     /data/pgsql/bin/vacuumdb -h pghost1 -p 1921 mydb
     ```

   **vacuumlo**

   vacuumlo 用来清理数据库中未引用的大对象。

   - 举例：

     ```apl
     /data/pgsql/bin/vacuumlo -h pghost1 -p 1921 mydb
     ```

   **createdb和dropdb**

   他们本别是SQL命令CREATE DATABASE和DEOP DATABASE的封装。

   - 举例

     ```apl
     /data/pgsql/bin/createdb -h pghost1 -p 1921 newdb "New database."
     
     ```

     ```apl
     /data/pgsql/bin/drop -h pghost1 -p 1921 newdb "New database."
     
     ```

   例如：创建一个名为newuser的非超级用户，newuser继承自pg_monitor系统角色，自由1个连接，没有创建数据库的权限，没有创建用户的权限，并且立即给他设置密码，如下：

   ```apl
   /data/pgsql/bin/createuser -h pghost1 -p 1921 -c 1 -g pg_monitor -D -R -S -P -e newuser
   Enter password for new role:
   Enter it again:
   ```



## 1.4 创建数据库实例

- 在PostgreSQL中一台数据库服务器可以管理多个数据库实例，也可以通过目录的位置和这个数据的集合实例的端口引用它

### 1.4.1 创建操作系统用户

- 在创建数据库之前，要先创建按一个独立的操作系统用户，也可以称为本地用户。目的是为例防止因为软件的BUG被攻击者利用。

```apl
groupadd -g 1000 postgres
useradd -g 1000 -u 1000 postgres
mkdir /data/pgdata
chown postgres.postgres /data/pgdata/
chown 0700 /data/pgdata/
su postgres
```

---

注意事项：

- 出于安全考虑，这个操作系统用户不能是root或具有系统管理员权限的用户如：sudo提权的用户。

### 1.4.2 创建数据目录

- 有时候可能会遇到多实例并存的情况，为例区分不同版本的数据，通常建立如/pgdata/9.x/xxx_data作为数据库实例的的目录，这样在进行大版本升级或多版本并存时，目录条理更清晰，同时可以减少出错。

- 例子：创建/data/pgdata目录作为数据目录，在pgdata的同级目录创建backups、scripts、archive_wals目录

  ```apl
  [root@pgsql postgresql-15.5]# mkdir -p /data/{backups,scripts,archive_wals}
  [root@pgsql postgresql-15.5]# chown postgres.postgres /data/ -R
  [root@pgsql data]# chmod 0700 /data/pgdata/
  
  ```

### 1.4.3初始化数据目录

- 实例化数据目录使用initdb工具。initdb工具将创建一个新数据库目录(这个目录包括存放数据的目录)，创建template1和postgres数据库，默认区域和字符编码。

  ![image-20240607132837989](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240607132837989.png?raw=true)

  ```apl
  [postgres@pgsql postgresql-15.5]$ /data/pgsql/bin/initdb -D /data/pgdata/ -W
  
  The files belonging to this database system will be owned by user "postgres".
  This user must also own the server process.
  
  The database cluster will be initialized with locale "zh_CN.UTF-8".
  The default database encoding has accordingly been set to "UTF8".
  initdb: could not find suitable text search configuration for locale "zh_CN.UTF-8"
  The default text search configuration will be set to "simple".
  
  Data page checksums are disabled.
  
  Enter new superuser password:
  Enter it again:
  
  fixing permissions on existing directory /data/pgdata ... ok
  creating subdirectories ... ok
  selecting dynamic shared memory implementation ... posix
  selecting default max_connections ... 100
  selecting default shared_buffers ... 128MB
  selecting default time zone ... Asia/Shanghai
  creating configuration files ... ok
  running bootstrap script ... ok
  performing post-bootstrap initialization ... ok
  syncing data to disk ... ok
  
  initdb: warning: enabling "trust" authentication for local connections
  initdb: hint: You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb.
  
  Success. You can now start the database server using:
  
      /data/pgsql/bin/pg_ctl -D /data/pgdata/ -l logfile start
  ```

- 因为使用了-W 参数，所以在初始化过程中，initdb工具要求为数据库超级用户创建密码

- 需要注意除了使用initdb来初始化数据目录，`pg_ctl`工具进行数据库目录的初始化，自持，初始化完成。

  ```apl
  /data/pgsql/bin/initdb -D /data/pgdata/ -W
  ```

## 1.5 启动和停止数据库服务器

- 在使用数据库服务器之前，必须先启动数据库服务器。可以通过service方式PostgreSQL的命令工具启动或停止数据库。

### 1.5.1 使用service方式

- 启动数据库服务的命令

  ```apl
  service postgresql start
  ## 查看运行状态
  service postgresql status
  ##停止数据库
  service postgresql stop
  ```

### 1.5.2 使用pg_ctl进行管理

- pg_ctl是postgreSQL中初始化数据目录，启动、停止、重启、数据库或查看数据库服务状态的工具，相比service或systemctl，pg_ctl提供了丰富的控制选项，`执行pg_ctl命令`需要系统用户使用`su`命令切换到`postgres`用户。

- 修改监听的主机

  vim /data/pgdata/postgresql.conf

  ```apl
  listen_addresses = '*'          # what IP address(es) to listen on;
  ```

- 配置远程连接认证

  vim /data/pgdata/pg_hba.conf

  ```apl
  host    all             postgres        192.168.71.10/32        md5
  ```

1. 启动数据库服务的命令

   ```apl
   su - postgres
   
   [postgres@pgsql postgresql-15.5]$ /data/pgsql/bin/pg_ctl -D /data/pgdata/ start
   waiting for server to start....2024-06-07 20:33:20.326 CST [38948] LOG:  starting PostgreSQL 15.5 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44), 64-bit
   2024-06-07 20:33:20.330 CST [38948] LOG:  listening on IPv6 address "::1", port 1921
   2024-06-07 20:33:20.330 CST [38948] LOG:  listening on IPv4 address "127.0.0.1", port 1921
   2024-06-07 20:33:20.331 CST [38948] LOG:  listening on Unix socket "/tmp/.s.PGSQL.1921"
   2024-06-07 20:33:20.333 CST [38951] LOG:  database system was shut down at 2024-06-07 19:25:12 CST
   2024-06-07 20:33:20.335 CST [38948] LOG:  database system is ready to accept connections
    done
   server started
   
   #####查看启动状态
   [postgres@pgsql postgresql-15.5]$ /data/pgsql/bin/pg_ctl -D /data/pgdata/ status
   
   pg_ctl: server is running (PID: 38948)
   /data/pg-15/bin/postgres "-D" "/data/pgdata"
   
   #####重启
   /data/pgsql/bin/pg_ctl -D /data/pgdata/ -m fast -w restart
   #####重启
   /data/pgsql/bin/pg_ctl -D /data/pgdata/ -m fast -w stop
   ```

2. 停止数据库

   使用pg_ctl停止数据库命令为：

   支持三种停止数据库的模式：smart、fast、immediate，默认为fast模式。

   - smart 模式会等待活动的事物提交结束，并等待客户端主动断开连接之后关闭数据库。
   - fast 模式则会回滚所有活动的事物，并强制断开客户的连接之后关闭数据库。
   - immediate模式立即终止所有服务器进程，当下次数据库启动时，他会首先进入恢复状态，一般不推荐使用
   - 这三个值简写为：`-ms -mf -mi`，例如使用smart模式停止数据库

   ```apl
   [postgres@pgsql data]$ /data/pgsql/bin/pg_ctl -D /data/pgdata/ -ms stop
   waiting for server to shut down....2024-06-07 23:32:32.411 CST [39561] LOG:  received smart shutdown request
   2024-06-07 23:32:32.412 CST [39561] LOG:  background worker "logical replication launcher" (PID 39567) exited with exit code 1
   2024-06-07 23:32:32.412 CST [39562] LOG:  shutting down
   2024-06-07 23:32:32.412 CST [39562] LOG:  checkpoint starting: shutdown immediate
   2024-06-07 23:32:32.413 CST [39562] LOG:  checkpoint complete: wrote 0 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.001 s, sync=0.001 s, total=0.002 s; sync files=0, longest=0.000 s, average=0.000 s; distance=0 kB, estimate=0 kB
   2024-06-07 23:32:32.415 CST [39561] LOG:  database system is shut down
    done
   server stopped
   ```

### 1.5.3 配置开机启动

- 如果使用官方yum源安装，会自动配置服务脚本，如果通过源码编译安装，则需要手动配置

1. 配置服务脚本

   在源码包的contrib目录中有linux、FreeBSD、OSX使用的服务脚本

   ```apl
   [root@pgsql postgresql-15.5]# ls contrib/start-scripts/
   freebsd  linux  macos
   ```

   我们将名称为linux的脚本拷贝到/etc/init.d/目录中，将脚本重命名为postgresql-15，并赋予可执行权限。

   ```apl
   root@pgsql postgresql-15.5]# chmod +x /etc/init.d/postgresql-15
   [root@pgsql postgresql-15.5]# ls -lh /etc/init.d/postgresql-15
   -rwxr-xr-x. 1 root root 3.5K 6月   7 23:41 /etc/init.d/postgresql-15
   ```

2. 设置开机启动

   chkcinfig命令将启用或禁止PostgreSQL开机启动项目

   chkconfig --list命令可以查看PostgreSQL是否开机启动

   ```apl
   [root@pgsql postgresql-15.5]# chkconfig postgresql-15 off
   [root@pgsql postgresql-15.5]# chkconfig --list|grep postgresql
   
   注：该输出结果只显示 SysV 服务，并不包含
   原生 systemd 服务。SysV 配置数据
   可能被原生 systemd 配置覆盖。
   
         要列出 systemd 服务，请执行 'systemctl list-unit-files'。
         查看在具体 target 启用的服务请执行
         'systemctl list-dependencies [target]'。
   
   postgresql-15   0:关    1:关    2:关    3:关    4:关    5:关    6:关
   ```

## 1.6数据库配置基础

- 在数据库实例中，有些配置会影响到整个实例，有些配置只对一个数据库实例中当个database生效，或支队当前会话数据库用户生效，称为非全局配置。
- 两个重要的配置文件：postgresql.conf和pg_hba.conf。这些参数从不同层面影响数据库系统的行为，
- postgresql.conf配置文件主要负责配置文件的位置、资源限制、集群复制等
- pg_hba.conf文件负责客户端的连接和认证。
  - 这两个文件都位于初始化数据目录中。

### 1.6.1 配置文件的位置

- 在实例化数据目录之后，在数据目录下会有postgresql.conf、postgresql.auto.conf、pg_hba.conf和pg_ident.conf这几个配置文件。除身份认证以外数据库系统行为都由postgresql.cnf文件配置

### 1.6.2 pg_hba.conf

pg_hba.conf是它所在数据库实例的”防火墙“文件格式如下

```apl
# TYPE  DATABASE        USER            ADDRESS                 METHOD

# "local" is for Unix domain socket connections only
local   all             all                                     trust
# IPv4 local connections:
host    all             all             127.0.0.1/32            trust
# IPv6 local connections:
host    all             all             ::1/128                 trust
# Allow replication connections from localhost, by a user with the
# replication privilege.
local   replication     all                                     trust
host    replication     all             127.0.0.1/32            trust
host    replication     all             ::1/128                 trust
host    all             postgres        192.168.71.10/32        md5
```

1. 连接方式

   TYPE 可用的值有：local、host、hostssl、hostnossl

   - local：匹配使用Unix，如果别有表示local的条目不允许通过Unix域套接字连接
   - host：匹配使用TCP/IP建立的连接，同时匹配SSL和非SSL连接。默认安装只监听本地回环地址localhost的连接，其用`远程连接`需要修改`postgresql.conf`中的`listen_address`参数
   - hostssl：匹配必须是使用ssl的TCP/IP连接。配置hostssl有三个前提条件
     - 客户端和服务端都安装OpenSSL
     - 编译PostgreSQL的时候指定configure参数--with-openssl打开SSL支持
     - 在postgresql.conf中配置ssl=on
   - hostnossl和hostssl相反，它只匹配使用非ssl的TCP/IP连接。

2. 目标数据库

   DATABSE 列表示该行设置对那个数据库生效；

3. 目标用户

   USER 列表示改行设置对哪个数据库用户生效

4. 访问来源

   ADDRESS 列标识该行设置对那个IP地址或IP地址段生效；

5. 认证方法：

   METHOD 列标识客户端认证方法，常见的认证方法有trust、reject、md5和password等。

   - reject认证方式：允许某一网段的大多数主机访问数据库，但拒绝这一网段少数特定主机
   - md5 和password 认证方式在于，md5认证方式为双重md5加密，password指明文密码，所以不要在非信任网络使用password认证方式。
   - scram-sha-256是PostgreSQL10中新增的基于SASL的认证方式，是PostgreSQL目前提供最安全的认证方式。
   - ```apl
     [postgres@pgsql bin]$ /data/pgsql/bin/psql -h pghost1 -p 1921 -U postgres mydb
     Password for user postgres:
     psql (15.5)
     Type "help" for help.
     
     mydb=#
     ```
   

### 1.6.3 Postgresql.conf

- postgresql.conf配置文件由多个configparameter = value形式的行组成，value支持的数据库类型由布尔、整数、浮点数、字符串、枚举，value的值还支持各种单位，MB、GB和ms、min、d。等还支持include和include_if_exists指令和嵌套

1. 全局配置修改方法

   修改全局配置方法由：

   - 修改postgresql.conf配置文件

   - 通过ALTER SYSTEM命令修改全局配置例如：

     ```apl
     mydb=# ALTER SYSTEM SET listen_addresses = '*';
     ALTER SYSTEM
     ```

   - 通过ALTER SYSTEM SQL命令修改的全局配置参数，会自动编辑postgresql.auto.conf文件，并在数据库启动时自动加载postgresql.auto.conf文件，并用它覆盖postgresql.conf中已有的配置。这个文件不建议修改它。

   - 启动数据库时进行设置，例如：

     ```apl
     [postgres@pgsql bin]$ /data/pgsql/bin/postgres -D /data/pgdata/ -c port=1922 &
     
     [1] 8473
     [postgres@pgsql bin]$ 2024-06-09 01:44:05.282 CST [8473] LOG:  starting PostgreSQL 15.5 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44), 64-bit
     2024-06-09 01:44:05.282 CST [8473] LOG:  listening on IPv4 address "0.0.0.0", port 1922
     2024-06-09 01:44:05.282 CST [8473] LOG:  listening on IPv6 address "::", port 1922
     2024-06-09 01:44:05.283 CST [8473] LOG:  listening on Unix socket "/tmp/.s.PGSQL.1922"
     2024-06-09 01:44:05.284 CST [8476] LOG:  database system was shut down at 2024-06-09 01:43:36 CST
     2024-06-09 01:44:05.285 CST [8473] LOG:  database system is ready to accept connections
     
     [postgres@pgsql bin]$ !ss
     ss -anptlu | grep postgre
     tcp    LISTEN     0      128       *:1922                  *:*                   users:(("postgres",pid=8473,fd=5))
     tcp    LISTEN     0      128    [::]:1922               [::]:*                   users:(("postgres",pid=8473,fd=6))
     ```

### 1.6.4允许远程访问数据库

- 默认情况PostgreSQL不允许通过远程访问数据库

1. 修改监听地址

   管理监听地址的配置项为postgresql.conf文件中的listen_addresses。默认localhost连接，不允许使用TCP/IP

   ```apl
   vim /data/pgdata/postgresql.conf
   
   找到监听项进行修改
   listen_addresses = '*'         
   ```

   监听项解释：

   - what IP address(es) to listen on; 
     - 监听什么IP地址，允许那些IP地址方位，可用是一个IP，也可以是多个IP
   - comma-separated list of addresses;
     - 以逗号分隔地址列表
   - defaults to 'localhost'; use '*' for all
     - 默认localhost，使用“*”允许所有地址，大多数的高可用架构使用VIP方式访问时一般设置为“*”
   - (change requires restart)
     - 修改这个参数时需要重启数据库，去掉listen前面的#号，并把它的值修改为“*”

   ```apl
   重启
   [postgres@pgsql bin]$ /data/pgsql/bin/pg_ctl -D /data/pgdata/ -m fast -w restart
   ```

# 第二章pgAdmin 4 

- pgAdmin是最流行的PostgreSQL图形化客户端工具，由于pgAdmin4 工具简单这里简单介绍

### 2.1.1 安装

官网下载地址：[PostgreSQL: File Browser](https://www.postgresql.org/ftp/pgadmin/pgadmin4/v8.7/windows/)

### 2.1.2 pgAdmin 4 使用

- pgAdmin 4 的使用非常简单，这一小节将演示pgAdmin 4 连接PostgreSQL数据库以及日常数据库操作

![image-20240608185616549](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240608185616549.png?raw=true)

![image-20240608185637870](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240608185637870.png?raw=true)

![image-20240608185702507](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240608185702507.png?raw=true)

![image-20240608185710751](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240608185710751.png?raw=true)

2. 查询工具使用

- 在pgAdmin 4 面板上点击Tools菜单中的QuseryTool进行日常数据库DDL、DML操作

![](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240608185710751.png?raw=true)

![image-20240608190050553](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240608190050553.png?raw=true)

3. 使用pgAdmin 4 显示统计信息

pgAdmin 4 具有丰富的监控功能，显示了数据库进程、每秒事物数、记录数据变化等相关信息。

![image-20240608190237759](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240608190237759.png?raw=true)

## 2.2 psql功能及应用

- psql是PostgreSQL自带的命令行客户端工具，具有非常丰富的功能，类似于Oracle命令行客户端工具sqlplus，这一节将介绍psql常用功能和特殊功能，熟练掌握psql处理日常维护工作

### 2.2.1 使用psql连接数据库

- 可以在数据接口服务端执行，可以远程连接数据库，在数据库服务端连接本地库

  psql 后面第一个postgres表示库名，第二个为用户，端口为默认1921

  ```apl
  数据库服务端连接本地[root@pgsql ~]# psql postgres postgres
  psql (15.5)
  Type "help" for help.
  
  postgres=# 
  ```

- 创建用户pguser

  ```apl
  postgres=# create role pguser with encrypted password  'qianyi12!';
  CREATE ROLE
  ```

- 创建表空间目录

  ```apl
  [postgres@pgsql ~]$ mkdir -p /data/pg-15/tbs_mydb
  [postgres@pgsql ~]$ psql postgres postgres
  psql (15.5)
  Type "help" for help.
  
  postgres=# create tablespace tbs_mydb OWNER pguser LOCATION '/data/pg-15/tbs_mydb';
  CREATE TABLESPACE
  
  ```

- 创建数据库

  ```apl
  查看当前来连接
  SELECT pid, usename, application_name, client_addr, client_port, backend_start, state
  FROM pg_stat_activity
  WHERE datname = 'mydb';
  
  创建数据库
  postgres=# CREATE DATABASE mydb WITH OWNER = pguser TEMPLATE = template0 ENCODING = 'UTF8' TABLESPACE = tbs_mydb;
  CREATE DATABASE
  
  ```

- 赋权

  ```apl
  postgres=# grant all on database mydb TO pguser with grant option;
  GRANT
  postgres=# grant all on tablespace tbs_mydb TO pguser;
  GRANT
  ```

CREATE DATABASE命令中的owner选项表示数据库属主，TEMPLATE表示数据库模板，默认有template0和templte1模板，也能自定义数据库模板，ENCODING表示数据库字符集，这里设置为UTF8，TABLESPACE表示数据库默认表空间。

- 服务器pghost1的IP为192.168.71.10，pghost2IP为192.168.71.11，在pghost1连接pghost2上的mydb数据库命令如下：

  ```apl
  [root@pgsql ~]# psql -h 192.168.71.11 -p 1921 mydb  -U postgres
  Password for user postgres:
  psql (15.5)
  Type "help" for help.
  
  mydb=# 
  ```

### 2.2.2psql元命令介绍

- psql中的元命令是指以反斜线开头给的命令，能够便捷的管理数据库，比如查看数据库对象定义、查看数据库占用空间大小、列出数据库各种对象名称、数据导入到出等。

- 查看数据库列表

  ```apl
  [root@pgsql ~]# psql -h pghost1 -p 1921 mydb  -U postgres
  Password for user postgres:
  psql (15.5)
  Type "help" for help.
  
  mydb=# \l
                                                   List of databases
     Name    |  Owner   | Encoding |   Collate   |    Ctype    | ICU Locale | Locale Provider |   Access privileges
  -----------+----------+----------+-------------+-------------+------------+-----------------+-----------------------
   mydb      | pguser   | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |            | libc            | =Tc/pguser           +
             |          |          |             |             |            |                 | pguser=C*T*c*/pguser
   postgres  | postgres | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |            | libc            |
   template0 | postgres | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |            | libc            | =c/postgres          +
             |          |          |             |             |            |                 | postgres=CTc/postgres
   template1 | postgres | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |            | libc            | =c/postgres          +
             |          |          |             |             |            |                 | postgres=CTc/postgres
  (4 rows)
  
  mydb=#
  
  ```

  1. \db查看空间列表

  ```apl
  mydb=# d\db
               List of tablespaces
      Name    |  Owner   |       Location
  ------------+----------+----------------------
   pg_default | postgres |
   pg_global  | postgres |
   tbs_mydb   | pguser   | /data/pg-15/tbs_mydb
  (3 rows)
  ```

  2. \dt查看表列表

     ```apl
     mydb=# \dt;
                List of relations
      Schema |   Name    | Type  |  Owner
     --------+-----------+-------+----------
      public | table_1   | table | postgres
      public | test_1    | table | postgres
      public | test_copy | table | postgres
     (3 rows)
     ```

  3. \d查看表定义

  - 先创建一张测试表：

  ```apl
  CREATE TABLE test_1 (
      id int4,
      name text,
      create_time timestamp without time zone DEFAULT clock_timestamp()
  );
  ALTER TABLE test_1 ADD PRIMARY KEY (id);
  ALTER TABLE
  ```

  `create_time` 是列名。

  `timestamp without time zone` 是数据类型，表示不带时区的时间戳。它用于存储日期和时间。

  `DEFAULT clock_timestamp()` 是默认值，指定如果插入行时未提供值，将使用当前的时间戳。

  `clock_timestamp()` 是一个内置函数，返回当前的日期和时间。

- generate_series函数产生连续的整数，使用这个函数能非常方便地产生测试数据，查看表test_1定义只需要执行\d后跟表名

  ```apl
  mydb=# \d test_1;
                                  Table "public.test_1"
     Column    |            Type             | Collation | Nullable |      Default
  -------------+-----------------------------+-----------+----------+-------------------
   id          | integer                     |           | not null |
   name        | text                        |           |          |
   create_time | timestamp without time zone |           |          | clock_timestamp()
  Indexes:
      "test_1_pkey" PRIMARY KEY, btree (id)
  ```

  4. 查看表、索引占用空间大小

  ```apl
  mydb=# INSERT INTO test_1(id, name)
  SELECT n, n || '_francs'
  FROM generate_series(1, 5000000) n;
  INSERT 0 5000000
  ```

  查看表大小执行\dt+ 表名：

  ```apl
  mydb=# \dt+ test_1
                                      List of relations
   Schema |  Name  | Type  |  Owner   | Persistence | Access method |  Size  | Description
  --------+--------+-------+----------+-------------+---------------+--------+-------------
   public | test_1 | table | postgres | permanent   | heap          | 287 MB |
  (1 row)
  ```

  查看索引大小执行\di+ 表名：

  ```apl
  mydb=# \di+ test_1_pkey;
                                             List of relations
   Schema |    Name     | Type  |  Owner   | Table  | Persistence | Access method |  Size  | Description
  --------+-------------+-------+----------+--------+-------------+---------------+--------+-------------
   public | test_1_pkey | index | postgres | test_1 | permanent   | btree         | 107 MB |
  (1 row)
  ```

5. \sf查看函数代码

```apl
CREATE OR REPLACE FUNCTION random_range(integer, integer)
RETURNS integer
LANGUAGE sql
AS $function$
    SELECT ($1 + FLOOR(($2 - $1 + 1) * random()))::int4;
$function$;
```

range(integer,integer),postgreSQL支持名称相同但输入参数类型不同的函数，如果有同名函数，\sf必须指定函数的参数类型。

6. \x设置查询结果输出

使用\x可用设置查询结果输出模式

```apl
mydb=# select * from test_1 limit 2;
  id  |    name     |        create_time
------+-------------+----------------------------
 7537 | 7537_francs | 2024-06-09 23:42:43.06093
 7538 | 7538_francs | 2024-06-09 23:42:43.060938
(2 rows)
```

7. 获取元命令对应的SQL代码

psql提供的元命令实质上向数据库发出相应的SQL查询，当使用psql连接数据库时，-E选项可用获取命令的SQL代码。

```apl
[root@pgsql ~]# psql -E mydb postgres
psql (15.5)
Type "help" for help.

mydb=# \db;
********* QUERY **********
SELECT spcname AS "Name",
  pg_catalog.pg_get_userbyid(spcowner) AS "Owner",
  pg_catalog.pg_tablespace_location(oid) AS "Location"
FROM pg_catalog.pg_tablespace
ORDER BY 1;
**************************

             List of tablespaces
    Name    |  Owner   |       Location
------------+----------+----------------------
 pg_default | postgres |
 pg_global  | postgres |
 tbs_mydb   | pguser   | /data/pg-15/tbs_mydb
(3 rows)
```

8. \?元命令

当忘记具体的命令名称可用查询手册

```apl
mydb=# \?
General
  \copyright             show PostgreSQL usage and distribution terms
  \crosstabview [COLUMNS] execute query and display result in crosstab
  \errverbose            show most recent error message at maximum verbosity
  \g [(OPTIONS)] [FILE]  execute query (and send result to file or |pipe);
                         \g with no arguments is equivalent to a semicolon
  \gdesc                 describe result of query, without executing it
  \gexec                 execute query, then execute each value in its result
  \gset [PREFIX]         execute query and store result in psql variables
  \gx [(OPTIONS)] [FILE] as \g, but forces expanded output mode
  \q                     quit psql
  \watch [SEC]           execute query every SEC seconds

Help
  \? [commands]          show help on backslash commands
  \? options             show help on psql command-line options
  \? variables           show help on special variables

```

9. 便捷的HELP命令

使用元命令\h后接SQL命令关键字能将sql命令的语法列车，对日常的数据库管理带来方便。

```apl
mydb=# \h create tablespace
Command:     CREATE TABLESPACE
Description: define a new tablespace
Syntax:
CREATE TABLESPACE tablespace_name
    [ OWNER { new_owner | CURRENT_ROLE | CURRENT_USER | SESSION_USER } ]
    LOCATION 'directory'
    [ WITH ( tablespace_option = value [, ... ] ) ]

URL: https://www.postgresql.org/docs/15/sql-createtablespace.html
```

### 2.2.3 psql导入、导出表数据

- psql支持文件数据导入到数据库，也支持数据库表数据导出到文件中。COPY命令和\copy命令都支持
  - COPY命令是SQL命令，\copy是元命令
  - COPY命令具有SUPERUSER超级权限(将数据通过stdin、stdout)方式导入导出情况除外),而 \copy元命令不是SUPERUSER权限
  - COPY命令读取和写入数据库服务端主机上的文件，而\copy元命令是从psql客户端主机读取或写入文件。

1. 使用COPY命令导入导出数据

   先来看看COPY命令如何将文本文件数据导入到数据库表中，首先在mydb库中创建测试表test_copy

   ```apl
   mydb=# create table test_copy(id int4,name text);
   CREATE TABLE
   ```

   编写数据文件test_copy_in.txt字段分隔符用TAB键，也可用设置其他分隔符，导入再指定已设置的字段分割符号

   ```apl
   [root@pgsql scripts]# ls
   [root@pgsql scripts]# pwd
   /data/scripts
   [root@pgsql scripts]# vim test_copy_in.txt
   [root@pgsql scripts]# cat test_copy_in.txt
   1       a
   2       b
   3       c
   sudo chown postgres:postgres /data/scripts/test_copy_in.txt
   sudo chmod 644 /data/scripts/test_copy_in.txt
   ```

   之后根据postgres用户登录mydb数据库，并将test_copy_in.txt文件中的数据导入到test_copy表中。

   ```apl
   mydb=# \dt public.test_copy
              List of relations
    Schema |   Name    | Type  |  Owner
   --------+-----------+-------+----------
    public | test_copy | table | postgres
   (1 row)
   
   mydb=# \dt
              List of relations
    Schema |   Name    | Type  |  Owner
   --------+-----------+-------+----------
    public | table_1   | table | postgres
    public | test_1    | table | postgres
    public | test_copy | table | postgres
   (3 rows)
   
   mydb=# COPY public.test_copy FROM '/data/scripts/test_copy_in.txt';
   COPY 3
   mydb=# select * from public.test_copy;
    id | name
   ----+------
     1 | a
     2 | b
     3 | c
   (3 rows)
   ```

   如果使用普通用户pguser导入文件数据，则报错

   ```apl
   [root@pgsql scripts]# psql -U postgres -d mydb
   psql (15.5)
   Type "help" for help.
   
   mydb=# ALTER ROLE pguser LOGIN;
   ALTER ROLE
   
   [root@pgsql scripts]# psql mydb pguser
   psql (15.5)
   Type "help" for help.
   
   mydb=> COPY public.test_copy FROM '/data/scripts/test_copy_in.txt';
   2024-06-10 00:57:07.055 CST [1961] ERROR:  must be superuser or have privileges of the pg_read_server_files role to COPY from a file
   2024-06-10 00:57:07.055 CST [1961] HINT:  Anyone can COPY to stdout or from stdin. psql's \copy command also works for anyone.
   2024-06-10 00:57:07.055 CST [1961] STATEMENT:  COPY public.test_copy FROM '/data/scripts/test_copy_in.txt';
   ERROR:  must be superuser or have privileges of the pg_read_server_files role to COPY from a file
   HINT:  Anyone can COPY to stdout or from stdin. psql's \copy command also works for anyone.
   ##提示需要使用超级用户而\copy元命令普通用户即可使用。
   ```

   COPY将表test_copy中的数据导出到文件，同样使用postgres用户

   ```apl
   [root@pgsql scripts]# cat test_copy_in.txt
   1       a
   2       b
   3       c
   [root@pgsql scripts]# psql mydb postgres
   psql (15.5)
   Type "help" for help.
   
   mydb=# copy public.test_copy TO '/data/scripts/test_copy_in.txt'
   mydb-# ;
   COPY 15
   mydb=# exit
   [root@pgsql scripts]# cat test_copy_in.txt
   1       a
   2       b
   3       c
   1       a
   2       b
   3       c
   1       a
   2       b
   3       c
   1       a
   2       b
   3       c
   1       a
   2       b
   3       c
   ```

   也可以将表数据输出到表中输出，不需要超级用户权限

   ```apl
   [root@pgsql scripts]# psql mydb pguser
   psql (15.5)
   Type "help" for help.
   
   mydb=> copy test_copy TO stdout;
   1       a
   2       b
   3       c
   1       a
   2       b
   3       c
   1       a
   2       b
   3       c
   1       a
   2       b
   3       c
   1       a
   2       b
   3       c
   ```

2. 导出为csv格式

   将数据导出为csv格式，并且with csv header 是指导出格式为csv，并显示字段名称，可用使用ofice execl打开。

   ```apl
   mydb=# COPY public.test_copy TO '/data/scripts/test_copy.csv' with csv header;
   COPY 15
   ```

3. 筛选导出ID为1的数据记录

   ```apl
   mydb=# COPY (SELECT * FROM public.test_copy where id=1) to '/data/scripts/test_copy2.csv' with csv header;
   COPY 5
   mydb=# exit
   [root@pgsql scripts]# cat test_copy2.csv
   id,name
   1,a
   1,a
   1,a
   1,a
   1,a
   ```

4. \COPY元命令导入导出数据

   如果需要导出小表数据，通过\copy元命令，如果是大表则使用主机COPY命令，效率更高。

   COPY命令是从数据库服务端主机读取或写入文件数据，并且\copy不需要超级用户权限

   ```apl
   mydb=> DELETE FROM public.test_copy;
   DELETE 15
   mydb=> \copy public.test_copy FROM '/data/scripts/test_copy.csv' CSV HEADER;
   COPY 15
   mydb=> \q
   [root@pgsql scripts]# cat test_copy2.csv
   [root@pgsql scripts]# psql mydb pguser
   psql (15.5)
   Type "help" for help.
   
   mydb=> \copy public.test_copy to '/data/scripts/test_copy2.csv' CSV HEADER;
   COPY 15
   mydb=> \q
   [root@pgsql scripts]# cat test_copy2.csv
   id,name
   1,a
   2,b
   3,c
   1,a
   2,b
   3,c
   1,a
   2,b
   3,c
   1,a
   2,b
   3,c
   1,a
   2,b
   3,c
   ```

### 2.2.4 psql语法和选项介绍

1. -A 设置非对齐输出模式

   ```apl
   [root@pgsql scripts]# psql -c "SELECT * FROM test_1 where id=1" mydb postgres
    id |   name   |        create_time
   ----+----------+----------------------------
     1 | 1_francs | 2024-06-09 23:42:43.047825
   (1 row)
   ## 添加-A选项
   [root@pgsql scripts]# psql -A -c "SELECT * FROM test_1 where id=1" mydb postgres
   id|name|create_time
   1|1_francs|2024-06-09 23:42:43.047825
   (1 row)
   
   ```

2. -t 只现实记录数据

   注意：通常-A和-t一起使用因为单独-t每个字段后空格无法省略。通过添加-A就可以去除空格

   ```apl
   [root@pgsql scripts]# psql -t -c  "SELECT * FROM test_1 where id=1" mydb postgres
     1 | 1_francs | 2024-06-09 23:42:43.047825
   [root@pgsql scripts]# psql -At -c  "SELECT * FROM test_1 where id=1" mydb postgres
   1|1_francs|2024-06-09 23:42:43.047825
   ```

3. -q不显示输出信息

   ![image-20240609173849453](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240609173849453.png?raw=true)

### 2.2.5psql执行sql脚本

-c 支持在操作系统层面通过psql向数据库发起sql命令

```apl
[root@pgsql scripts]# psql -c "select current_user;" -U postgres
 current_user
--------------
 postgres
(1 row)
[root@pgsql scripts]# psql -At -c "select current_user;" -U postgres
postgres
```

通过-f选项导入脚本

```apl
[root@pgsql scripts]# cat test_2.sql
create table test_2(id int4);
insert into test_2 values (1);
insert into test_2 values (2);
insert into test_2 values (3);
[root@pgsql scripts]# psql mydb postgres -f test_2.sql
CREATE TABLE
INSERT 0 1
INSERT 0 1
INSERT 0 1
```

### 2.2.6 psql如何传递变量到SQL

1. \set元命令方式传递变量

   ```apl
   mydb=# \set name value
   mydb=# \set v_id 2
   mydb=# select * from test_copy where id=:v_id
   mydb-# ;
    id | name
   ----+------
     2 | b
   ```

   取消之前设置的变量值，\set 命令后，参数名即可

   ```apl
   mydb=# \set v_id
   ```

2. psql的-v参数传递变量：查询id为1的行数

   通过-v参数传递变量，首先编写select_1.sql脚本

   ```apl
   [root@pgsql scripts]# cat select_1.sql
   select * from test_copy where id=:v_id;
   [root@pgsql scripts]# psql -v v_id=1 mydb postgres -f select_1.sql
    id | name
   ----+------
     1 | a
     1 | a
     1 | a
     1 | a
     1 | a
   (5 rows)
   
   ```

#### 2.2.7 使用sql定制日常维护脚本

1. 定制维护脚本，查询活动会话

   - .psqlrc文件，如果psql没有带-X选项，psql尝试读取和执行用户~/.psqlrc启动文件中的命令，结合这个文件预先定制维护脚本。例如查询活动会话的SQL
   - PID：指进程号
   - usename：指数据库用户名称
   - datname：指数据库名称
   - query：显示进程最近执行的SQL
   - state：为active则query显示当前执行的sql
     - active：后台进程正在执行
     - idle：后台进程为空闲状态，等待后续客户端发出命令
     - idle in transaction：后台进程正在事物中，并不是指正在执行SQL
     - idle in transaction(aborted)：类似上面一个，只是事物中的部分SQL异常。
   - client_addr是进程的客户端IP

   ```apl
   mydb=# select * from pg_stat_activity limit 1;
   
   mydb=# 
    pid  | usename  | datname |                                query                                 | client_addr
   ------+----------+---------+----------------------------------------------------------------------+-------------
    1652 |          |         |                                                                      |
    1653 | postgres |         |                                                                      |
    2232 | postgres | mydb    | select pid,usename,datname,query,client_addr from pg_stat_activity ; |
    1649 |          |         |                                                                      |
    1648 |          |         |                                                                      |
    1651 |          |         |                                                                      |
   (6 rows)
   ```

- 之后，重新连接数据库，执行active_session命令，冒号后边接变量名即可

  ```apl
  [root@pgsql ~]# pwd
  /root
  [root@pgsql ~]# cat .psqlrc
  \set active_session 'select pid,usename,datname,query,client_addr from pg_stat_activity where pid <> pg_backend_pid () and state=\'active\' order by query;';
  
  [root@pgsql ~]# psql -U postgres -d mydb
  psql (15.5)
  Type "help" for help.
  
  mydb=# :active_session
   pid | usename | datname | query | client_addr
  -----+---------+---------+-------+-------------
  (0 rows)
  ```

2. 定制维护脚本：查询等待事件

   PostgreSQL也有等待事件的概念，对于问题诊断有较大的参考作用，查询等待事件SQL

   查看会话等待事件

   ```apl
   [root@pgsql ~]# cat .psqlrc
   \set active_session 'select pid,usename,datname,query,client_addr from pg_stat_activity where pid <> pg_backend_pid () and state=\'active\' order by query;';
   \set wait_event  'SELECT pid, usename, datname, query, client_addr, wait_event_type, wait_event FROM pg_stat_activity WHERE pid <> pg_backend_pid() AND wait_event IS NOT NULL ORDER BY wait_event_type;'
   
   [root@pgsql ~]# psql -U postgres -d mydb
   psql (15.5)
   Type "help" for help.
   
   mydb=# :wait_event
    pid  | usename  | datname | query | client_addr | wait_event_type |     wait_event
   ------+----------+---------+-------+-------------+-----------------+---------------------
    1652 |          |         |       |             | Activity        | AutoVacuumMain
    1653 | postgres |         |       |             | Activity        | LogicalLauncherMain
    1649 |          |         |       |             | Activity        | BgWriterHibernate
    1648 |          |         |       |             | Activity        | CheckpointerMain
    1651 |          |         |       |             | Activity        | WalWriterMain
   (5 rows)
   ```

   查看连接数

   ```apl
   [root@pgsql ~]# cat .psqlrc
   \set connections  'SELECT datname, usename, client_addr, count(*) FROM pg_stat_activity WHERE pid <> pg_backend_pid() GROUP BY 1, 2, 3 ORDER BY 1, 4 DESC;'
   mydb=# :connections
    datname | usename  | client_addr | count
   ---------+----------+-------------+-------
            |          |             |     4
            | postgres |             |     1
   (2 rows)
   ```

   

   1. **条件 1: `pid <> pg_backend_pid()`**：
      - `pid` 是 `pg_stat_activity` 表中的列，表示每个活动会话的进程 ID。
      - `pg_backend_pid()` 是一个 PostgreSQL 内置函数，用于获取当前会话的后端进程 ID。
      - `pid <> pg_backend_pid()` 表示选择那些进程 ID 不等于当前后端进程 ID 的行。这个条件确保查询不会返回当前执行查询的会话自身的信息。
   2. **条件 2: `wait_event IS NOT NULL`**：
      - `wait_event` 是 `pg_stat_activity` 表中的列，它表示当前会话正在等待的事件类型。
      - `IS NOT NULL` 是一个条件运算符，用于检查列的值是否不为 `NULL`。
      - `wait_event IS NOT NULL` 表示选择那些等待事件不为空的会话。这个条件确保只返回正在等待某种事件的活动会话信息。

   ### ORDER BY 子句解释：

   - ORDER BY 子句

     ：

     - `ORDER BY` 子句用于对查询结果进行排序。在您的查询中，`ORDER BY wait_event_type` 表示按照 `wait_event_type` 列的值对结果进行升序排序。
     - `wait_event_type` 是 `pg_stat_activity` 表中的列，表示当前会话正在等待的事件的类型。
     - `ORDER BY 1`: 结果集会首先按照数据库名称 (`datname`) 的字母顺序进行升序排列。
     - `ORDER BY 4 DESC`: 如果有多行具有相同的 `datname`，那么这些行会按照它们的 `count(*)` 的值进行降序排列。也就是说，在每个数据库名称组合下，会把拥有最多连接数的会话放在前面。

### 2.2.8 psql亮点功能

1. \timing显示SQL执行时间

   ```apl
   mydb=# \timing
   Timing is on.
   mydb=# select count(*) FROM test_copy ;
    count
   -------
       15
   (1 row)
   
   Time: 0.555 ms
   ```

   以上显示count语句执行的时间为0.5毫秒，如果需要关闭再次执行\timing元命令即可

   ```apl
   mydb=# \timing
   Timing is on.
   mydb=# select count(*) FROM test_copy ;
    count
   -------
       15
   (1 row)
   
   Time: 0.555 ms
   mydb=# \timing
   Timing is off.
   ```

2. \watch反复执行当前sql

   \watch 元命令会反复执行当前查询缓冲区的SQL命令，知道SQL被中止或失败

   语法：

   \watch [ seconds ]

   seconds表示两次执行间隔的时间，以秒为单位，默认为2秒，例如每个一秒反复执行now()函数查询当前时间

   ```apl
   mydb=# select now();
                 now
   -------------------------------
    2024-06-10 03:17:45.571675+08
   (1 row)
   
   mydb=# \watch 1
   2024年06月10日 星期一 03时17分51秒 (every 1s)
   
                now
   ------------------------------
    2024-06-10 03:17:51.51207+08
   (1 row)
   
   2024年06月10日 星期一 03时17分52秒 (every 1s)
   
                 now
   -------------------------------
    2024-06-10 03:17:52.512406+08
   (1 row)
   
   2024年06月10日 星期一 03时17分53秒 (every 1s)
   
                 now
   -------------------------------
    2024-06-10 03:17:53.512246+08
   (1 row)
   ```

3. 客户端提示符

   以下命令显示了psql客户端提示符“postgresql=#”是默认的客户端提示符

   ```apl
   [root@pgsql ~]# psql -U postgres
   psql (15.5)
   Type "help" for help.
   
   postgres=#
   
   ```

   可用根据喜好设置psql客户端提示符

   %M：数据库服务器别名，不是指主机名，显示的是psql的-h参数设置的值；当连接建立在Unix域套接字上时则是[local]

   %>：数据库服务器的端口号

   %n：数据库会话的用户名，在数据库会话期间，这个值可能会应为命令SET SESSIONAUTHORIZATION的结构而改变。

   %/：当前数据库名称。

   %#：如果是超级用户则显示“#”，其他用户“>"

   %p：当前数据库连接的后台进程号。

   %R：在PROMPT1中通常显示”=“如果进程被断开则显示”！“

   ```
   postgres=# \echo :PROMPT1
   %/%R%x%#
   
   postgres=# \set PROMPT1 '%M%R%#'
   [local]=#
   
   ```

   在pghost1远程pghost2主机设置PROMPT1变量值为 "%M%R%#"

   ```apl
   [root@pgsql ~]# psql -U postgres -h 192.168.71.11
   Password for user postgres:
   psql (15.5)
   Type "help" for help.
   
   postgres=# \set PROMPT1 '%M%R%#'
   192.168.71.11=#
   
   [root@pgsql ~]# psql -U pguser -h 192.168.71.11 -d mydb
   Password for user pguser:
   psql (15.5)
   Type "help" for help.
   
   mydb=# \set PROMPT1 '%/@%M%R%#'
   mydb@192.168.71.11=#
   
   ```

   将PROMPT1设置为"%/@%M:%>%R%#"

   ```apl
   [root@pgsql ~]# cat .psqlrc
   \set PROMPT1 '%/@%M:%>%R%#'
   
   [root@pgsql ~]# psql -U pguser -h 192.168.71.11 mydb -p 1921
   Password for user pguser:
   psql (15.5)
   Type "help" for help.
   
   mydb@192.168.71.11:1921=#
   ```

# 第三章 数据类型

## 3.1数字类型

- PostgreSQL支持的数据类型有整数类型，用户指定精度类型、浮点类型、serial类型

### 3.1.1数字类型列表

| 类型名称         | 存储长度 | 描述           | 范围                                                     |
| ---------------- | -------- | -------------- | -------------------------------------------------------- |
| smallint         | 2 字节   | 小范围整数类型 | -32,768 到 +32,767                                       |
| integer          | 4 字节   | 整数类型       | -2,147,483,648 到 +2,147,483,647                         |
| bigint           | 8 字节   | 大范围整数类型 | -9,223,372,036,854,775,808 到 +9,223,372,036,854,775,807 |
| decimal          | 可变     | 用户指定精度   | 小数点前 131,072 位；小数点后 16,383 位                  |
| numeric          | 可变     | 用户指定精度   | 小数点前 131,072 位；小数点后 16,383 位                  |
| real             | 4 字节   | 变长，不精确   | 6 位十进制精度                                           |
| double precision | 8 字节   | 变长，不精确   | 15 位十进制精度                                          |

- smallint、integer、bigint都是整数类型，存储一定范围的整数，超出范围将报错。
- smallint存储2字节整数，字段定义时可以写成int2，integer存储4字节整数，支持的数值范围比smallint大，字段写成int4，是最常用的整数类型，bigint存储8字节整数，支持的发呢我i比integer大，写成int8.

| 类型名称         | 存储长度 | 描述           | 范围                                                     |
| ---------------- | -------- | -------------- | -------------------------------------------------------- |
| smallint         | 2 字节   | 小范围整数类型 | -32,768 到 +32,767                                       |
| integer          | 4 字节   | 整数类型       | -2,147,483,648 到 +2,147,483,647                         |
| bigint           | 8 字节   | 大范围整数类型 | -9,223,372,036,854,775,808 到 +9,223,372,036,854,775,807 |
| decimal          | 可变     | 用户指定精度   | 小数点前 131,072 位；小数点后 16,383 位                  |
| numeric          | 可变     | 用户指定精度   | 小数点前 131,072 位；小数点后 16,383 位                  |
| real             | 4 字节   | 变长，不精确   | 6 位十进制精度                                           |
| double precision | 8 字节   | 变长，不精确   | 15 位十进制精度                                          |

### 其他数据类型

| 类型名称    | 存储长度 | 描述              | 范围                           |
| ----------- | -------- | ----------------- | ------------------------------ |
| smallserial | 2 字节   | smallint 自增序列 | 1 到 32,767                    |
| serial      | 4 字节   | integer 自增序列  | 1 到 2,147,483,647             |
| bigserial   | 8 字节   | bigint 自增序列   | 1 到 9,223,372,036,854,775,807 |

定义一张使用integer类型的表：

```apl
mydb@192.168.71.11:1921=#create table test_integer (id1 integer,id2 int4);
CREATE TABLE
```

- decimal和numeric是等效的，可以存储指定精度的多位数据，比如小数位的数据和要求计算精度的运算

  precision是指numeric数字里面的所有数字，scale是指小数为，比如：

  18.222，precision=5为，scale=3位，numeric类型运算相比整数类型性能低些

- real和double precision是指浮点数据类型，real支持4字节，double precision支持8字节。

- smallserial、serial和bigserial类型是指自增serial类型，严格意义上不能称之为一种数据类型

  ```apl
  mydb@192.168.71.11:1921=#create table test_serial (id serial,falg text);
  CREATE TABLE
  ```

  查看test_serial的表结构

  ```apl
  mydb@192.168.71.11:1921=#\d test_serial
                              Table "public.test_serial"
   Column |  Type   | Collation | Nullable |                 Default
  --------+---------+-----------+----------+-----------------------------------------
   id     | integer |           | not null | nextval('test_serial_id_seq'::regclass)
   falg   | text    |           |          |
  ```

  以上显示id字段使用了序列test_serial_id_seq,插入表数据时可以不指定serial字段名称，将自动使用序列值填充

  ```apl
  mydb@192.168.71.11:1921=#\d test_serial
                              Table "public.test_serial"
   Column |  Type   | Collation | Nullable |                 Default
  --------+---------+-----------+----------+-----------------------------------------
   id     | integer |           | not null | nextval('test_serial_id_seq'::regclass)
   falg   | text    |           |          |
  
  mydb@192.168.71.11:1921=#insert into test_serial(falg) values ('a');
  mydb@192.168.71.11:1921=#insert into test_serial(falg) values ('a');
  INSERT 0 1
  mydb@192.168.71.11:1921=#insert into test_serial(falg) values ('b');
  INSERT 0 1
  mydb@192.168.71.11:1921=#insert into test_serial(falg) values ('c');
  INSERT 0 1
  mydb@192.168.71.11:1921=#select * from test_serial
  ;
   id | falg
  ----+------
    1 | a
    2 | b
    3 | c
  (3 rows)
  ```

### 3.1.2 数字类型操作符和数学函数

- PostgreSQL支持数字类型操作和丰富的数学函数，列入：加、减、乘、除

  ```apl
  mydb@192.168.71.11:1921=#select 1+2,2*3,4/2,8%3,22*2;
   ?column? | ?column? | ?column? | ?column? | ?column?
  ----------+----------+----------+----------+----------
          3 |        6 |        2 |        2 |       44
  (1 row)
  ```

  按模取余8除3余2

  ```apl
  mydb@192.168.71.11:1921=#select mod(8,3);
   mod
  -----
     2
  ```

  四舍五入函数如下：

  ```apl
  mydb@192.168.71.11:1921=#select round(10.2),round(10.9);
   round | round
  -------+-------
      10 |    11
  (1 row)
  ```

  返回大于或等于给出参数的最小整数

  ```apl
  mydb@192.168.71.11:1921=#select ceil(3.6),ceil(-3.6);
   ceil | ceil
  ------+------
      4 |   -3
  ```

  返回小于或等于给出参数的最大整数

  ```apl
  mydb@192.168.71.11:1921=#select floor(3.6),floor(-3.6);
   floor | floor
  -------+-------
       3 |    -4
  ```

## 3.2字符类型

- PostgreSQL支持的字符类型，并且介绍常用的字符类型函数。

### 3.2.1字符类型列表

| 字符类型名称                     | 描述                                   |
| -------------------------------- | -------------------------------------- |
| character varying(n), varchar(n) | 变长，字符最大数有限制                 |
| character(n), char(n)            | 定长，字符数没达到最大值则使用空白填充 |
| text                             | 变长，无长度限制                       |

character varying(n) 存储的是变长字符类型，n是一个正整数，如果存储的字符串长度超出n则报错：如果存储的字符串比n小，character varying(n)进存储实际位数，如何小则用空格填充。

```apl
mydb@192.168.71.11:1921=#create table test_char(coll varchar(4),coll2 character(4));
CREATE TABLE
INSERT 0 1
```

表test_char的字段coll类型为character varying(4),col2类型为character(4),接下来计算两个字段值的字符串长度。

```apl
mydb@192.168.71.11:1921=#select char_length(coll),char_length(coll2) FROM test_char;
 char_length | char_length
-------------+-------------
           1 |           1
(1 row)
```

char_length(string)显示字符串字符数，从上面结果可以看出字符串长度为1，接着查看两字段实际占用物理空间大小。

```apl
mydb@192.168.71.11:1921=#select octet_length(coll),octet_length(coll2) FROM test_char ;
 octet_length | octet_length
--------------+--------------
            1 |            4
(1 row)
```

test字符类型存储任意长度的字符串，和没有声明字符长度的character varying类型几乎没有差别。

### 3.2.2 字符类型函数

- PostgreSQL支持丰富的字符函数

- 字符数：char_length

  ```apl
  mydb@192.168.71.11:1921=#select char_length('a释');
   char_length
  -------------
             2
  ```

- 字节数：octet_length

  ```apl
  mydb@192.168.71.11:1921=#select octet_length('a释');
   octet_length
  --------------
              4
  ```

- 指定字符在字符串的位置：position

  ```apl
  mydb@192.168.71.11:1921=#select position('a' in 'bacd');
   position
  ----------
          2
  ```

- 提前字符串中的子串

  ```apl
  mydb@192.168.71.11:1921=#select substring('franc释放' from 3 for 5);
   substring
  -----------
   anc释放
  ```

- 拆分字符串，split_part

  ```apl
  mydb@192.168.71.11:1921=#select split_part('abc@def1@cnb','@',2);
   split_part
  ------------
   def1
  
  mydb@192.168.71.11:1921=#select split_part('abc@def1@cnb','c',2);
   split_part
  ------------
   @def1@
  ```

## 3.3时间/日期类型

PostgreSQL对时间、日期数据类型支持丰富灵活。

### 3.3.1 时间/日期类型列表

| 字符类型名称                        | 存储长度 | 描述                                       |
| ----------------------------------- | -------- | ------------------------------------------ |
| timestamp [(p)] [without time zone] | 8 字节   | 包括日期和时间，不带时区，简写成 timestamp |
| timestamp [(p)] with time zone      | 8 字节   | 包括日期和时间，带时区，简写成 timestamptz |
| date                                | 4 字节   | 日期，但不包含一天中的时间                 |
| time [(p)] [without time zone]      | 8 字节   | 一天中的时间，不包含日期，不带时区         |
| time [(p)] with time zone           | 12 字节  | 一天中的时间，不包含日期，带时区           |
| interval [fields] [(p)]             | 16 字节  | 时间间隔                                   |

- 系统自带的now()

  ```apl
  mydb@192.168.71.11:1921=#select now();
                now
  -------------------------------
   2024-06-10 08:59:00.716041+08
  ```

- timestamp和timestamptz

  ```apl
  mydb@192.168.71.11:1921=#select now()::timestamp;
              now
  ----------------------------
   2024-06-10 09:01:18.417413
  
  mydb@192.168.71.11:1921=#select now()::timestamp without time zone;
              now
  ----------------------------
   2024-06-10 09:01:20.374325
  
  mydb@192.168.71.11:1921=#select now()::timestamp with time zone;
  mydb@192.168.71.11:1921=#select now()::timestamptz;
                now
  -------------------------------
   2024-06-10 09:01:52.010901+08
  ```

  转换成data格式

  ```apl
  mydb@192.168.71.11:1921=#select now()::date;
      now
  ------------
   2024-06-10
  ```

  转换成time with time zone格式

  ```apl
  mydb@192.168.71.11:1921=#select now()::time without time zone;
         now
  -----------------
   09:05:47.112888
  
  mydb@192.168.71.11:1921=#select now()::time with time zone;
          now
  --------------------
   09:05:48.801075+08
  
  mydb@192.168.71.11:1921=#select now()::timetz;
          now
  --------------------
   09:05:59.646271+08
  
  ```

  interval指时间间隔，间隔单位可以是hour、day、month、year等

  ```apl
  mydb@192.168.71.11:1921=#select now(),now()+interval'1 day';
                now              |           ?column?
  -------------------------------+-------------------------------
   2024-06-10 09:10:05.685558+08 | 2024-06-11 09:10:05.685558+08
  (1 row)
  ```

  没声明精度默认值

  ```apl
  mydb@192.168.71.11:1921=#select now(),now()::timestamp(0);
                now              |         now
  -------------------------------+---------------------
   2024-06-10 09:12:03.945239+08 | 2024-06-10 09:12:04
  ```

### 3.3.2 时间/日期类型操作符

- 时间、日期数据类型支持的操作符有加减乘除

  ```apl
  mydb@192.168.71.11:1921=#select date '2017-07-29' + interval '1 days,1 year';
        ?column?
  ---------------------
   2018-07-30 00:00:00
  ```

- 日期相乘

  ```apl
  mydb@192.168.71.11:1921=#select 100* interval '1 second';
   ?column?
  ----------
   00:01:40
  ```

- 日期相除

  ```apl
  mydb@192.168.71.11:1921=#select interval '1 hour' / double precision '3';
   ?column?
  ----------
   00:20:00
  ```

### 3.3.3 日期/日期类型常用函数

- 显示当前时间、日期常用函数

  ```apl
  mydb@192.168.71.11:1921=#select current_date,current_time;
   current_date |    current_time
  --------------+--------------------
   2024-06-10   | 09:23:54.679631+08
  ```

  ![image-20240610012451176](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240610012451176.png?raw=true)

  ```apl
  mydb@192.168.71.11:1921=#select extract(year from now());
   extract
  ---------
      2024
  ```

- 对于timestamp类型，取月份和月份里的第几天

  ```apl
  mydb@192.168.71.11:1921=#select extract(month from now()),extract(day from now());
   extract | extract
  ---------+---------
         6 |      10
  ```

- 取小时、分钟

  ```apl
  mydb@192.168.71.11:1921=#select extract( hour from now()),extract(minute from now());
   extract | extract
  ---------+---------
         9 |      28
  ```

- 取秒

  ```apl
  mydb@192.168.71.11:1921=#select extract(second from now());
   extract
  ----------
   9.786804
  ```

- 取当前日期所在年份中第几周

  ```apl
  mydb@192.168.71.11:1921=#select extract(week from now());
   extract
  ---------
        24
  ```

- 当天属于当年的第几天

  ```apl
  mydb@192.168.71.11:1921=#select now();
                now
  -------------------------------
   2024-06-10 09:32:39.584523+08
  
  mydb@192.168.71.11:1921=#select extract(doy from now());
   extract
  ---------
       162
  
  ```

## 3.4布尔类型

- PostgreSQL还支持很多非常规数据类型，比如布尔类型、网络地址类型、数组类型、范围类型、json/isonb类型等，从这一节开始将介绍PostgreSQL支持的非常规数据类型，本节介绍布尔类型，PostgreSQL支持的布尔类

| 字符类型名称 | 存储长度 | 描述              |
| ------------ | -------- | ----------------- |
| boolean      | 1字节    | 状态为true或false |

true状态的有效值可以是TRUE、t、true、y、yes、on、1、false状态的有效值FALSE、f、false、n、no、off、0

```apl
mydb@192.168.71.11:1921=#create table test_boolean(cola boolean,colb boolean);
CREATE TABLE

mydb@192.168.71.11:1921=#insert into test_boolean (cola,colb) values ('true','false');

INSERT 0 1
mydb@192.168.71.11:1921=#insert into test_boolean (cola,colb) values ('t','f');

INSERT 0 1
mydb@192.168.71.11:1921=#insert into test_boolean (cola,colb) values ('TRUE','FALSE');

INSERT 0 1
mydb@192.168.71.11:1921=#insert into test_boolean (cola,colb) values ('yes','no');

INSERT 0 1                                                       ^
mydb@192.168.71.11:1921=#insert into test_boolean (cola,colb) values ('1','0');

INSERT 0 1                                                    ^
mydb@192.168.71.11:1921=#insert into test_boolean (cola,colb) values (null,null);
INSERT 0 1

```

```apl
mydb@192.168.71.11:1921=#select * from test_boolean;
 cola | colb
------+------
 t    | f
 t    | f
 t    | f
 t    | f
 t    | f
      |
```

## 3.5 网络地址类型

- 当有存储IP地址需求的业务场景时，postgresql提供用于ipv4、ipv6、mac网络地址的转有网络地址数据类型，使用网络地址数据类型存储IP地址要由于字符类型，因为网络地址类型一方面会对数据合法性进行检查，另一方面也提供了网络数据类型操作和函数方便应用程序开发

### 3.5.1网络地址类型列表

| 字符类型名称 | 存储长度     | 描述                   |
| ------------ | ------------ | ---------------------- |
| cidr         | 7 或 19 字节 | IPv4 和 IPv6 网络      |
| inet         | 7 或 19 字节 | IPv4 和 IPv6 网络      |
| macaddr      | 6 字节       | MAC 地址               |
| macaddr8     | 8 字节       | MAC 地址 (EUI-64 格式) |

- inet和cidr类型存储的网络地址格式为address/y,其中address表示ipv4或ipv6网络地址，y表示网络掩码位数，如果省略y，则表示ipv4掩码为32为，对于ipv6为128，所以改该值表示一台主机

  ![image-20240610015429951](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240610015429951.png?raw=true)

inet和cid网络类型存在一下差别

1. cidr类型输出默认带子网掩码，而inet不一定。

```apl
mydb@192.168.71.11:1921=#select '192.168.1.100'::inet;
     inet
---------------
 192.168.1.100
(1 row)

mydb@192.168.71.11:1921=#select '192.168.1.100/32'::inet;
     inet
---------------
 192.168.1.100
(1 row)

mydb@192.168.71.11:1921=#select '192.168.1.100/16'::inet;
       inet
------------------
 192.168.1.100/16
(1 row)
```

2. cidr类型对IP地址和子网掩码合法性进行检查，inet不会

```apl
mydb@192.168.71.11:1921=#select '192.168.2.0/8'::cidr;
ERROR:  invalid cidr value: "192.168.2.0/8"
LINE 1: select '192.168.2.0/8'::cidr;
               ^
DETAIL:  Value has bits set to right of mask.

mydb@192.168.71.11:1921=#select '192.168.2.0/8'::inet;
     inet
---------------
 192.168.2.0/8
 
 mydb@192.168.71.11:1921=#select '192.168.2.0/24'::inet;
      inet
----------------
 192.168.2.0/24
```

- 因此，从这个层面来说cidr比inet网络类型更严谨。

### 3.5.2 网络地址操作符

![image-20240610020144165](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240610020144165.png?raw=true)

### 3.5.3网络地址函数

- PostgreSQL网络地址类型支持一系列函数

- 取IP地址，返回文本格式

  ```apl
  mydb@192.168.71.11:1921=#select host(cidr '192.168.1.0/24');
      host
  -------------
   192.168.1.0
  ```

- 取IP地址和网络掩码，返回文本格式

  ```apl
  mydb@192.168.71.11:1921=#select text(cidr '192.168.1.0/24');
        text
  ----------------
   192.168.1.0/24
  ```

- 取网络地址和子网掩码，返回文本格式

  ```apl
  mydb@192.168.71.11:1921=#select netmask(cidr '192.168.1.0/24');
      netmask
  ---------------
   255.255.255.0
  ```

## 3.6 数组类型

- PostgreSQL支持一系列数组和多数组，常用的数据类型为数字类型数组和字符型数组，也就是枚举类型，复合类型数组

### 3.6.1 数组类型定义

![image-20240610020701114](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240610020701114.png?raw=true)

```apl
mydb@192.168.71.11:1921=#create table test_array1 ( id integer,array_i integer[],array_t text[]);
CREATE TABLE
```

### 3.6.2 数据类型值输入

- 数组类型的插入有两种方式，第一种方式使用花括号方式

  ```apl
  ‘{vall delim val2 delim...}
  ```

- 将数组元素值用花括号“{}“包围并用delim分隔符分开，数组元素值可以用双引号引用，delim分隔符通常为逗号

  ```apl
  mydb@192.168.71.11:1921=#select '{1,2,3}';
   ?column?
  ----------
   {1,2,3}
  ```

- 往表test_array1中插入一条记录的代码

  ```apl
  mydb@192.168.71.11:1921=#insert into test_array1(id,array_i,array_t) values (1,'{1,2,3}','{"a","b","c"}');
  INSERT 0 1
  ```

- 数组类型插入的第二种方式为使用ARRAY关键字

  ```apl
  mydb@192.168.71.11:1921=#select array[1,2,3];
    array
  ---------
   {1,2,3}
  (1 row)
  ```

- 往test_array1表中插入另一条记录

  ```apl
  mydb@192.168.71.11:1921=#insert into test_array1 (id,array_i,array_t) values (2,array[4,5,6],array['d','e','f']);
  INSERT 0 1
  ```

- 表arrary1数据如下

  ```apl
  mydb@192.168.71.11:1921=#select * from test_array1
  ;
   id | array_i | array_t
  ----+---------+---------
    1 | {1,2,3} | {a,b,c}
    2 | {4,5,6} | {d,e,f}
  ```

### 3.6.3

查询数组元素

- 如果查询素组所有元素值，只需查询数组字段名即可

  ```apl
  mydb@192.168.71.11:1921=#select array_i from test_array1 where id=1;
   array_i
  ---------
   {1,2,3}
  ```

- 数组元素的引用通过方括号”[]"方式

  ```apl
  mydb@192.168.71.11:1921=#select array_i[1],array_t[3] from test_array1 where id=1;
   array_i | array_t
  ---------+---------
         1 | c
  (1 row)
  
  mydb@192.168.71.11:1921=#select * from test_array1
  ;
   id | array_i | array_t
  ----+---------+---------
    1 | {1,2,3} | {a,b,c}
    2 | {4,5,6} | {d,e,f}
  (2 rows)
  
  ```

### 3.6.4 数组元素的追加、删除、更新

- PostgreSQL数组类型支持数组元素的追加、删除与更新操作，数据元素的追加使用array_append

  ```apl
  array_append(anyarray,anyelement)
  ```

- array_append函数向数组末端加一个元素

  ```apl
  mydb@192.168.71.11:1921=#select array_append(array[1,2,3],4);
   array_append
  --------------
   {1,2,3,4}
  ```

- 数据元素最佳到数组也可以使用||

  ```apl
  mydb@192.168.71.11:1921=#select array[1,2,3] || 4;
   ?column?
  -----------
   {1,2,3,4}
  ```

- 数组元素的删除使用array_remove函数

  ```apl
  array_remove(anyarray,anylement)
  ```

- array_remove函数将移除函数中值等于给定值的所有数组元素

  ```apl
  mydb@192.168.71.11:1921=#select array[1,2,2,3],array_remove(array[1,2,2,3],2);
     array   | array_remove
  -----------+--------------
   {1,2,2,3} | {1,3}
  ```

- 数组元素的修改

  ```apl
  mydb@192.168.71.11:1921=#select * from test_array1 ;
   id | array_i | array_t
  ----+---------+---------
    1 | {1,2,3} | {a,b,c}
    2 | {4,5,6} | {d,e,f}
  (2 rows)
  
  mydb@192.168.71.11:1921=#update test_array1 set array_i[3]=4 where id=1;
  UPDATE 1
  mydb@192.168.71.11:1921=#select * from test_array1 ;
   id | array_i | array_t
  ----+---------+---------
   1 | {1,2,4} | {a,b,c}
   2 | {4,5,6} | {d,e,f}
  ```

- 真个数组也能被更新

  ```apl
  mydb@192.168.71.11:1921=#update test_array1 set array_i=array[7,8,9] where id =1;
  UPDATE 1
  mydb@192.168.71.11:1921=#select * from test_array1 ;
   id | array_i | array_t
  ----+---------+---------
    1 | {7,8,9} | {a,b,c}
    2 | {4,5,6} | {d,e,f}
  ```

### 3.6.5 数组操作符

![image-20240610023449649](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240610023449649.png?raw=true)

### 3.6.6数组函数

- PostgreSQL支持丰富的数组函数，给数组添加元素或删除元素

  ```apl
  mydb@192.168.71.11:1921=#select array_append(array[1,2,3],3),array_remove(array[1,2],2);
   array_append | array_remove
  --------------+--------------
   {1,2,3,3}    | {1}
  ```

- 获取数组维度

  ```apl
  mydb@192.168.71.11:1921=#select array_ndims(array[1,2]);
   array_ndims
  -------------
             1
  ```

- 获取数组长度

  ```apl
  mydb@192.168.71.11:1921=#select array_length(array[1,2],1);
   array_length
  --------------
              2
  ```

- 返回数组中某个数组元素第一次出现的位置

  ```apl
  mydb@192.168.71.11:1921=#select array_position(array['a','d','c','d','c'],'d');
   array_position
  ----------------
                2
  (1 row)
  
  mydb@192.168.71.11:1921=#select array_position(array['a','d','c','d','c'],'c');
   array_position
  ----------------
                3
  ```

## 3.7 范围类型

- 范围类型包含一个范围内的数据，常见的范围数据类型有日期范围类型、整数范围类型等，对于日期安排、价格范围应用场景比较适用。

### 3.7.1 范围类型列表

- PostgreSQL 系统提供内置的范围类型如下
  int4range--integer范围类型
  int8range--bigint 范围类型
  numrange--numeric范围类型
  --不带时区的timestamp范围类型tsrangetstzrange--带时区的timestamp范围类型
  daterange--date 范围类型

- 用户可以通过CREATE TYPE命令自定义范围数据类型，integer举例如下

  ```apl
  mydb@192.168.71.11:1921=#select int4range(1,5);
   int4range
  -----------
   [1,5)
  ```

- 以上定义 1到5的整数范围，date范围举例如下

  ```apl
  mydb@192.168.71.11:1921=#select daterange('2017-07-01','2017-07-30');
          daterange
  -------------------------
   [2017-07-01,2017-07-30)
  ```

### 3.7.2 范围类型边界

- 每一个范围类型都包含下界和上界，方括号“[”表示包含下界，圆括号“(”表示排除下界，方括号“]”表示包含上界，圆括号“)”表示排除上界，也就是说方括号表示边界点包含在内，圆括号表示边界点不包含在内，范围类型值的输人有以下几种模式:
  (lower-bound,upper-bound)
  (lower-bound,upper-bound]
  [lower-bound,upper-bound)
  [lower-bound,upper-bound]
  empty

- 主要empty表示空范围，不包含任何元素

  ```apl
  mydb@192.168.71.11:1921=#select int4range(4,7);
   int4range
  -----------
   [4,7)
  ```

- 以上表示包含4，5，6，但不包含7，表中的范围类型为下界包含同时上节排除如下：

  ```apl
  mydb@192.168.71.11:1921=#select int4range(1,3);
   int4range
  -----------
   [1,3)
  ```

- 以上没有指定数据类型边界模式，指定上界为“]"

  ```apl
  mydb@192.168.71.11:1921=#select int4range(1,3,'[]');
   int4range
  -----------
   [1,4)
  ```

### 3.7.3 范围类型操作

- 包含元素操作如下

  ```apl
  mydb@192.168.71.11:1921=#select int4range(4,7) @> 4;
   ?column?
  ----------
   t
  ```

- 包含范围操作符

  ```apl
  mydb@192.168.71.11:1921=#select int4range(4,7)@>int4range(4,6);
   ?column?
  ----------
   t
  ```

- 等于操作符

  ```apl
  mydb@192.168.71.11:1921=#select int4range(4,7)=int4range(4,6,'[]');
   ?column?
  ----------
   t
  (1 row)
  
  mydb@192.168.71.11:1921=#select int4range(4,7)=int4range(4,7,'[]');
   ?column?
  ----------
   f
  ```

- 其中@> 操作符在范围数据类型中比较常用，常用查询范围数据类型是否包含莫格指定元素。

### 3.7.4 范围类型函数

- 一下列举范围类型常用函数

- 区范围下界

  ```apl
  mydb@192.168.71.11:1921=#select lower(int4range(1,10));
   lower
  -------
       1
  ```

- 取范围类型上界

  ```apl
  mydb@192.168.71.11:1921=#select upper(int4range(1,10));
   upper
  -------
      10
  ```

- 范围是否为空

  ```apl
  mydb@192.168.71.11:1921=#select isempty(int4range(1,10));
   isempty
  ---------
   f
  ```

### 3.7.5 给范围类型创建索引

- 范围类型数据支持创建GiST索引，GiST索引支持的操作符有 = && <@  @>   <<  >>  -|-  &<  &>  

  ```apl
  create index idx_ip_address_range ON ip_address USING gist (ip_range);
  ```

## 3.8 json/sjonb类型

- PostgreSQL不只是一个关系数据库，同时还支持非关系数据库类型json（非常规化数据类型），本章介绍，json类型，json与jsonb差异，json与jsonb操作符和函数，以及jsonb键值的追加、删除、更新。

### 3.8.1 json类型简介

- PG对json的支持趋于完善，提供多个json函数和操作符便于开发

  ```apl
  mydb@192.168.71.11:1921=#SELECT '{"a":1,"b":2}'::json;
       json
  ---------------
   {"a":1,"b":2}
  ```

- 更好的演示，创建一张表

  ```apl
  mydb@192.168.71.11:1921=#create table test_json1 (id serial primary key,name json);
  CREATE TABLE
  ```

- 以上定义字段name为json，插入数据如下：

  ```apl
  mydb@192.168.71.11:1921=#insert into test_json1 (name) values ('{"coll":1,"coll2":"francs","coll3":"male"}');
  INSERT 0 1
  
  mydb@192.168.71.11:1921=#insert into test_json1 (name) values ('{"coll":2,"coll2":"fp","coll3":"female"}');
  INSERT 0 1
  ```

- 查询表test_json1数据

  ```apl
  mydb@192.168.71.11:1921=#select * from test_json1;
   id |                           name
  ----+-----------------------------------------------------------
    1 | {"coll":1,"coll2":"francs","coll3":"male"}
    2 | {"coll":2,"coll2":"fp","coll3":"female"}
  ```

### 3.8.2 查询json数据

- 通过 ”->"操作符可以查询json数据的键值

  ```apl
  mydb@192.168.71.11:1921=#select name -> 'coll2' from test_json1 where id=1;
   ?column?
  ----------
   "francs"
  ```

- 如果想以文本格式返回json字段，可以使用>>

  ```apl
  mydb@192.168.71.11:1921=#select name ->> 'coll2' from test_json1 where id = 1;
   ?column?
  ----------
   francs
  ```

### 3.8.3 jsonb于json差异

- 几乎相同，json存储格式为文本，而jsonb存储格式为二进制，jsonb写入比jsonb快，但减少比jsonb慢

- 输出顺序对比

  ```apl
  mydb@192.168.71.11:1921=#select '{"bar":"baz","banlance":7.77,"active":false}'::jsonb;
                         jsonb
  ---------------------------------------------------
   {"bar": "baz", "active": false, "banlance": 7.77}
  (1 row)
  
  mydb@192.168.71.11:1921=#select '{"bar":"baz","banlance":7.77,"active":false}'::json;
                       json
  ----------------------------------------------
   {"bar":"baz","banlance":7.77,"active":false}
  (1 row)
  ```

- 另外jsonb类型会去掉输入数据中键值空格

  ```apl
  mydb@192.168.71.11:1921=#select '{"id":1,          "name":"france"}'::jsonb;
              jsonb
  -----------------------------
   {"id": 1, "name": "france"}
  (1 row)
  
  mydb@192.168.71.11:1921=#select '{"id":1,          "name":"france"}'::json;
                  json
  ------------------------------------
   {"id":1,          "name":"france"}
  (1 row)
  ```

- 另外jsonb会删除重复的键，仅保留最后一个

  ```apl
  mydb@192.168.71.11:1921=#select '{"id":1,"name":"france","remark":"a good guy!","name":"test"}'::jsonb;
                         jsonb
  ----------------------------------------------------
   {"id": 1, "name": "test", "remark": "a good guy!"}
  (1 row)
  
  mydb@192.168.71.11:1921=#select '{"id":1,"name":"france","remark":"a good guy!","name":"test"}'::json;
                               json
  ---------------------------------------------------------------
   {"id":1,"name":"france","remark":"a good guy!","name":"test"}
  (1 row)
  ```

- 大多场景建议使用jsonb，除非特殊需求，比如json的键顺序由特殊要求

### 3.8.4 jsonb与json操作符

- 以文本格式返回json类型的字段键值可以使用 "->>"

  ```apl
  mydb@192.168.71.11:1921=#select name ->>  'coll2' from test_json1 where id =1 ;
   ?column?
  ----------
   francs
  ```

- 字符串是否作为顶层键值

  ```apl
  mydb@192.168.71.11:1921=#select '{"a":1,"b":2}'::jsonb ? 'a';
   ?column?
  ----------
   t
  ```

- 删除json数据值的键 / 值

  ```apl
  mydb@192.168.71.11:1921=#select '{"a":1,"b":2}'::jsonb - 'b';
   ?column?
  ----------
   {"a": 1}
  (1 row)
  
  mydb@192.168.71.11:1921=#select '{"a":1,"b":2}'::jsonb - 'a';
   ?column?
  ----------
   {"b": 2}
  (1 row)
  ```

### 3.8.5 jsonb与json函数

- 扩展主最外层的json对象成为一组键 /值结果集

  ```apl
  mydb@192.168.71.11:1921=#select * from json_each('{"a":"foo","b":"bar"}');
   key | value
  -----+-------
   a   | "foo"
   b   | "bar"
  ```

- 以文本形式返回结果

  ```apl
  mydb@192.168.71.11:1921=#select * from json_each_text('{"a":"foo","b":"bar"}');
   key | value
  -----+-------
   a   | foo
   b   | bar
  ```

- 一个非常重要的函数 row_to_json()，能够将行为作为json对象返回，此函数用来生产json测试数据，比如将一个普通表转为json类型表

  ![image-20240610035559024](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240610035559024.png?raw=true)

  

### 3.8.6 jsonb键/值的追加、删除、更新

- jsonb键/值追加可通过“||”操作符，类如增加sex键/值

  ```apl
  mydb@192.168.71.11:1921=#select '{"name":"france","age":31}'::jsonb || '{"sex":"male"}'::jsonb;
                     ?column?
  ----------------------------------------------
   {"age": 31, "sex": "male", "name": "france"}
  (1 row)
  ```

- jsonb键/值的删除有两种方法，一种是通过操作符“_"删除，另一种是通过操作符"#_"删除指定键/值

- 通过操作符"_"删除

  ```apl
  mydb@192.168.71.11:1921=#select '{"name":"james","email":"Lzh_888888_1223@163.com"}'::jsonb - 'email';
       ?column?
  -------------------
   {"name": "james"}
   
   mydb@192.168.71.11:1921=#select '["red","green","bule"]'::jsonb -0;
       ?column?
  -------------------
   ["green", "bule"]
  (1 row)
  ```

- 第二种方法通过操作符"#-"删除嵌套contact中的fax键/值

  ```apl
  mydb@192.168.71.11:1921=#SELECT '{"name": "James", "contact": {"phone": "01234 567890", "fax": "01987 543210"}}'::jsonb #- '{contact,fax}'::text[];
                          ?column?
  ---------------------------------------------------------
   {"name": "James", "contact": {"phone": "01234 567890"}}
  (1 row)
  ```

- 删除嵌套aliases中位置为1的键/值

  ```apl
  mydb@192.168.71.11:1921=#select '{"name":"James","aliases":["Jamie","The Jamester","J MAN"]}'::jsonb #- '{aliases,0}'::text[];
                          ?column?
  ---------------------------------------------------------
   {"name": "James", "aliases": ["The Jamester", "J MAN"]}
  (1 row)
  
  mydb@192.168.71.11:1921=#select '{"name":"James","aliases":["Jamie","The Jamester","J MAN"]}'::jsonb #- '{aliases,1}'::text[];
                       ?column?
  --------------------------------------------------
   {"name": "James", "aliases": ["Jamie", "J MAN"]}
  (1 row)
  ```

- 键/值的更新两种方式，第一种通过 “||"操作符，||操作符可以连接到json键，可以覆盖

  ```apl
  mydb@192.168.71.11:1921=#select '{"name":"franche","age":"31"}'::jsonb || '{"age":"21"}'::jsonb;
               ?column?
  ----------------------------------
   {"age": "21", "name": "franche"}
  ```

- 第二种是通过jsonb_set函数

  ```apl
  jsonb set(target jsonb, path text[],new value jsonb[, create missing boolean])
  ```

- target指源jsonb数据，path指路径，new_value指更新后的键值，create_missing值为true表示如果键值不存在则添加，create_missing值为false表示如果键不存在则不添加

  ```apl
  mydb@192.168.71.11:1921=#select jsonb_set('{"name":"france","age":"31"}'::jsonb,'{age}','"21"'::jsonb,false);
              jsonb_set
  ---------------------------------
   {"age": "21", "name": "france"}
   
  mydb@192.168.71.11:1921=#select jsonb_set('{"name":"france","age":"31"}'::jsonb,'{sex}','"male"'::jsonb,true);
                     jsonb_set
  ------------------------------------------------
   {"age": "31", "sex": "male", "name": "france"}
  ```

## 3.9 数据类型转换

- 前面几个小节介绍了PostgreSQL常规数据类型和非常规数据类型，本节将数据转换，转换有三种方式：
  - 格式化函数
  - CAST函数
  - :: 操作符

![image-20240610042430710](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240610042430710.png?raw=true)

### 3.9.2 通过CAST函数进行转换

- 将varchar字符串转换成text类型

  ```apl
  mydb@192.168.71.11:1921=#select CAST(varchar'123' as int4);
   int4
  ------
    123
  ```

### 3.9.3 通过 ::操作符进行转换

- 转换成int4或numeric类型

  ```apl
  mydb@192.168.71.11:1921=#select 1::int4, 3/2::numeric;
   int4 |      ?column?
  ------+--------------------
      1 | 1.5000000000000000
  ```

- 通过SQL查询给定表的字段名称，现根据表名在系统表pg_class找到表OID，其中OID为隐藏的系统字段

  ```apl
  mydb@192.168.71.11:1921=#select oid,relname from pg_class where relname='test_json1';
    oid  |  relname
  -------+------------
   32795 | test_json1
  ```

- 之后根据test_json1表示的 OLD，在系统表pg_attribute中根据attrelid(即表的OID)找到表的字段

  ```apl
  mydb@192.168.71.11:1921=#select attname from pg_attribute where attrelid='32795' and attnum > 0;
   attname
  ---------
   id
   name
  ```

- 上述操作需通过两步完成，但通过类型转换一步即可

  ```apl
  mydb@192.168.71.11:1921=#select attname from pg_attribute where attrelid='test_json1'::regclass and attnum >0;
   attname
  ---------
   id
   name
  ```

  ![image-20240610043858289](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240610043858289.png?raw=true)

# 第四章 SQL高级特性

- 本章将介绍PostgreSQL在SQL方面的高级特性，例如WHERE查询，批量插入，RET-urning返回修改的数据、upsert、数据抽样、聚合函数、窗口函数。

## 4.1 WITH查询

- with查询是PostgreSQL支持的高级SQL特性之一，这一特性常称为CTE，with查询在复杂的查询中定义一个辅助语句（可以理解成一个查询中定义的临时表），通常用于递归查询或复杂查询。

### 4.1.1 复杂查询使用CTE

- 简单的CTE了解WITH

  ```apl
  mydb@192.168.71.11:1921=#with t as ( select generate_series(1,3)) select * from t;
   generate_series
  -----------------
                 1
                 2
                 3
  ```

  CTE示例中，一开始定义了一条辅助语句t取数，之后在主查询语句中查询 t，定义的辅助语句就像是定义了一张临时表，对于复杂查询如果不使用CTE，可以通过创建视图方式简化SQL

- CTE可以简化SQL并且减少嵌套，因为可以预先定义辅助语句，之后在主查询中多次调用。接着看一个稍复杂CTE例子

  ```apl
  with regional_sales as (
      select region, sum(amount) as total_sales
      from sales.orders
      group by region
  ),
  top_regions as (
      select region
      from regional_sales
      where total_sales > (select sum(total_sales) / 10 from regional_sales)
  )
  select region, product, sum(quantity) as product_units, sum(amount) as product_sales
  from sales.orders
  where region in (select region from top_regions)
  group by region, product;
  ```

  这个例子首先定义了regional_sales和top_regions两个辅助语句，regional_sales算出每个区域的总销量，top_regions算出销量占总销量10%以上的所有区域，主查询语句通过辅助语句与orders表关联，算出了顶级区域每件商品的销量和销售额。

### 4.1.2 递归查询使用CTE

- with查询的一个重要属性是recursive，使用recursive属性可以引用自己的输出，从而实现递归，一般用于层次结构或树形结构的应用场景，一个简单的recursive

  ```apl
  mydb@192.168.71.11:1921=#WITH recursive t (x) AS (
      SELECT 1
      UNION ALL
      SELECT x + 1 //1+2+3+4+5
      FROM t
      WHERE x < 5
  )
  SELECT sum(x) FROM t;
   sum
  -----
    15
  ```

- 递归查询案例，当给定一个id是能够得到他完整的域名，例如当id=7时，地名是：中国辽宁沈阳和平区，当id=5是，地名是：`中国辽宁大连`，这是一个典型的层次数据递归应用场景，恰好通过PostgreSQL的WITH查询实现，首先创建测试表并插入数据：

  ```apl
  postgres=# create table test_area(id int4,name varchar(32),fatherid int4);
  
  insert into test_area values (1,'中国' ,0);
  insert into test_area values (2,'辽宁' ,1);
  insert into test_area values (3,'山东' ,1);
  insert into test_area values (4,'沈阳' ,2);
  insert into test_area values (5,'大连' ,2);
  insert into test_area values (6,'济南' ,3);
  insert into test_area values (7,'和平区' ,4);
  insert into test_area values (8,'沈河区' ,4);
  
  postgres=# select * from test_area;
   id |  name  | fatherid
  ----+--------+----------
    1 | 中国   |        0
    2 | 辽宁   |        1
    3 | 山东   |        1
    4 | 沈阳   |        2
    5 | 大连   |        2
    6 | 济南   |        3
    7 | 和平区 |        4
    8 | 沈河区 |        4
  ```

- 使用PostgreSQL我WITH查询检索ID为7以及以上的所有父节点：

  - **UNION ALL**: 将前一个查询的结果与下一个查询的结果合并。`UNION ALL` 保留所有重复行，而 `UNION` 会去除重复行。这里使用 `UNION ALL` 是因为我们希望保留所有找到的行。
  - **FROM test_area, r**: 从 `test_area` 表和递归CTE `r` 中选择数据。
  - **WHERE test_area.id = r.fatherid**: 仅选择 `test_area` 表中 `id` 等于 `r` 表中 `fatherid` 的行

  ```postgresql
  postgres=# with recursive r as (
  select * from test_area where id =7
  union all
  select test_area.* from test_area, r where test_area.id = r.fatherid )
  select * from r order by id;\
  
  postgres=# with recursive r as (
  select * from test_area where id =7
  union all
  select test_area.* from test_area, r where test_area.id = r.fatherid )
  select * from r order by id;
   id |  name  | fatherid
  ----+--------+----------
    1 | 中国   |        0
    2 | 辽宁   |        1
    4 | 沈阳   |        2
    7 | 和平区 |        4
  ```

  ![image-20240611100226784](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240611100226784.png?raw=true)

- 查询结果正好是ID=7 节点以及它所有父节点，将输出的name字段合并成 "中国辽宁沈阳和平区"，方法很多，这里通过string_agg函数实现

  ```postgresql
  postgres=# with recursive r as (
  select * from test_area where id =7
  union all
  select test_area.* from test_area,r where test_area.id = r.fatherid)
  select string_agg(name,'<<-') from (select name from r order by id )n;
           string_agg
  -----------------------------
   中国<<-辽宁<<-沈阳<<-和平区
  ```

- 以上是查询当前节点以及当前节点的所有父节点，也可以查询当前节点以及其下的所有子节点，需要修改where条件，如果查找沈阳市及管辖区

  ```postgresql
  postgres=# with recursive r as (
  select * from test_area where id = 3
  union all
  select test_area.* from test_area,r where test_area.fatherid = r.id
  )
  select * from r order by id;
   id | name | fatherid
  ----+------+----------
    3 | 山东 |        1
    6 | 济南 |        3
  (2 rows)
  
  postgres=# with recursive r as (
  select * from test_area where id = 4
  union all
  select test_area.* from test_area,r where test_area.fatherid = r.id
  )
  select * from r order by id;
   id |  name  | fatherid
  ----+--------+----------
    4 | 沈阳   |        2
    7 | 和平区 |        4
    8 | 沈河区 |        4
  ```

---

以上给出了CTE的两个应用场景：复杂查询中的应用和递归查询中的应用，通过示例，很容易知道CTE有以下有点：

- CTE可以简化SQL代码，减少SQL嵌套层数，提高SQL代码的可读性。
- CTE可以辅助语句只需要计算一次，在主查询中可以多次使用
- 当不需要共享查询结果时，相比视图更轻量。

## 4.2批量插入

- 批量插入是指一次性插入多条数据，主要用于提升数据库插入效率，PostgreSQL有多种方法实现批量插入。

### 4.2.1 方式一：INSERT INTO SELECT

通过表数据或函数批量插入

```apol
insert into table_name select...from source_table
```

1. 创建一张表结构和user_ini相同的表并插入user_ini表的全量数据

```
create table tb1_batch1(user_id int8,user_name text);

create table user_ini (user_id integer,user_name varchar(255));
insert into user_ini (user_id,user_name) values (0,'alice');
insert into user_ini (user_id,user_name) values (1,'text');


postgres=# insert into tb1_batch1 (user_id,user_name)
select user_id,user_name from user_ini;
INSERT 0 2
postgres=# select * from tb1_batch1 ;
 user_id | user_name
---------+-----------
       0 | alice
       1 | text
```

2. 指定where进行插入

```apl
postgres=# insert into tb1_batch1 (user_id,user_name)
postgres-# select * from user_ini where user_id=0;
INSERT 0 1
postgres=# select * from tb1_batch1 ;
 user_id | user_name
---------+-----------
       0 | alice
       1 | text
       0 | alice
```

3. 函数进行批量插入

   - **generate_series(1,5)**：这是一个生成序列函数，它会生成一个从 1 到 5 的序列。
   - **'batch2'**：这是一个字符串常量 `'batch2'`，每次生成的记录都将包含这个字符串。

   创建tab1_batch2库

   ```apl
   create table tb1_batch2 (id int8,info text)
   ```

   通过select表数据批量插入的方式大多关系型数据库都不支持，接下来看看PostgreSQL支持的其他批量插入方式。

   ```postgresql
   postgres=# insert into tb1_batch2 (id,info)
   postgres-# select generate_series(1,5),'徐梦云';
   INSERT 0 5
   
   postgres=# select * from tb1_batch2 ;
    id |  info
   ----+--------
     1 | 徐梦云
     2 | 徐梦云
     3 | 徐梦云
     4 | 徐梦云
     5 | 徐梦云
   ```

### 4.2.2 方式二 INSERT INTO VALUES(),(),...

- PostgreSQL的另一种支持批量插入的方法在一条INSERT语句中通过VALUES关键字插入多条记录，通过一个例子就很容易理解。

  ```postgresql
  postgres=# create table tb1_batch3(id int4,info text);
  CREATE TABLE
  postgres=# insert into tb1_batch3(id,info) values (1,'a'),(2,'b'),(3,'c');
  INSERT 0 3
  postgres=# select * from tb1_batch3 ;
   id | info
  ----+------
    1 | a
    2 | b
    3 | c
  ```

- 这种批量插入方式非常独特，一条sql插入多行数据，相比一条SQL插入一条数据方式能减少和数据的交互，减少数据库WAL日志的生成。

### 4.2.3 方式三：COPY或\COPY元命令

- 创建一张测算表，并插入一千万数据，如下

  - **default clock_timestamp()**：是一个 PostgreSQL 内置函数，它返回当前的日期和时间，包括时区。不同于 `current_timestamp` 或 `now()`，`clock_timestamp()` 在一个事务中每次调用都会返回不同的值（精确到微秒）

  ```apl
  create table tb1_batch4(
  id int4,
  info text,
  create_time timestamp(6) with time zone default clock_timestamp());
  
  insert into tb1_batch4(id,info) select n,n||'_batch4' from generate_series(1.10000000) as n;
  ```

- 通过insert插入一千万数据，将一千万数据导出到文件

  ```apl
  [postgres@pgsql root]$ psql postgres
  psql (15.5)
  Type "help" for help.
  
  postgres=# \timing
  Timing is on.
  
  postgres=# copy public.tb1_batch4 TO '/data/scripts/tb1_batch4.txt';
  COPY 10000000
  Time: 3978.851 ms (00:03.979)
  ```

- 一千万数据导出花了3978毫秒，之后情况tb1_batch4并将tb1_batch4.txt数据导入到表中。

  ```postgresql
  postgres=# truncate table tb1_batch4 ;
  TRUNCATE TABLE
  Time: 61.340 ms
  postgres=# select * from tb1_batch4;
   id | info | create_time
  ----+------+-------------
  (0 rows)
  
  Time: 0.693 ms
  
  postgres=# copy public.tb1_batch4 from '/data/scripts/tb1_batch4.txt';
  COPY 10000000
  Time: 10560.340 ms (00:10.560)
  ```

## 4.3 RETURNING返回的数据

- Postgresql的returning可以返回DML修改的数据，具体三个场景：

  insert语句后接returning属性返回插入的数据

  update语句后接returning属性返回更新后的数据

  delete语句后接returning属性后返回删除的数据。

  这个特性的优点在于不需要额外的SQL获取这些值，能够便于应用开发

### 4.3.1 RETURNING返回插入的数据

- insert语句后接returning属性返回插入的值，下面的代码创建测试表，并返回已插入的整行数据。

  ```postgresql
  postgres=# create table test_r1(id serial,flag char(1));
  CREATE TABLE
  
  postgres=# insert into test_r1(flag) values ('a') returning *;
   id | flag
  ----+------
    1 | a
  ```

  `RETURNING *`表示返回表插入的所有字段数据，也可以返回指定字段，RETURNING后接字段名即可，如下代码仅返回插入的id字段：

  ```apl
  postgres=# insert into test_r1(flag) values ('b') returning id;
   id
  ----
    2
  ```

### 4.3.2 RETURNING 返回更新后数据

- UPdate后接RETURNING属性返回UPDATE语句更行后的值：

  ```apl
  postgres=# update test_r1 set flag ='p' where id =1 returning *;
   id | flag
  ----+------
    1 | p
  ```

### 4.3.3 RETURNING 返回删除的数据

- DELETE后接RETURNING属性返回删除的数据

  ```apl
  postgres=# delete from test_r1 where id =2 returning *;
   id | flag
  ----+------
    2 | b
  (1 row)
  
  DELETE 1
  postgres=# select * from test_r1;
   id | flag
  ----+------
    1 | p
  ```

## 4.4 UPSERT

- UPSERT特性是指INSERT....ON CONFLICT UPSERT，解决插入过程数据冲突，如违反用户自定义约束，并且在日志场景中，批量插入日志数据，如果其中一条数据违反表上的约束，整个插入事件将会回滚。UPSERT能解决这一问题。

### 4.4.1 UPSERT 场景演示：

- 定义一张用户登录日志表并插入一条数据

  ```postgresql
  create table user_logins(user_name text primary key,
  login_cat int4,
  last_login_time timestamp(0) without time zone);
  CREATE TABLE
  
  postgres=# insert into user_logins (user_name,login_cat)
  postgres-# values ('francs',1);
  INSERT 0 1
  
  postgres=# select * from user_logins ;
   user_name | login_cat | last_login_time
  -----------+-----------+-----------------
   francs    |         1 |
  ```

  ---

  在user_logins表user_name字段上定义主键，批量插入数据中如果有重复会报错

  ```apl
  postgres=# insert into user_logins (user_name,login_cat)
  postgres-# values ('matiler',1),('francs',1);
  ERROR:  duplicate key value violates unique constraint "user_logins_pkey"
  DETAIL:  Key (user_name)=(francs) already exists.
  ```

  ---

  上述SQL试图插入两条数据，其中matiler这条数据不违反主键冲突，而francs这条数据违反主键冲突，结果两台数据都不能插入。

- PostgreSQL的UPSERT可以处理冲突的数据比如当掺入的数据的冲突是不报错，同时更新冲突的数据

  - **ON CONFLICT**: 指定当插入操作导致唯一约束冲突时的处理方式。
  - **(user_name)**: 指定用于检测冲突的列，这里是 `user_name` 列。它通常是一个唯一约束或主键。

  - `DO UPDATE SET login_cat = user_logins.login_cat + EXCLUDED.login_cat, last_login_time = now()`

  - **DO UPDATE SET**: 指定在冲突发生时需要执行的更新操作。

  - login_cat = user_logins.login_cat + EXCLUDED.login_cat

    :

    - **user_logins.login_cat**: 表示现有表中对应冲突行的 `login_cat` 列的值。
    - **EXCLUDED.login_cat**: 表示试图插入但引发冲突的行的 `login_cat` 列的值。
    - **user_logins.login_cat + EXCLUDED.login_cat**: 将现有行的 `login_cat` 值与新行的 `login_cat` 值相加。

  - **last_login_time = now()**: 将 `last_login_time` 列设置为当前时间。

  ```postgresql
  postgres=# insert into user_logins(user_name,login_cat)
  values ('matiler',1),('francs',1)
  on conflict(user_name)
  do update set login_cat=user_logins.login_cat+EXCLUDED.login_cat,
  postgres-# last_login_time=now()::timestamp with time zone;
  INSERT 0 2
  
  postgres=# select * from user_logins;
   user_name | login_cat |   last_login_time
  -----------+-----------+---------------------
   matiler   |         1 |
   francs    |         2 | 2024-06-12 01:09:32
  (2 rows)
  ```

---

一方面冲突的francs这条数据被更新了login_cat和last_login_time字段另一方面新的数据matiler记录已经正常插入。

- 指定数据冲突后啥也不干，这时需要指定DO nothing属性

  ```apl
  postgres=# insert into user_logins (user_name,login_cat)
  postgres-# values ('true',1),('francs',1)
  postgres-# on conflict(user_name)
  postgres-# do nothing;
  INSERT 0 1
  postgres=# select * from user_logins;
   user_name | login_cat |   last_login_time
  -----------+-----------+---------------------
   matiler   |         1 |
   francs    |         2 | 2024-06-12 01:09:32
   true      |         1 |
  ```

### 4.4.2 UPSERT语法

- PostgreSQL的UPSERT语法比较复杂，通过以上演示后再来查看语法会轻松些。

![image-20240611172112973](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240611172112973.png?raw=true)

## 4.5 数据抽样

- 数据抽样 TABLESAMPLE(tablesample)数据处理经常用，特别是表数据量比较大时，随机查询表中一定数量记录操作很常见，但新能很低。

  ```apl
  postgres=# create table user_ini (id int4,user_id int4 ,user_name varchar(100),create_time timestamp without time zone default clock_timestamp());
  CREATE TABLE
  postgres=# insert into user_ini (id,user_id,user_name)                                           select n,n,n ||'_francs'
  from generate_series(1,500000) n;
  INSERT 0 500000
  ```

  ```apl
  postgres=# select * from user_ini limit 2;
   id | user_id | user_name |        create_time
  ----+---------+-----------+----------------------------
    1 |       1 | 1_francs  | 2024-06-12 01:37:41.010486
    2 |       2 | 2_francs  | 2024-06-12 01:37:41.010583
  (2 rows)
  
  postgres=# select * from user_ini order by random() limit 2;
     id   | user_id |   user_name   |        create_time
  --------+---------+---------------+----------------------------
   286380 |  286380 | 286380_francs | 2024-06-12 01:37:41.406446
    51589 |   51589 | 51589_francs  | 2024-06-12 01:37:41.084805
    
  postgres=# select * from user_ini order by random() limit 2;
     id   | user_id |   user_name   |        create_time
  --------+---------+---------------+----------------------------
   174038 |  174038 | 174038_francs | 2024-06-12 01:37:41.249593
   471258 |  471258 | 471258_francs | 2024-06-12 01:37:41.664831
  ```

- 执行计划如下：

  ```apl
  postgres=# EXPLAIN ANALYZE select * from user_ini order by random() limit 1;
                                                           QUERY PLAN
  
  -------------------------------------------------------------------------------------------------
  ----------------------------
   Limit  (cost=12427.00..12427.00 rows=1 width=37) (actual time=111.123..111.125 rows=1 loops=1)
     ->  Sort  (cost=12427.00..13677.00 rows=500000 width=37) (actual time=111.121..111.122 rows=1
  loops=1)
           Sort Key: (random())
           Sort Method: top-N heapsort  Memory: 25kB
           ->  Seq Scan on user_ini  (cost=0.00..9927.00 rows=500000 width=37) (actual time=0.012..
  52.569 rows=500000 loops=1)
   Planning Time: 0.078 ms
   Execution Time: 111.146 ms
  (7 rows)
  ```

  表user_ini数据量为50万，从50万随机取一条上述SQL的执行事件为111ms这种方式进行了全表扫描和排序，效率非常低，当表数据量大时，性能几乎无法接受。
  
- PostgreSQL支持TABLESAMPLE数据抽样

  ![image-20240611232407774](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240611232407774.png?raw=true)
  
  sampling_method指抽样方法，主要有两种：SYSTEM和BERNOULLI，接下来详细解释这两种抽样方式，argument指抽样百分比。

### 4.5.1 SYSTEM抽样方式

- SYSTEM抽样方式随机抽取表上数据库上的数据，SYSTEM抽样方式基于数据块级别，后接抽样参数，的所有数据将被检索。

  ```postgresql
  postgres=# create table test_sample(id int4,message text,
  create_time timestamp(6) without time zone default clock_timestamp());
  
  postgres=# insert into test_sample (id,message)
  select n, md5(random()::text) from generate_series(1,1500000) n;
  
  postgres=# select * from test_sample limit 1;
   id |             message              |        create_time
  ----+----------------------------------+----------------------------
    1 | 1cc563b206c6ad324daa0d7cd684d3fd | 2024-06-12 02:10:23.671603
  (1 row)
  ```

  抽样因子设置成0.01，意味着50000×0.01%=150条记录

  ```postgresql
  postgres=# explain analyze select * from test_sample tablesample system(0.01);
                                                   QUERY PLAN
  -------------------------------------------------------------------------------------------------------------
   Sample Scan on test_sample  (cost=0.00..5.58 rows=158 width=44) (actual time=0.038..0.138 rows=321 loops=1)
     Sampling: system ('0.01'::real)
   Planning Time: 0.140 ms
   Execution Time: 0.163 ms
  (4 rows)
  
  ```

  以上执行计划主要有两点，一方面进行了Sample Scan扫描(抽样的方式为SYSTEM)执行事件为0.019ms，性能，另一方面优化器预计访问5条记录，实际返回45

  ```apl
  postgres=# select relname,relpages from pg_class where relname='test_sample';
     relname   | relpages
  -------------+----------
   test_sample |    14019
  ```

  表test_sample物理上占用了14019个数据块，也就是说每个数据块1000000/14019=158

- 查看抽样数据的ctid

  ```apl
  postgres=# select ctid,* from test_sample tablesample system(0.01);
      ctid     |   id    |             message              |        create_time
  -------------+---------+----------------------------------+----------------------------
   (9988,1)    | 1068717 | 9610359f37ce3188f4d6b6c2df5f258f | 2024-06-12 02:31:13.413036
   (9988,2)    | 1068718 | a0454591f2f6f09ebd7f4d3fa98907cd | 2024-06-12 02:31:13.41306
  ..............
  ```

  ctid是表的隐藏列，括号里第一位表示逻辑数据库编号，第二位表示逻辑块上的数据的逻辑编号，从以上看出，这107条记录都存储在逻辑编号为6646的数据块上，也就是抽样返回一个数据库上的所有数据，抽样因子固定为0.01，多次执行以下查询

  ```apl
  postgres=# select count(*) from test_sample tablesample system(0.01);
   count
  -------
     214
  (1 row)
  
  postgres=# select count(*) from test_sample tablesample system(0.01);
   count
  -------
     107
  (1 row)
  ```

---

再次查询发现返回的记录为214或107，由于一个数据存储块107条记录，因此查询结果有时返回了两个数据块以上的所有数据，这是因为抽样因子设置成0.01，意味着返回样方式返回的数据块为单位，被抽样的块上所有数据被检索。

### 4.5.2 BERNOULLI抽样方式

- BERNOULLI抽样方式随机抽取表的数据，并返回指定百分比数据，基于数据行级别，BERNOULLI抽样方式抽取的数据相比SYSTEM方式有更好的随机性，但性能上相比SYSTEM抽样方式低很多。

  ```apl
  postgres@pghost1:1921=#explain analyze select * from test_sample tablesample bernoulli (0.01);
                                                       QUERY PLAN
  
  -------------------------------------------------------------------------------------------------
  -------------------
   Sample Scan on test_sample  (cost=0.00..14020.50 rows=150 width=45) (actual time=10.349..207.223
   rows=167 loops=1)
     Sampling: bernoulli ('0.01'::real)
   Planning Time: 0.048 ms
   Execution Time: 207.258 ms
  (4 rows)
  ```

  从以上执行计划看出继续宁了Sample Scan扫描执行计划预计返回150条记录，实际返回167，从返回的记录数来看，非常接近150条(100000×0.01%)需要执行207毫秒，

- 多次执行以下查询，查看返回记录数据的变化

  ```apl
  postgres@pghost1:1921=#select count(*) from test_sample tablesample bernoulli (0.01);
   count
  -------
     166
  (1 row)
  
  postgres@pghost1:1921=#select count(*) from test_sample tablesample bernoulli (0.01);
   count
  -------
     132
  ```

- 由于BERNOULLI 抽样基于数据行级别，猜想返回的数据应该位于不同的数据块上，通过查询表的ctid进行验证

  ```postgresql
  postgres@pghost1:1921=#select ctid,id,message from test_sample tablesample bernoulli (0.01);
      ctid     |   id    |             message
  -------------+---------+----------------------------------
   (127,28)    |   13617 | 29094764b4e8154f2bacb4257f960910
   (206,25)    |   22067 | e35edc24436cc633bb4d7da0f97d65c9
   (207,59)    |   22208 | ae9d8042bce53f1210ef45f24cb45c5f
  ................
  ```

  从以上三条记录的ctid信息看出，三条数据分别位于数据库127，206，207上，因此BERNOULLI抽样方式随机性相比SYSTEM方式更好。

  ## 4.6聚合函数

  聚合函数可以对结果进行计算，常用聚合函数有 avg()、sum()、main()、max()、count()等

  ![image-20240612094847305](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240612094847305.png?raw=true)

### 4.6.1 string_agg函数

- 首先介绍string_agg函数，此函数语法如下所示

  ```apl
  string_agg(expression,delimiter)
  ```

- string_agg函数能将结果集某个字段的所有行连接成字符串，并指定delimiter分隔符分隔，expression处理字符类型数据，参数类型为(text,text)或(bytea,bytea)函数返回的类型同输入参数类型一直，bytea属于二进制类型，使用情况不多，我们主要介绍text类型输入参数，本节开头的场景正好可以用string_agg函数处理

- 首先创建测试表并插入以下数据

  ```apl
  postgres@pghost1:1921=#create table city (country character varying(64),city character varying(64));
  
  insert into city values ('中国','台北');
  insert into city values ('中国','香港');
  insert into city values ('中国','上海');
  insert into city values ('日本','东京');
  insert into city values ('日本','大连');
  
  postgres@pghost1:1921=#select * from city ;
   country | city
  ---------+------
   中国    | 台北
   中国    | 香港
   中国    | 上海
   日本    | 东京
   日本    | 大连
  ```

- 将city字段连接成字符串

  ```apl
  postgres@pghost1:1921=#select string_agg(city,'<>') from city ;
            string_agg
  ------------------------------
   台北<>香港<>上海<>东京<>大连
  ```

- string_agg函数将输出结果集成了字符串，并用指定逗号分隔

  ```apl
  postgres@pghost1:1921=#select country,string_agg(city,',') from city group by country;
   country |   string_agg
  ---------+----------------
   日本    | 东京,大连
   中国    | 台北,香港,上海
  ```

### 4.6.2array_agg函数

- array_agg函数和string_agg函数类似，主要的区别为返回类型为数组，数组数据类型同输入参数数据类型一直，array_agg函数支持两种语法

  ```apl
  array_agg(expressions)--输入参数为任何非数组类型
  ```

  输入参数可以是任何非数组类型，返回的结果是一组数组，array_agg函数将结束集某个字段女的所有行连接数组

  ```apl
  postgres@pghost1:1921=#select country,array_agg(city) from city group by country;
   country |    array_agg
  ---------+------------------
   日本    | {东京,大连}
   中国    | {台北,香港,上海}
  ```

  ---

  arrar_agg函数输出的结果为字符类型数组，其他无明显区别，使用array_agg函数组要优点在于可以使用数组相关函数和操作符

- 第二种array_agg(expression) --输入参数为任何数据类型

  第一种array_agg函数的输入阐述为任何非数组类型，这里输入任何参数为数组类型

  创建数组表

  ```postgresql
  postgres@pghost1:1921=#create table test_array3(id int4[]);
  
  postgres@pghost1:1921=#insert into test_array3(id) values ( array[1,2,3]);
  
  postgres@pghost1:1921=#insert into test_array3(id) values ( array[4,5,6]);
  
  postgres@pghost1:1921=#select * from test_array3 ;
     id
  ---------
   {1,2,3}
   {4,5,6}
  (2 rows)
  ```

  使用array_agg函数

  ```apl
  postgres@pghost1:1921=#select array_agg(id) from test_array3 ;
       array_agg
  -------------------
   {{1,2,3},{4,5,6}}
  ```

  也可以将array_agg函数输出类型转换成字符串，并用分隔符分隔`arrag_to_string`函数

  ```postgresql
  postgres@pghost1:1921=#select array_to_string (array_agg(id),',') from test_array3 ;
   array_to_string
  -----------------
   1,2,3,4,5,6
  ```

## 4.7 窗口函数

- 窗口函数也是基于结果集进行计算，与聚合函数不同的是窗口函数不会将结果集输出一行，二十合并到输出的结果集上，返回多行。

### 4.7.1 窗口函数语法

- postgresql提供内置的窗口函数，例如：row()、rank()、lan()等，除了内置的窗口函数外，聚合函数，自定义函数后接OVER属性也可以作为窗口函数。

  窗口函数的调用语法稍微复杂

  ![image-20240612104805041](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240612104805041.png?raw=true)

### 4.7.2 avg() OVER()

- 聚合函数后接OVER属性的窗口函数，表示在一个查询结果集上应用聚合函数。

1. 将此窗口函数用来计算分组后数据的平均值。

- 创建一张成绩表并插入测试数据

  ```apl
  postgres@pghost1:1921=#create table score ( id serial primary key,
  subject character varying (32),
  stu_name varchar(32),
  score numeric(3,0));
  CREATE TABLE
  
  INSERT INTO score (subject, stu_name, score) VALUES ('Chinese', 'francs', 70);
  INSERT INTO score (subject, stu_name, score) VALUES ('Chinese', 'matiler', 70);
  INSERT INTO score (subject, stu_name, score) VALUES ('Chinese', 'tutu', 80);
  INSERT INTO score (subject, stu_name, score) VALUES ('English', 'matiler', 75);
  INSERT INTO score (subject, stu_name, score) VALUES ('English', 'francs', 90);
  INSERT INTO score (subject, stu_name, score) VALUES ('English', 'tutu', 60);
  INSERT INTO score (subject, stu_name, score) VALUES ('Math', 'francs', 80);
  INSERT INTO score (subject, stu_name, score) VALUES ('Math', 'matiler', 99);
  INSERT INTO score (subject, stu_name, score) VALUES ('Math', 'tutu', 65);
  
  ```

- 查询每名学生学习成绩并且显示课程的平均分，通常是先计算出课程的平均分，然后用score表与平均分表关联查询

  - **LEFT JOIN**：执行左连接操作，确保左边表`s`中的所有记录都被包括，即使右边的子查询`tmp`中没有对应的记录。

    **(SELECT subject, avg(score) avgscore FROM score GROUP BY subject)**：这是一个子查询，用于计算每个学科的平均分数。

    - **SELECT subject, avg(score)**：选择每个学科和对应的平均分数。
    - **avg(score)**：计算每个学科的平均分数。
    - **FROM score**：指定数据来源于`score`表。
    - **GROUP BY subject**：按`subject`列分组，以计算每个学科的平均分数。

    - **tmp**：给子查询结果起一个别名`tmp`，方便在主查询中引用。

    - **ON**：指定连接条件。

      **s.subject = tmp.subject**：连接条件为主查询表`s`中的`subject`列与子查询结果`tmp`中的`subject`列相等。

  ```apl
  LEFT JOIN (SELECT subject, avg(score) avgscore FROM score GROUP BY subject) tmp
  ON s.subject = tmp.subject;
   subject | stu_name | score |      avgscore
  ---------+----------+-------+---------------------
   Chinese | francs   |    70 | 73.3333333333333333
   Chinese | matiler  |    70 | 73.3333333333333333
   Chinese | tutu     |    80 | 73.3333333333333333
   English | matiler  |    75 | 75.0000000000000000
   English | francs   |    90 | 75.0000000000000000
   English | tutu     |    60 | 75.0000000000000000
   Math    | francs   |    80 | 81.3333333333333333
   Math    | matiler  |    99 | 81.3333333333333333
   Math    | tutu     |    65 | 81.3333333333333333
  ```

- 使用窗口函数很容易实现以上需求

  - 查询前三列源于表socre，低撕裂表示课程的平均分，PARTITION BY subject

  ```apl
  postgres@pghost1:1921=#select subject,stu_name,score,avg(score) OVER(partition by subject) from score;
   subject | stu_name | score |         avg
  ---------+----------+-------+---------------------
   Chinese | francs   |    70 | 73.3333333333333333
   Chinese | matiler  |    70 | 73.3333333333333333
   Chinese | tutu     |    80 | 73.3333333333333333
   English | matiler  |    75 | 75.0000000000000000
   English | francs   |    90 | 75.0000000000000000
   English | tutu     |    60 | 75.0000000000000000
   Math    | francs   |    80 | 81.3333333333333333
   Math    | matiler  |    99 | 81.3333333333333333
   Math    | tutu     |    65 | 81.3333333333333333
  ```

### 4.7.3 row_number()

- row_number()窗口函数对结果及分组后的数据标注行号，从1开始

  ```apl
  postgres@pghost1:1921=#select row_number() OVER (PARTITION by subject ORDER by score desc),* from score;
   row_number | id | subject | stu_name | score
  ------------+----+---------+----------+-------
            1 |  3 | Chinese | tutu     |    80
            2 |  1 | Chinese | francs   |    70
            3 |  2 | Chinese | matiler  |    70
            1 |  5 | English | francs   |    90
            2 |  4 | English | matiler  |    75
            3 |  6 | English | tutu     |    60
            1 |  8 | Math    | matiler  |    99
            2 |  7 | Math    | francs   |    80
            3 |  9 | Math    | tutu     |    65
  (9 rows)
  ```

  以上row_number()窗口函数显示的是分组后记录的行号，如果不指定partition属性，row_number()窗口函数表示所有记录的行号。

  ```apl
  postgres@pghost1:1921=#select row_number() OVER(ORDER BY id) as rownum,* from score;
   rownum | id | subject | stu_name | score
  --------+----+---------+----------+-------
        1 |  1 | Chinese | francs   |    70
        2 |  2 | Chinese | matiler  |    70
        3 |  3 | Chinese | tutu     |    80
        4 |  4 | English | matiler  |    75
        5 |  5 | English | francs   |    90
        6 |  6 | English | tutu     |    60
        7 |  7 | Math    | francs   |    80
        8 |  8 | Math    | matiler  |    99
        9 |  9 | Math    | tutu     |    65
  (9 rows)
  ```

### 4.7.4 rank()

- rank()窗口函数和row_number()窗口函数相似，主要区别为当组内某行字段值相同时，行号重复并且行号产生间隙，如下所示

  ```apl
  postgres@pghost1:1921=#select rank() OVER(partition by subject order by score),* from score;
   rank | id | subject | stu_name | score
  ------+----+---------+----------+-------
      1 |  2 | Chinese | matiler  |    70
      1 |  1 | Chinese | francs   |    70
      3 |  3 | Chinese | tutu     |    80
      1 |  6 | English | tutu     |    60
      2 |  4 | English | matiler  |    75
      3 |  5 | English | francs   |    90
      1 |  9 | Math    | tutu     |    65
      2 |  7 | Math    | francs   |    80
      3 |  8 | Math    | matiler  |    99
  (9 rows)
  ```

  以上示例中，Chinese课程前两条记录的score字段值为70，因此前两行的rank字段值为1，而三行的rank()字段值为3，产生了间隙。

### dense_rank()

- dense_rank()窗口函数和rank()窗口函数相似，主要区别当组内某行字段值相同时，虽然行号重复，但行号不产生间隙

  ```apl
  postgres@pghost1:1921=# select dense_rank() OVER(partition by subject order by score),* from score;
   dense_rank | id | subject | stu_name | score
  ------------+----+---------+----------+-------
            1 |  2 | Chinese | matiler  |    70
            1 |  1 | Chinese | francs   |    70
            2 |  3 | Chinese | tutu     |    80
            1 |  6 | English | tutu     |    60
            2 |  4 | English | matiler  |    75
            3 |  5 | English | francs   |    90
            1 |  9 | Math    | tutu     |    65
            2 |  7 | Math    | francs   |    80
            3 |  8 | Math    | matiler  |    99
  (9 rows)
  ```

  ---

  Chinese课程前两行的rank字段值为1，而第三个字段为2，没有产生间隙。

### 4.7.7 first_value()

- first_value()窗口函数用来取结果集每一个分组的第一行数据的字段值。

- 例如score表按课程分组后取分组的第一行的分数

  ```apl
  postgres@pghost1:1921=#select first_value (score) OVER(partition by subject),*from score;
   first_value | id | subject | stu_name | score
  -------------+----+---------+----------+-------
            70 |  1 | Chinese | francs   |    70
            70 |  2 | Chinese | matiler  |    70
            70 |  3 | Chinese | tutu     |    80
            75 |  4 | English | matiler  |    75
            75 |  5 | English | francs   |    90
            75 |  6 | English | tutu     |    60
            80 |  7 | Math    | francs   |    80
            80 |  8 | Math    | matiler  |    99
            80 |  9 | Math    | tutu     |    65
  (9 rows)
  ```

- 通过first_value()窗口函数很容易查询分组数据的最大值或最小值，例如score表按课程分组同时取每门课程的最高分

  ```postgresql
  ### 降序desc
  postgres@pghost1:1921=#select first_value(score) OVER(partition by subject order by score desc),* from score;
   first_value | id | subject | stu_name | score
  -------------+----+---------+----------+-------
            80 |  3 | Chinese | tutu     |    80
            80 |  1 | Chinese | francs   |    70
            80 |  2 | Chinese | matiler  |    70
            90 |  5 | English | francs   |    90
            90 |  4 | English | matiler  |    75
            90 |  6 | English | tutu     |    60
            99 |  8 | Math    | matiler  |    99
            99 |  7 | Math    | francs   |    80
            99 |  9 | Math    | tutu     |    65
  (9 rows)
  
  ###升序ASC
  postgres@pghost1:1921=#select first_value(score) OVER(partition by subject order by score asc),* from score;
   first_value | id | subject | stu_name | score
  -------------+----+---------+----------+-------
            70 |  2 | Chinese | matiler  |    70
            70 |  1 | Chinese | francs   |    70
            70 |  3 | Chinese | tutu     |    80
            60 |  6 | English | tutu     |    60
            60 |  4 | English | matiler  |    75
            60 |  5 | English | francs   |    90
            65 |  9 | Math    | tutu     |    65
            65 |  7 | Math    | francs   |    80
            65 |  8 | Math    | matiler  |    99
  (9 rows)
  
  ```

### 4.7.8 last_value()

- last_value()窗口函数用来取结果集每一个分组的最后一行数据的字段值

  ```postgresql
  postgres@pghost1:1921=#select last_value(score) OVER(partition by subject ),* from score;
   last_value | id | subject | stu_name | score
  ------------+----+---------+----------+-------
           80 |  1 | Chinese | francs   |    70
           80 |  2 | Chinese | matiler  |    70
           80 |  3 | Chinese | tutu     |    80
           60 |  4 | English | matiler  |    75
           60 |  5 | English | francs   |    90
           60 |  6 | English | tutu     |    60
           65 |  7 | Math    | francs   |    80
           65 |  8 | Math    | matiler  |    99
           65 |  9 | Math    | tutu     |    65
  (9 rows)
  ```

### 4.7.9 nth_value()

- nth_value()窗口函数用来取结果集每一个分组的指定行数据的字段值

  ```postgresql
  nth_value(value any,nth integer)
  ```

  其中：

  - value：指定表的字段
  - nth：指定结果集分组数据中的第几行，如果不存在则返回空。

  ```apl
  postgres@pghost1:1921=#select nth_value(score,2) OVER(partition by subject),* from score;
   nth_value | id | subject | stu_name | score
  -----------+----+---------+----------+-------
          70 |  1 | Chinese | francs   |    70
          70 |  2 | Chinese | matiler  |    70
          70 |  3 | Chinese | tutu     |    80
          90 |  4 | English | matiler  |    75
          90 |  5 | English | francs   |    90
          90 |  6 | English | tutu     |    60
          99 |  7 | Math    | francs   |    80
          99 |  8 | Math    | matiler  |    99
          99 |  9 | Math    | tutu     |    65
  ```

### 4.7.10窗口函数别名的使用

- 如果SQL中需要多次使用窗口函数，可以使用窗口函数别名

  ```postgresql
  select....from....WINDOW window_name as (window_definition) {,...}
  ```

  WINDOW属性指定表的别名为window_name，可以给OVER属性应用

  ```apl
  postgres@pghost1:1921=#select avg(score) OVER(r),sum(score) OVER(r),* from score window r as (partition by subject);
           avg         | sum | id | subject | stu_name | score
  ---------------------+-----+----+---------+----------+-------
   73.3333333333333333 | 220 |  1 | Chinese | francs   |    70
   73.3333333333333333 | 220 |  2 | Chinese | matiler  |    70
   73.3333333333333333 | 220 |  3 | Chinese | tutu     |    80
   75.0000000000000000 | 225 |  4 | English | matiler  |    75
   75.0000000000000000 | 225 |  5 | English | francs   |    90
   75.0000000000000000 | 225 |  6 | English | tutu     |    60
   81.3333333333333333 | 244 |  7 | Math    | francs   |    80
   81.3333333333333333 | 244 |  8 | Math    | matiler  |    99
   81.3333333333333333 | 244 |  9 | Math    | tutu     |    65
  (9 rows)
  ```

# 核心篇

# 第五章 体系结构



# 第六章 并行查询

- oracle支持并行查询，比如SELECT、UPDATE、DELETE大事物开启并行功能后能利用多核CPU，从而发挥硬件性能，提升大事物处理效率，并行索引查询，并行索引扫描，并行index-only扫描，并行bitmap heap扫描等。

## 6.1 并行查询相关配置参数

- 介绍并行查询之前先介绍并行查询几个重要参数。

  1. **max_worker_processes(integer)**

     设置系统支持的最大后台进程数，默认值为8，如果有备库，备库上此参数必须大于或等于主库上的此参数配置值，此参数调整后需重启数据库生效。

  2. **max_parallel_workers(integer)**

     设置系统支持的并行查询进程数，默认值为8，此参数受max_worker_processes参数限制，设置此参数的值比max_worker_processes值高将无效。

     当调整这个参数时建议同时调整max_parallel_workers_per_gather参数值

  3. **max_parallel_workers_per_gather（integer）**

     设置允许启用并行进程的进数，默认值为2，设置成0表示禁用并行查询，此参数受max_worker_processes参数和max_parallel_workers参数限制，因此并行查询的实际进程数会少些，并行查询比非并行查询消耗更多CPU、IO、内存资源，对生产系统有一定影响，使用时需要考虑这方面的因素

     ```apl
     max_worker_processes > max_parallel_workers > max_parallel_workers_per_gather
     ```

  4. **parallel_setup_cost(floating point)**

     设置优化器启动并行进程的成本，默认为1000

  5. **parallel_tuple_cost(floating point)**

     设置优化器通过并行进程处理一行数据的成本，默认0.1

  6. **min_parallel_table_scan_size(integer)**

     设置开启并行的条件之一，表占用空间小于此值将不会开启并行，并行顺序扫描场景下扫描的数据大小通常等于表大小，默认值为8MB

  7. **min_parallel_index_scan_size(integer)**

     设置开启并行的条件之一，实际上并行索引扫描不会扫描索引所有模块，只是扫描索引相关数据模块，默认值512kb。

  8. **force_parallel_mode(enum)**

     强制开启并行，一般作为测试目的，OLTP生产环境开启需要慎重，一般不建议开启。

     本章中Postgresql.conf配置文件设置了一下参数

     ```apl
     max_worker_processes = 16 
     max_parallel_workers_per_gather = 4
     max_parallel_workers = 8
     parallel_tuple_cost = 0.1
     parallel_setup_cost = 1000.0 
     min_parallel_table_scan_size = 8MB
     min_parallel_index_scan_size = 512kB
     force_parallel_mode = off //如果没有手动添加
     ```

---

![image-20240612171647299](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240612171647299.png?raw=true)

## 6.2 并行扫描

- 扫描包括并行扫描、并行索引扫描，并行index-only扫描、并行bitmap heap扫描场景，测试过程中会对上一小节的部分参数进行设置，通过实验了解这些参数的含义。

### 6.2.1 并行顺序扫描

- 介绍并行顺序扫描前先介绍（sequential scan)，顺序扫描通常也称之为全表扫描，全表扫描会扫描整张表数据，当表很大时，全表扫描会占用大量CPU\内存\IO资源，对数据库性能影响大。

1. 创建一张测试表，并插入5000万数据

   ```postgresql
   postgres@pghost1:1921=#create table test_big1(id int4,
   postgres(# name varchar(32),
   postgres(# craete_time timestamp without time zone default clock_timestamp());
            
   postgres@pghost1:1921=#insert into test_big1 (id,name)
   select n,n||'_test' from generate_series(1,50000000)n;
   ```

2. 一个顺序扫描的示例

   ```apl
   postgres@pghost1:1921=#explain select * from test_big1 where name='1_test';
                                     QUERY PLAN
   ------------------------------------------------------------------------------
    Gather  (cost=1000.00..523930.22 rows=1 width=25)
      Workers Planned: 4
      ->  Parallel Seq Scan on test_big1  (cost=0.00..522930.12 rows=1 width=25)
            Filter: ((name)::text = '1_test'::text)
   (4 rows)
   ```

   以上执行计划Seq Scan on test_big1说明表test_big1上继续宁了顺序扫描，并利用多个逻辑CPU并行全表扫描，一个并行顺序扫描的执行如下：

   ```apl
   postgres@pghost1:1921=#explain analyze select * from test_big1 where name='1_test';
                                                            QUERY PLAN
   
   ---------------------------------------------------------------------------------------------
   -------------------------------
    Gather  (cost=1000.00..523930.22 rows=1 width=25) (actual time=0.971..875.605 rows=1 loops=1
   )
      Workers Planned: 4
      Workers Launched: 4
      ->  Parallel Seq Scan on test_big1  (cost=0.00..522930.12 rows=1 width=25) (actual time=67
   9.975..854.734 rows=0 loops=5)
            Filter: ((name)::text = '1_test'::text)
            Rows Removed by Filter: 10000000
    Planning Time: 0.067 ms
    Execution Time: 875.624 ms
   (8 rows)
   ```

   以上Woeker Planned表执行计划预估的并行进程数，Woker Launched表示查询实际获得的并行进程数，这里Woker Planned和Woker Launched值都为4，Parallel Seq on test_big1表示进行了并行顺序扫描, 从上可以看出，开启4个并行时，sql的执行时间为875毫秒

3. 不开启worker_per_gather参数设置成了4，设置成0表示关闭并行。

   ```apl
   postgres@pghost1:1921=#explain analyze select * from test_big1 where name='1_test';
                                                     QUERY PLAN
   
   --------------------------------------------------------------------------------------
   ------------------------
    Seq Scan on test_big1  (cost=0.00..991728.50 rows=1 width=25) (actual time=878.832..2
   439.526 rows=1 loops=1)
      Filter: ((name)::text = '1_test'::text)
      Rows Removed by Filter: 49999999
    Planning Time: 0.041 ms
    Execution Time: 2439.541 ms
   (5 rows)
   ```

   不开启并行时此SQL执行时间为5329毫秒，比开启并行查询性能低了3倍左右。

### 6.2.2并行索引扫描

- 索引扫描(index scan) ，在表上创建索引后，进行索引扫描的执行如下：

  ```apl
  postgres@pghost1:1921=#explain select * from test_1 where id=1;
                                  QUERY PLAN
  ---------------------------------------------------------------------------
   Index Scan using test_1_pkey on test_1  (cost=0.15..8.17 rows=1 width=40)
     Index Cond: (id = 1)
  (2 rows)
  ```

  Index Scan using 表示执行计划预计进行索引扫描，索引扫描也支持并行，称为并行索引扫描(Parallel index scan)，本节演示并行索引扫描，并在表test_big1上创建索引

  ```apl
  postgres@pghost1:1921=#create index idx_big1_id ON test_big1 USING btree (id);
  CREATE INDEX
  ```

  执行以下SQL，统计ID小于1千万的记录数

  ```apl
  postgres@pghost1:1921=#explain analyze select count(name) from test_big1 where id<10000000;
                                                                                QUERY PL
  AN
  --------------------------------------------------------------------------------------
  --------------------------------------------------------------------------------
   Finalize Aggregate  (cost=284884.55..284884.56 rows=1 width=8) (actual time=413.915..
  424.356 rows=1 loops=1)
     ->  Gather  (cost=284883.93..284884.54 rows=6 width=8) (actual time=413.753..424.34
  8 rows=7 loops=1)
           Workers Planned: 6
           Workers Launched: 6
           ->  Partial Aggregate  (cost=283883.93..283883.94 rows=1 width=8) (actual tim
  e=402.149..402.150 rows=1 loops=7)
                 ->  Parallel Index Scan using idx_big1_id on test_big1  (cost=0.56..279
  642.04 rows=1696754 width=13) (actual time=0.053..294.569 rows=1428571 loops=7)
                       Index Cond: (id < 10000000)
   Planning Time: 0.139 ms
   Execution Time: 424.380 ms
  (9 rows)
  ```

  根据以上执行计划可以看出，进行了并行索引扫描，开启了4个并行进程，执行时间为424毫秒

- 会话级别关闭进行查询

  ```apl
  max_parallel_workers_per_gather
  ```

  再次执行

  ```apl
  postgres@pghost1:1921=#explain analyze select count(name) from test_big1 where id<10000000;
                                                                      QUERY PLAN
  
  --------------------------------------------------------------------------------------
  -------------------------------------------------------------
   Aggregate  (cost=389931.07..389931.08 rows=1 width=8) (actual time=1552.588..1552.590
   rows=1 loops=1)
     ->  Index Scan using idx_big1_id on test_big1  (cost=0.56..364479.75 rows=10180525
  width=13) (actual time=0.065..1097.416 rows=9999999 loops=1)
           Index Cond: (id < 10000000)
   Planning Time: 0.060 ms
   Execution Time: 1552.613 ms
  (5 rows)
  ```

  从执行计划看出进行了索引扫描，并没有开启并行，执行时间为1552毫秒，比并行索引性能低很多。

### 6.2.3并行index-only扫描

- index-only扫描只需要扫描索引，也就是说SQL仅根据索引就能够获取所需要检索的数据，而不需要通过索引回表查询数据。

- 会话级别关闭。

  ```apl
  postgres@pghost1:1921=#set max_parallel_workers_per_gather=0;                         SET
  ```

1. 查看执行计划

   ```apl
   postgres@pghost1:1921=#explain select count(*) from test_big1 where id<10000000;
                                                QUERY PLAN
   
   --------------------------------------------------------------------------------------
   --------------
    Aggregate  (cost=315271.07..315271.08 rows=1 width=8)
      ->  Index Only Scan using idx_big1_id on test_big1  (cost=0.56..289819.75 rows=1018
   0525 width=0)
            Index Cond: (id < 10000000)
   (3 rows)
   ```

   以上执行主要看Index Only Scan 这一行，由于ID字段上建立了索引，统计记录数不需要再回表查询其他信息，因此进行了index-only扫描

2. EXPLAIN ANALYZE执行此SQL

   ```apl
   postgres@pghost1:1921=#explain analyze select count(*) from test_big1 where id<10000000;
                                                                         QUERY PLAN
   
   --------------------------------------------------------------------------------------
   ----------------------------------------------------------------
    Aggregate  (cost=315271.07..315271.08 rows=1 width=8) (actual time=863.722..863.723 r
   ows=1 loops=1)
      ->  Index Only Scan using idx_big1_id on test_big1  (cost=0.56..289819.75 rows=1018
   0525 width=0) (actual time=0.020..563.454 rows=9999999 loops=1)
            Index Cond: (id < 10000000)
            Heap Fetches: 0
    Planning Time: 0.058 ms
    Execution Time: 863.745 ms
   (6 rows)
   ```

   执行时间为253毫秒，index-only扫描支持并行，称为并行index-only扫描

- 开启并行index-only扫描

  ```apl
  postgres@pghost1:1921=#set max_parallel_workers_per_gather to default;
  SET
  ```

- 再次执行以下查询

  ```apl
  postgres@pghost1:1921=#set max_parallel_workers_per_gather to default;
  
  postgres@pghost1:1921=#explain analyze select count(*) from test_big1 where id <10000000;
                                                                                  QUERY
  PLAN
  --------------------------------------------------------------------------------------
  ------------------------------------------------------------------------------------
   Finalize Aggregate  (cost=220829.06..220829.07 rows=1 width=8) (actual time=348.532..
  350.266 rows=1 loops=1)
     ->  Gather  (cost=220828.64..220829.05 rows=4 width=8) (actual time=348.430..350.25
  9 rows=5 loops=1)
           Workers Planned: 4
           Workers Launched: 4
           ->  Partial Aggregate  (cost=219828.64..219828.65 rows=1 width=8) (actual tim
  e=337.799..337.800 rows=1 loops=5)
                 ->  Parallel Index Only Scan using idx_big1_id on test_big1  (cost=0.56
  ..213465.82 rows=2545131 width=0) (actual time=0.060..252.034 rows=2000000 loops=5)
                       Index Cond: (id < 10000000)
                       Heap Fetches: 0
   Planning Time: 0.074 ms
   Execution Time: 350.291 ms
  (10 rows)
  ```

### 6.2.4 并行bitmap heap扫描

- Bitmap Index和Bitmap Heap扫描，当SQL的where条件中出现or时很有可能出现Bitmap Index扫描

  ```apl
  postgres@pghost1:1921=#explain select * from test_big1 where id=1 or id=2;
                                     QUERY PLAN
  --------------------------------------------------------------------------------
   Bitmap Heap Scan on test_big1  (cost=9.15..17.16 rows=2 width=25)
     Recheck Cond: ((id = 1) OR (id = 2))
     ->  BitmapOr  (cost=9.15..9.15 rows=2 width=0)
           ->  Bitmap Index Scan on idx_big1_id  (cost=0.00..4.57 rows=1 width=0)
                 Index Cond: (id = 1)
           ->  Bitmap Index Scan on idx_big1_id  (cost=0.00..4.57 rows=1 width=0)
                 Index Cond: (id = 2)
  (7 rows)
  ```

  从以上执行计划看出，限制性两次Bitamp index扫描获取索引项，之后讲Bitmap index扫描获取的结果结合起来回表查询，再查询中讲ID的选择范围扩大。

  ```apl
  postgres@pghost1:1921=#explain analyze select count(*) from test_big1 where id <10000000 or id > 49000000;
                                                                      QUERY PLAN
  
  --------------------------------------------------------------------------------------
  -------------------------------------------------------------
   Finalize Aggregate  (cost=562003.43..562003.44 rows=1 width=8) (actual time=896.896..
  897.563 rows=1 loops=1)
     ->  Gather  (cost=562003.01..562003.42 rows=4 width=8) (actual time=896.785..897.55
  6 rows=5 loops=1)
           Workers Planned: 4
           Workers Launched: 4
           ->  Partial Aggregate  (cost=561003.01..561003.02 rows=1 width=8) (actual tim
  e=893.790..893.791 rows=1 loops=5)
                 ->  Parallel Seq Scan on test_big1  (cost=0.00..554164.00 rows=2735602
  width=0) (actual time=256.298..801.286 rows=2200000 loops=5)
                       Filter: ((id < 10000000) OR (id > 49000000))
                       Rows Removed by Filter: 7800000
   Planning Time: 0.191 ms
   Execution Time: 897.595 ms
  (10 rows)
  ```

2. 在会话级关闭并行查询

   ```APL
   postgres@pghost1:1921=#explain analyze select count (*) from test_big1 where id < 1000000 or id > 49000000;
                                                                      QUERY PLAN
   
   --------------------------------------------------------------------------------------
   -----------------------------------------------------------
    Aggregate  (cost=1096345.81..1096345.82 rows=1 width=8) (actual time=183.203..183.206
    rows=1 loops=1)
      ->  Bitmap Heap Scan on test_big1  (cost=38885.60..1091272.21 rows=2029440 width=0)
    (actual time=44.967..122.749 rows=1999999 loops=1)
            Recheck Cond: ((id < 1000000) OR (id > 49000000))
            Heap Blocks: exact=13724
            ->  BitmapOr  (cost=38885.60..38885.60 rows=2050366 width=0) (actual time=43.
   152..43.153 rows=0 loops=1)
                  ->  Bitmap Index Scan on idx_big1_id  (cost=0.00..20199.28 rows=1093696
    width=0) (actual time=21.794..21.794 rows=999999 loops=1)
                        Index Cond: (id < 1000000)
                  ->  Bitmap Index Scan on idx_big1_id  (cost=0.00..17671.59 rows=956670
   width=0) (actual time=21.357..21.357 rows=1000000 loops=1)
                        Index Cond: (id > 49000000)
    Planning Time: 0.086 ms
    Execution Time: 183.229 ms
   (11 rows)
   ```

   从以上执行计划看出进行了Bitmap Heap扫描，执行时间为183毫秒，不开启并行此开启并行性能低了不少。

## 6.3 并行聚合

- 并行聚合：count()、sum()等集合函数的SQL，以下执行count()函数统计表记录总数

  ```apl
  postgres@pghost1:1921=#explain analyze select count(*) from test_big1 ;                                                                                   QUERY PLAN
  
  --------------------------------------------------------------------------------------
  -------------------------------------------------------------
   Finalize Aggregate  (cost=523914.42..523914.43 rows=1 width=8) (actual time=1122.163.
  .1122.678 rows=1 loops=1)
     ->  Gather  (cost=523914.00..523914.41 rows=4 width=8) (actual time=1122.047..1122.
  660 rows=5 loops=1)
           Workers Planned: 4
           Workers Launched: 4
           ->  Partial Aggregate  (cost=522914.00..522914.01 rows=1 width=8) (actual tim
  e=1109.915..1109.915 rows=1 loops=5)
                 ->  Parallel Seq Scan on test_big1  (cost=0.00..491664.00 rows=12500000
   width=0) (actual time=0.025..696.300 rows=10000000 loops=5)
   Planning Time: 0.059 ms
   Execution Time: 1122.701 ms
  (8 rows)
  ```

  ![image-20240613174121480](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240613174121480.png?raw=true)

  首先进行partial Aggregate，开启了四个并行进程，最后进行Finalize Aggregate，此SQL执行时间为2474毫秒，在操作系统层通过top命令看到 EXPLAIN ANLAYZE四个进程

2. 尝试讲进程数更改为2

   ```apl
   postgres@pghost1:1921=#set max_parallel_workers_per_gather=0;
   
   postgres@pghost1:1921=#explain analyze select count(*) from test_big1 ;
                                                                        QUERY PLAN
   ----------------------------------------------------------------------------------------------------------------------------------------------------
    Finalize Aggregate  (cost=628080.88..628080.89 rows=1 width=8) (actual time=1658.148..1658.546 rows=1 loops=1)
      ->  Gather  (cost=628080.67..628080.88 rows=2 width=8) (actual time=1658.059..1658.538 rows=3 loops=1)
            Workers Planned: 2
            Workers Launched: 2
            ->  Partial Aggregate  (cost=627080.67..627080.68 rows=1 width=8) (actual time=1648.419..1648.420 rows=1 loops=3)
                  ->  Parallel Seq Scan on test_big1  (cost=0.00..574997.33 rows=20833333 width=0) (actual time=0.050..1017.596 rows=16666667 loops=3)
    Planning Time: 0.131 ms
    Execution Time: 1658.579 ms
   (8 rows)
   ```

   | 并行进程数 | Count（）执行时间 |
   | ---------- | ----------------- |
   | 0          | 4132毫秒          |
   | 2          | 1598毫秒          |
   | 4          | 1036毫秒          |
   | 6          | 785毫秒           |

3. sum()函数也能支持并行扫描

   ```apl
   postgres@pghost1:1921=#explain analyze select sum(hashtext (name)) from test_big1 ;
                                                                       QUERY PLAN
   --------------------------------------------------------------------------------------------------------------------------------------------------
    Finalize Aggregate  (cost=492664.62..492664.63 rows=1 width=8) (actual time=1126.214..1126.902 rows=1 loops=1)
      ->  Gather  (cost=492664.00..492664.61 rows=6 width=8) (actual time=1126.121..1126.895 rows=7 loops=1)
            Workers Planned: 6
            Workers Launched: 6
            ->  Partial Aggregate  (cost=491664.00..491664.01 rows=1 width=8) (actual time=1122.389..1122.390 rows=1 loops=7)
                  ->  Parallel Seq Scan on test_big1  (cost=0.00..449997.33 rows=8333333 width=13) (actual time=0.023..494.675 rows=7142857 loops=7)
    Planning Time: 0.133 ms
    Execution Time: 1126.938 ms
   (8 rows)
   ```

   main()、max() 聚合函数也支持并行查询，这里不再测试。

## 6.4 多表关联

- 多表关联也能用到并行扫描，而是指多表关联涉及的表数据检索时能够使用并行处理

### 6.4.1 Nested loop多表关联

- 多表关联Nested loop是一个嵌套循环，伪代码

  ```
  for(i=0;i<length(outer);i++)
  for(j=0;j<length(inner);j++)
  	if(outer[i]== inner[j])
  	output(outerli],innerlj]);
  ```

- 接着测试Nested loop 多表关联场景下使用到并行扫描的情况，创建一张test_small小表。

  ```apl
  postgres@pghost1:1921=#create table test_small(id int4,name character varying(32));
  CREATE TABLE
  
  postgres@pghost1:1921=#insert into test_small(id,name)
  select n,n || '_small' from generate_series(1,8000000) n;
  INSERT 0 8000000
  ```

- 创建索引并做表分析

  ```apl
  postgres@pghost1:1921=#create index idx_test_small_id ON test_small USING btree (id);
  CREATE INDEX
  postgres@pghost1:1921=#select * from test_small limit 1;
   id |  name
  ----+---------
    1 | 1_small
  (1 row)
  
  postgres@pghost1:1921=#analyze test_small;
  ANALYZE
  ```

- ANALYZE命令用于收集表上的统计信息，使优化器能够获得更精准的执行计划

  ```postgresql
  postgres@pghost1:1921=#explain analyze select test_small.name from test_big1 ,test_small where test_big1.id = test_small.id and test_small.id < 10000;
                                                                   QUERY PLAN
  ---------------------------------------------------------------------------------------------------------------------------------------------
   Nested Loop  (cost=1.00..44018.87 rows=9804 width=13) (actual time=0.037..11.778 rows=9999 loops=1)
     ->  Index Scan using idx_test_small_id on test_small  (cost=0.43..346.00 rows=9804 width=17) (actual time=0.011..1.266 rows=9999 loops=1)
           Index Cond: (id < 10000)
     ->  Index Only Scan using idx_big1_id on test_big1  (cost=0.56..4.44 rows=1 width=4) (actual time=0.001..0.001 rows=1 loops=9999)
           Index Cond: (id = test_small.id)
           Heap Fetches: 0
   Planning Time: 0.811 ms
   Execution Time: 12.044 ms
  ```

  首先在表test_big1上进行了Index Only扫描，用于检索id小于100000的记录，之后两表进行Nested loop关联同时在表test_small
  
  

### 6.4.1 Merge join 多表关联

- Merge join 多表关联首先讲两个表进行排序，之后进行关联字段匹配，Merge join

  ```apl
  postgres@pghost1:1921=#explain analyze select test_small.name from test_small,test_big1 where test_big1.id = test_small.id and test_small.id < 200000;
                                                                             QUERY PLAN
  
  -------------------------------------------------------------------------------------------------
  ---------------------------------------------------------------
   Gather  (cost=1001.74..176162.42 rows=204448 width=13) (actual time=0.750..70.396 rows=199999 lo
  ops=1)
     Workers Planned: 6
     Workers Launched: 6
     ->  Merge Join  (cost=1.74..154717.62 rows=34075 width=13) (actual time=4.650..52.878 rows=285
  71 loops=7)
           Merge Cond: (test_big1.id = test_small.id)
           ->  Parallel Index Only Scan using idx_big1_id on test_big1  (cost=0.56..881729.90 rows=
  8333333 width=4) (actual time=0.050..2.763 rows=28572 loops=7)
                 Heap Fetches: 0
           ->  Index Scan using idx_test_small_id on test_small  (cost=0.43..7125.27 rows=204448 wi
  dth=17) (actual time=0.026..32.533 rows=199999 loops=7)
                 Index Cond: (id < 200000)
   Planning Time: 0.246 ms
   Execution Time: 76.992 ms
  (11 rows)
  ```

- 开启6个并行，执行时间为76毫秒，下面关闭进行比较

  ```postgresql
  postgres@pghost1:1921=#explain analyze select test_small.name from test_small,test_big1 where test_big1.id = test_small.id and test_small.id < 200000;
                                                                       QUERY PLAN
  
  -------------------------------------------------------------------------------------------------
  ----------------------------------------------------
   Merge Join  (cost=1.74..241099.09 rows=204448 width=13) (actual time=0.033..70.119 rows=199999 l
  oops=1)
     Merge Cond: (test_small.id = test_big1.id)
     ->  Index Scan using idx_test_small_id on test_small  (cost=0.43..7125.27 rows=204448 width=17
  ) (actual time=0.020..22.511 rows=199999 loops=1)
           Index Cond: (id < 200000)
     ->  Index Only Scan using idx_big1_id on test_big1  (cost=0.56..1298396.56 rows=50000000 width
  =4) (actual time=0.009..13.382 rows=200000 loops=1)
           Heap Fetches: 0
   Planning Time: 0.218 ms
   Execution Time: 175.200 ms
  (8 rows)
  ```

### 6.4.3 Hash join 多表关联

- PostgreSQL多表关联也支持 Hash join，当关联字段没有索引情况下两表关联通常会进行Hash join接下来查看Hash join 的执行计划，先将两表上的索引删除，同时关闭并行。

  ```postgresql
  postgres@pghost1:1921=#SET enable_nestloop TO off;
  SET
  postgres@pghost1:1921=#SET enable_mergejoin TO off;
  SET
  postgres@pghost1:1921=#drop index idx_test_big1_id;  
  postgres@pghost1:1921=#drop index idx_test_small_id;
  DROP INDEX
  postgres@pghost1:1921=#set max_parallel_workers_per_gather=0;                  
  
  postgres@pghost1:1921=#explain analyze select test_small.name from test_big1 join test_small ON ( test_big1.id =test_small.id) and test_small.id < 100;
                                                            QUERY PLAN
  
  -------------------------------------------------------------------------------------------------
  ------------------------------
   Hash Join  (cost=150870.85..1205042.85 rows=800 width=13) (actual time=5264.722..6393.665 rows=9
  9 loops=1)
     Hash Cond: (test_big1.id = test_small.id)
     ->  Seq Scan on test_big1  (cost=0.00..866664.00 rows=50000000 width=4) (actual time=0.012..31
  83.107 rows=50000000 loops=1)
     ->  Hash  (cost=150860.85..150860.85 rows=800 width=17) (actual time=459.848..459.849 rows=99
  loops=1)
           Buckets: 1024  Batches: 1  Memory Usage: 13kB
           ->  Seq Scan on test_small  (cost=0.00..150860.85 rows=800 width=17) (actual time=0.008.
  .459.832 rows=99 loops=1)
                 Filter: (id < 100)
                 Rows Removed by Filter: 7999901
   Planning Time: 0.123 ms
   Execution Time: 6393.693 ms
  
  ```

- 开启4个并行

  ```postgresql
  postgres@pghost1:1921=#explain analyze select test_small.name from test_big1 join test_small ON ( test_big1.id =test_small.id) and test_small.id < 100;
                                                                   QUERY PLAN
  
  -------------------------------------------------------------------------------------------------
  --------------------------------------------
   Gather  (cost=76862.71..615482.21 rows=800 width=13) (actual time=1504.987..1505.477 rows=99 loo
  ps=1)
     Workers Planned: 4
     Workers Launched: 4
     ->  Parallel Hash Join  (cost=75862.71..614402.21 rows=200 width=13) (actual time=1439.674..14
  94.355 rows=20 loops=5)
           Hash Cond: (test_big1.id = test_small.id)
           ->  Parallel Seq Scan on test_big1  (cost=0.00..491664.00 rows=12500000 width=4) (actual
   time=0.019..680.644 rows=10000000 loops=5)
           ->  Parallel Hash  (cost=75860.21..75860.21 rows=200 width=17) (actual time=99.912..99.9
  12 rows=20 loops=5)
                 Buckets: 1024  Batches: 1  Memory Usage: 40kB
                 ->  Parallel Seq Scan on test_small  (cost=0.00..75860.21 rows=200 width=17) (actu
  al time=77.773..99.748 rows=20 loops=5)
                       Filter: (id < 100)
                       Rows Removed by Filter: 1599980
   Planning Time: 0.185 ms
   Execution Time: 1505.509 ms
  ```

# 第七章事物与并发控制

## 7.1 事物和并发控制的概念

- 事物有四个重要的特性
  - 原子性
    - 一个事物的所有操作，要么全部执行，要么全不执行
  - 一致性
    - 执行事物时保持数据库从一个一致的状态变更到另一个一致的状态。
  - 隔离性
    - 即使每个事物都能确保一致性和原子性，如果并发执行时，不希望的方式交叉运行，就会导致不一致的情况发生。
  - 持久性
    - 一个事物完成之后，即使数据库发生故障，他对数据库的更变也永久保存在数据库中。

### 7.1.2 并发引发的现象

- 事务都按照顺序执行，所有事物的执行时间没有重叠就不会存在事物并发性。Postgresql可以把这些非预期的现象总结为：脏读、不可重复读、幻读、和序列化异常

1. 脏读

   - 当第一个事物读取了第二个事物中已经修改但还未提交的数据，包括INSERT UPDATE、DELETE当第二个事务不提交并执行ROLLBACK后，第一个事务所读取到的数据是不正常的，这种读取现象称作脏读。
   - 首先创建一张测试表并插入测试数据，如下所示

   ```postgresql
   postgres@pghost1:1921=#CREATE TABLE tbl_mvcc (
       id SERIAL NOT NULL,
       ival INT,
       PRIMARY KEY (id)
   );
   
   postgres@pghost1:1921=#INSERT INTO tb1_mvcc (ival) VALUES (1);
   INSERT 0 1
   ```

   | T1                                                           | T2                                                           |
   | ------------------------------------------------------------ | ------------------------------------------------------------ |
   | set session transaction isolation level read uncommitted; start transaction; | start transaction;<br />update tb1_mvcc set ival = 10 where id =1; |
   |                                                              |                                                              |
   | select * from tb1_mvcc where id =1;                          |                                                              |
   |                                                              | rollback;                                                    |
   |                                                              |                                                              |

   

![image-20240618230951775](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240618230951775.png?raw=true)

- 事物T1在tb1_mvcc表中查询数据，得到id=1，ival=1的行，这时时间T2更新表中id=1，ival=10，此时事务T1查询tb1_mvcc表，而事务T2此时并未提交，ival预期的值应当是1，但是T1却得到ival=10，事务T2最终进行了ROLLBACK操作，显然，事务T1将得到错误的值，引发了脏读现象

2. 不可重复读

   当一个事务第一次读取数据之后，被读取的数据已经被另一个已提交的事务进行了修改，事务再次读取这些数据已经被另一个事务修改，两次查询的结果不一致，这种称为不可重复读。

   - 创建一张测试表插入数据

     ```postgresql
     postgres@pghost1:1921=#create table tb2_mvcc (
     id serial primary key,
     ival int
     );
     postgres@pghost1:1921=#insert into tb2_mvcc (ival) values (1);
     ```

     | T1                                                           | T2                                                      |
     | ------------------------------------------------------------ | ------------------------------------------------------- |
     | begin transaction isolation level read committed;            |                                                         |
     | select id,ival from tb2_mvcc where id =1;                    |                                                         |
     | ![image-20240618232045706](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240618232045706.png?raw=true) |                                                         |
     |                                                              | begin;<br />update tb2_mvcc set ival = 10 where id =1 ; |
     | select id,ival from tb2_mvcc where id =1;                    |                                                         |

![image-20240618232601911](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240618232601911.png?raw=true)

![image-20240618232651718](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240618232651718.png?raw=true)

3. 幻读

- 指一个事务的两次查询的结果集 记录数不一致。例如第一次查询的数据和第二次再次插入或删除了所查询的数据不一致。或则第一次查询的结果数据不存在，两次查询结果不同

  | T1                                                           | T2                                                       |
  | ------------------------------------------------------------ | -------------------------------------------------------- |
  | begin transaction isolation level read committed;<br />select id,ival from tb2_mvcc where id > 3 and id < 10; |                                                          |
  | select id,ival from tb2_mvcc where id =1;                    |                                                          |
  |                                                              | begin;<br />insert into tb2_mvcc (id,ival) values (6,6); |
  | select id,ival from tb2_mvcc where id > 3 and id < 10;       |                                                          |
  |                                                              |                                                          |

![image-20240618234052221](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240618234052221.png?raw=true)

![image-20240618234245199](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240618234245199.png?raw=true)

### 7.1.3 ANSI SQL 标准事务隔离级别

- 为避免事务与事务之间发生执行引发的副作用，最简单的方法是窜行化地逐个执行事务。
- ANSI SQL标准定义了四类隔离级别，每个隔离级别都包括了一些具体规则，也就是允许或不允许出现脏读、不可重复读，幻读的现象
  - **Read Uncommitted(读未提交)|**
    - 所有事物都可以看到其他未提交事物的执行结果，在多用户数据库中，脏读非常危险。所以未提交 这一事物隔离级别很少用于实际应用。
  - **Read Committed（读已提交)**
    - 默认隔离级别，满足一个事物只能看已经提交事物对关联数据所做的改变的隔离需求
  - **Serializable(可序列化)**
    - 最高隔离级别，通过强制事物排序，不能相互冲突，从而解决幻读问题。

![image-20240618234956844](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240618234956844.png?raw=true)

![image-20240618235021729](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240618235021729.png?raw=true)

## 7.2 事物隔离级别

![image-20240618235701353](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240618235701353.png?raw=true)

| T1                                                           | T2                                               |
| ------------------------------------------------------------ | ------------------------------------------------ |
| begin transaction isolation level repeatable read;<br />select id,ival from tb2_mvcc where id =1; |                                                  |
|                                                              |                                                  |
|                                                              | update tb2_mvcc set ival= ival * 10 where id =1; |
| update tb2_mvcc set ival= ival + 1 where id =1;              |                                                  |
| ROLLBACK                                                     |                                                  |

![image-20240619000155858](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240619000155858.png?raw=true)

![image-20240619000527215](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240619000527215.png?raw=true)

- Repeatable 事物隔离级别不能出现幻读

  | T1                                                           | T2                                                           |
  | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | begin transaction isolation level repeatable read;<br />select id,ival from tb2_mvcc where id > 3 and id < 10; |                                                              |
  |                                                              |                                                              |
  |                                                              | begin;<br />insert into tb1_mvcc (id,ival) values (6,6);end; |
  | select id,ival from tb2_mvcc where id > 3 and id < 10;       |                                                              |
  | end;                                                         |                                                              |

![image-20240619002217458](https://github.com/liuzhenhua1223/Image/blob/master//PGSQL/image-20240619002217458.png?raw=true)

### 7.2.1 查看和设置数据库的事务隔离级别

- 默认的事务隔离级别是Read Committed。

  ```postgresql
  postgres@pghost1:1921=#select name,setting from pg_settings where name ='default_transaction_isolation';
               name              |    setting
  -------------------------------+----------------
   default_transaction_isolation | read committed
   
   postgres@pghost1:1921=#select current_setting('default_transaction_isolation');
   current_setting
  -----------------
   read committed
  ```

### 7.2.2 修改全局的事务隔离级别

- 方法1：通过修改Postgresql.conf文件中的 **default_transaction_isolation**参数修改全局事务隔离级别，修改之后reload

- 方法2：通过ALTER SYSTEM 命令修改全局事务隔离级别

  ```postgresql
  postgres@pghost1:1921=#alter system set default_transaction_isolation TO 'REPEATABLE READ';
  ALTER SYSTEM
  
  postgres@pghost1:1921=#select pg_reload_conf();
   pg_reload_conf
  ----------------
   t
  ```

### 7.2.3 查看当前会话的事务隔离级别

- 会话级别

  ```apl
  postgres@pghost1:1921=#show transaction_isolation;
   transaction_isolation
  -----------------------
   repeatable read
  
  postgres@pghost1:1921=#select current_setting('transaction_isolation');
   current_setting
  -----------------
   repeatable read
  
  ```

### 7.2.4 设置当前会话的事务隔离级别

- 设置会话级别

  ```apl
  postgres@pghost1:1921=#set session characteristics as transaction isolation level read uncommitted;
  SET
  postgres@pghost1:1921=#show transaction_isolation;
   transaction_isolation
  -----------------------
   read uncommitted
  ```

  